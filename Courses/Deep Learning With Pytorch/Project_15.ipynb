{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 15 - CIFAR-10 Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.CIFAR10(root='Datasets', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='Datasets', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
       "          [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
       "          [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
       "          ...,\n",
       "          [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
       "          [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
       "          [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
       " \n",
       "         [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
       "          [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
       "          [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
       "          ...,\n",
       "          [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
       "          [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
       "          [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
       " \n",
       "         [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
       "          [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
       "          [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
       "          ...,\n",
       "          [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
       "          [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
       "          [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]]),\n",
       " 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(train_data.targets)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 5000, 9: 5000, 4: 5000, 1: 5000, 2: 5000, 7: 5000, 8: 5000, 3: 5000, 5: 5000, 0: 5000})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(train_data.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class frog')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[0])\n",
    "\n",
    "plt.title('Class ' + str(train_data.classes[train_data.targets[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3))\n",
    "        self.conv2 = nn.Conv2d(32, 32, (3,3))\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.bnorm = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # output = (input - filter + 1)/stride\n",
    "        # conv1 = (32-03 + 1) /1 -> 30\n",
    "        # pool1 = (30 -2 + 1) /2 -> 15\n",
    "        # conv2 = (15 - 3 + 1) /1 -> 13\n",
    "        # pool2 = (13 - 2 + 1) /2 -> 6\n",
    "        # image is now 6x6 pixels\n",
    "        # 32 filters of 6x6 pixels\n",
    "\n",
    "        self.linear1 = nn.Linear(32*6*6, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(self.bnorm(self.activation(self.conv1(X))))\n",
    "        X = self.pool(self.bnorm(self.activation(self.conv2(X))))\n",
    "        X = self.flatten(X)\n",
    "\n",
    "        X = self.dropout(self.activation(self.linear1(X)))\n",
    "        X = self.dropout(self.activation(self.linear2(X)))\n",
    "        X = self.output(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = classifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (activation): ReLU()\n",
       "  (bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=1152, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(loader, epoch):\n",
    "    running_loss = 0\n",
    "    runing_accuracy = 0.\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        ps = F.softmax(outputs, dim=1)\n",
    "\n",
    "        top_p, top_class = ps.topk(k=1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "        accuracy = torch.mean(equals.type(torch.float))\n",
    "\n",
    "        runing_accuracy += accuracy\n",
    "\n",
    "        print(f'Epoch {epoch} - Batch {i} - Loss {running_loss/(i+1)} - Accuracy {runing_accuracy/(i+1)}')\n",
    "    \n",
    "    print(f'Epoch {epoch} - Loss {running_loss/len(loader)} - Accuracy {runing_accuracy/len(loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0 - Batch 0 - Loss 0.868009626865387 - Accuracy 0.71875\n",
      "Epoch 0 - Batch 1 - Loss 0.9224379658699036 - Accuracy 0.6953125\n",
      "Epoch 0 - Batch 2 - Loss 0.933422843615214 - Accuracy 0.6901041865348816\n",
      "Epoch 0 - Batch 3 - Loss 0.9481247514486313 - Accuracy 0.673828125\n",
      "Epoch 0 - Batch 4 - Loss 0.9636596083641052 - Accuracy 0.6781250238418579\n",
      "Epoch 0 - Batch 5 - Loss 0.9863843619823456 - Accuracy 0.6614583730697632\n",
      "Epoch 0 - Batch 6 - Loss 1.015109121799469 - Accuracy 0.6573660969734192\n",
      "Epoch 0 - Batch 7 - Loss 0.9930089637637138 - Accuracy 0.6572265625\n",
      "Epoch 0 - Batch 8 - Loss 0.980266789595286 - Accuracy 0.663194477558136\n",
      "Epoch 0 - Batch 9 - Loss 0.9612057507038116 - Accuracy 0.672656238079071\n",
      "Epoch 0 - Batch 10 - Loss 0.9635274735364047 - Accuracy 0.6690341234207153\n",
      "Epoch 0 - Batch 11 - Loss 0.9724379181861877 - Accuracy 0.6673177480697632\n",
      "Epoch 0 - Batch 12 - Loss 0.9731525916319627 - Accuracy 0.6664663553237915\n",
      "Epoch 0 - Batch 13 - Loss 0.9699321900095258 - Accuracy 0.6662946939468384\n",
      "Epoch 0 - Batch 14 - Loss 0.9591246565183004 - Accuracy 0.6713541746139526\n",
      "Epoch 0 - Batch 15 - Loss 0.9760011918842793 - Accuracy 0.66552734375\n",
      "Epoch 0 - Batch 16 - Loss 0.9664882526678198 - Accuracy 0.6695771813392639\n",
      "Epoch 0 - Batch 17 - Loss 0.9614474376042684 - Accuracy 0.671006977558136\n",
      "Epoch 0 - Batch 18 - Loss 0.9545883159888419 - Accuracy 0.6735197305679321\n",
      "Epoch 0 - Batch 19 - Loss 0.9504169642925262 - Accuracy 0.6742187738418579\n",
      "Epoch 0 - Batch 20 - Loss 0.9401243584496635 - Accuracy 0.6774553656578064\n",
      "Epoch 0 - Batch 21 - Loss 0.9408315528522838 - Accuracy 0.6775568127632141\n",
      "Epoch 0 - Batch 22 - Loss 0.9333246842674587 - Accuracy 0.680027186870575\n",
      "Epoch 0 - Batch 23 - Loss 0.9391854703426361 - Accuracy 0.6770833730697632\n",
      "Epoch 0 - Batch 24 - Loss 0.941028733253479 - Accuracy 0.6762499809265137\n",
      "Epoch 0 - Batch 25 - Loss 0.94164927647664 - Accuracy 0.6748798489570618\n",
      "Epoch 0 - Batch 26 - Loss 0.9453130651403356 - Accuracy 0.6756365895271301\n",
      "Epoch 0 - Batch 27 - Loss 0.9419944328921181 - Accuracy 0.6774553656578064\n",
      "Epoch 0 - Batch 28 - Loss 0.9403695875200732 - Accuracy 0.6775323152542114\n",
      "Epoch 0 - Batch 29 - Loss 0.9336673160394032 - Accuracy 0.6778646111488342\n",
      "Epoch 0 - Batch 30 - Loss 0.9335580602768929 - Accuracy 0.6761592626571655\n",
      "Epoch 0 - Batch 31 - Loss 0.9357035011053085 - Accuracy 0.674560546875\n",
      "Epoch 0 - Batch 32 - Loss 0.9350104006853971 - Accuracy 0.675426185131073\n",
      "Epoch 0 - Batch 33 - Loss 0.9342828778659596 - Accuracy 0.6750919222831726\n",
      "Epoch 0 - Batch 34 - Loss 0.9326645748955863 - Accuracy 0.6758928894996643\n",
      "Epoch 0 - Batch 35 - Loss 0.9323051306936476 - Accuracy 0.67578125\n",
      "Epoch 0 - Batch 36 - Loss 0.9292971894547746 - Accuracy 0.675886869430542\n",
      "Epoch 0 - Batch 37 - Loss 0.929139527835344 - Accuracy 0.6763980388641357\n",
      "Epoch 0 - Batch 38 - Loss 0.9304830798735986 - Accuracy 0.6746795177459717\n",
      "Epoch 0 - Batch 39 - Loss 0.9326402381062507 - Accuracy 0.673828125\n",
      "Epoch 0 - Batch 40 - Loss 0.934274797032519 - Accuracy 0.6732088327407837\n",
      "Epoch 0 - Batch 41 - Loss 0.9352343082427979 - Accuracy 0.6739211678504944\n",
      "Epoch 0 - Batch 42 - Loss 0.9367151052452797 - Accuracy 0.6735101938247681\n",
      "Epoch 0 - Batch 43 - Loss 0.9364985214038328 - Accuracy 0.6727628111839294\n",
      "Epoch 0 - Batch 44 - Loss 0.9360721786816915 - Accuracy 0.671875\n",
      "Epoch 0 - Batch 45 - Loss 0.934255864309228 - Accuracy 0.671875\n",
      "Epoch 0 - Batch 46 - Loss 0.9326969943148025 - Accuracy 0.6720411777496338\n",
      "Epoch 0 - Batch 47 - Loss 0.9342697883645693 - Accuracy 0.6722005605697632\n",
      "Epoch 0 - Batch 48 - Loss 0.9326134190267447 - Accuracy 0.6721938848495483\n",
      "Epoch 0 - Batch 49 - Loss 0.9269255566596984 - Accuracy 0.6732812523841858\n",
      "Epoch 0 - Batch 50 - Loss 0.9269659273764667 - Accuracy 0.672947347164154\n",
      "Epoch 0 - Batch 51 - Loss 0.9284816991824371 - Accuracy 0.6720252633094788\n",
      "Epoch 0 - Batch 52 - Loss 0.9272534633582493 - Accuracy 0.6733490824699402\n",
      "Epoch 0 - Batch 53 - Loss 0.9298207417682365 - Accuracy 0.6725983619689941\n",
      "Epoch 0 - Batch 54 - Loss 0.9299159082499417 - Accuracy 0.672443151473999\n",
      "Epoch 0 - Batch 55 - Loss 0.9295139759778976 - Accuracy 0.6729910969734192\n",
      "Epoch 0 - Batch 56 - Loss 0.9296806747453255 - Accuracy 0.671875\n",
      "Epoch 0 - Batch 57 - Loss 0.9281933667330906 - Accuracy 0.6728178858757019\n",
      "Epoch 0 - Batch 58 - Loss 0.9268679164223752 - Accuracy 0.6731991767883301\n",
      "Epoch 0 - Batch 59 - Loss 0.928501479824384 - Accuracy 0.6717448234558105\n",
      "Epoch 0 - Batch 60 - Loss 0.9304017522295968 - Accuracy 0.670850396156311\n",
      "Epoch 0 - Batch 61 - Loss 0.9295369204013578 - Accuracy 0.6711189150810242\n",
      "Epoch 0 - Batch 62 - Loss 0.9278597888492403 - Accuracy 0.6716270446777344\n",
      "Epoch 0 - Batch 63 - Loss 0.9272807035595179 - Accuracy 0.671630859375\n",
      "Epoch 0 - Batch 64 - Loss 0.9271864826862629 - Accuracy 0.6713942289352417\n",
      "Epoch 0 - Batch 65 - Loss 0.9255904031522346 - Accuracy 0.6721117496490479\n",
      "Epoch 0 - Batch 66 - Loss 0.9272615696067241 - Accuracy 0.671875\n",
      "Epoch 0 - Batch 67 - Loss 0.9265592326136196 - Accuracy 0.6725643277168274\n",
      "Epoch 0 - Batch 68 - Loss 0.9262782214344412 - Accuracy 0.6723279356956482\n",
      "Epoch 0 - Batch 69 - Loss 0.9255764118262699 - Accuracy 0.6733258962631226\n",
      "Epoch 0 - Batch 70 - Loss 0.9269212828555577 - Accuracy 0.6722050905227661\n",
      "Epoch 0 - Batch 71 - Loss 0.9260556548833847 - Accuracy 0.6726345419883728\n",
      "Epoch 0 - Batch 72 - Loss 0.9258710390900913 - Accuracy 0.6727311611175537\n",
      "Epoch 0 - Batch 73 - Loss 0.9252938676524807 - Accuracy 0.6731418967247009\n",
      "Epoch 0 - Batch 74 - Loss 0.9233787536621094 - Accuracy 0.6739583611488342\n",
      "Epoch 0 - Batch 75 - Loss 0.9209815028466677 - Accuracy 0.6751644611358643\n",
      "Epoch 0 - Batch 76 - Loss 0.9207373029225833 - Accuracy 0.6751217246055603\n",
      "Epoch 0 - Batch 77 - Loss 0.9226687390070695 - Accuracy 0.6749799847602844\n",
      "Epoch 0 - Batch 78 - Loss 0.9211862268327158 - Accuracy 0.6758307218551636\n",
      "Epoch 0 - Batch 79 - Loss 0.9220888085663319 - Accuracy 0.6756836175918579\n",
      "Epoch 0 - Batch 80 - Loss 0.9224376244309508 - Accuracy 0.6757330298423767\n",
      "Epoch 0 - Batch 81 - Loss 0.9247951660214401 - Accuracy 0.6748284697532654\n",
      "Epoch 0 - Batch 82 - Loss 0.9241806836013334 - Accuracy 0.6750752925872803\n",
      "Epoch 0 - Batch 83 - Loss 0.9233084697098959 - Accuracy 0.675967276096344\n",
      "Epoch 0 - Batch 84 - Loss 0.9222039552295909 - Accuracy 0.6767463088035583\n",
      "Epoch 0 - Batch 85 - Loss 0.9225883560125218 - Accuracy 0.6767805218696594\n",
      "Epoch 0 - Batch 86 - Loss 0.9234951508456263 - Accuracy 0.6762751340866089\n",
      "Epoch 0 - Batch 87 - Loss 0.9228427748788487 - Accuracy 0.6762251853942871\n",
      "Epoch 0 - Batch 88 - Loss 0.9224238697062718 - Accuracy 0.6759129166603088\n",
      "Epoch 0 - Batch 89 - Loss 0.9209593574206034 - Accuracy 0.6766493320465088\n",
      "Epoch 0 - Batch 90 - Loss 0.920203176173535 - Accuracy 0.6773695349693298\n",
      "Epoch 0 - Batch 91 - Loss 0.9185351055601368 - Accuracy 0.6778193116188049\n",
      "Epoch 0 - Batch 92 - Loss 0.9194000779941518 - Accuracy 0.6775873899459839\n",
      "Epoch 0 - Batch 93 - Loss 0.9185865172680389 - Accuracy 0.677942156791687\n",
      "Epoch 0 - Batch 94 - Loss 0.918783890573602 - Accuracy 0.6773849129676819\n",
      "Epoch 0 - Batch 95 - Loss 0.9192952190836271 - Accuracy 0.6773275136947632\n",
      "Epoch 0 - Batch 96 - Loss 0.919739223018135 - Accuracy 0.6770296096801758\n",
      "Epoch 0 - Batch 97 - Loss 0.919823015222744 - Accuracy 0.6768175959587097\n",
      "Epoch 0 - Batch 98 - Loss 0.920231226718787 - Accuracy 0.6768465638160706\n",
      "Epoch 0 - Batch 99 - Loss 0.9210348033905029 - Accuracy 0.676562488079071\n",
      "Epoch 0 - Batch 100 - Loss 0.9205320784361055 - Accuracy 0.6767481565475464\n",
      "Epoch 0 - Batch 101 - Loss 0.9203278515853134 - Accuracy 0.6767770051956177\n",
      "Epoch 0 - Batch 102 - Loss 0.9187617053105993 - Accuracy 0.6772603392601013\n",
      "Epoch 0 - Batch 103 - Loss 0.9189159480425028 - Accuracy 0.6774339079856873\n",
      "Epoch 0 - Batch 104 - Loss 0.919807725860959 - Accuracy 0.6772321462631226\n",
      "Epoch 0 - Batch 105 - Loss 0.9183798691011825 - Accuracy 0.6777712106704712\n",
      "Epoch 0 - Batch 106 - Loss 0.9176431688192849 - Accuracy 0.6785922646522522\n",
      "Epoch 0 - Batch 107 - Loss 0.9181605262888802 - Accuracy 0.6783130764961243\n",
      "Epoch 0 - Batch 108 - Loss 0.9173966602447929 - Accuracy 0.6786123514175415\n",
      "Epoch 0 - Batch 109 - Loss 0.9162741476839239 - Accuracy 0.679261326789856\n",
      "Epoch 0 - Batch 110 - Loss 0.915997973433486 - Accuracy 0.6789836883544922\n",
      "Epoch 0 - Batch 111 - Loss 0.916112633155925 - Accuracy 0.6789900064468384\n",
      "Epoch 0 - Batch 112 - Loss 0.915783959679899 - Accuracy 0.6791344285011292\n",
      "Epoch 0 - Batch 113 - Loss 0.914047275196042 - Accuracy 0.6796875\n",
      "Epoch 0 - Batch 114 - Loss 0.9143667713455532 - Accuracy 0.679619550704956\n",
      "Epoch 0 - Batch 115 - Loss 0.9133076801382262 - Accuracy 0.6800916194915771\n",
      "Epoch 0 - Batch 116 - Loss 0.9130036968451279 - Accuracy 0.6800881624221802\n",
      "Epoch 0 - Batch 117 - Loss 0.9128659322100171 - Accuracy 0.6798861026763916\n",
      "Epoch 0 - Batch 118 - Loss 0.9119768813878548 - Accuracy 0.6805409789085388\n",
      "Epoch 0 - Batch 119 - Loss 0.9103666370113691 - Accuracy 0.6811197996139526\n",
      "Epoch 0 - Batch 120 - Loss 0.9093479578160057 - Accuracy 0.6816890239715576\n",
      "Epoch 0 - Batch 121 - Loss 0.9091792560991694 - Accuracy 0.6820568442344666\n",
      "Epoch 0 - Batch 122 - Loss 0.9088178281861592 - Accuracy 0.6824186444282532\n",
      "Epoch 0 - Batch 123 - Loss 0.9082829654216766 - Accuracy 0.6827746629714966\n",
      "Epoch 0 - Batch 124 - Loss 0.9079661254882813 - Accuracy 0.6832500100135803\n",
      "Epoch 0 - Batch 125 - Loss 0.9062098785052224 - Accuracy 0.6839038133621216\n",
      "Epoch 0 - Batch 126 - Loss 0.905430565199514 - Accuracy 0.6843011975288391\n",
      "Epoch 0 - Batch 127 - Loss 0.9045239319093525 - Accuracy 0.68450927734375\n",
      "Epoch 0 - Batch 128 - Loss 0.904044554215069 - Accuracy 0.6847746968269348\n",
      "Epoch 0 - Batch 129 - Loss 0.9046040278214674 - Accuracy 0.6844350695610046\n",
      "Epoch 0 - Batch 130 - Loss 0.9036929889489677 - Accuracy 0.6847566962242126\n",
      "Epoch 0 - Batch 131 - Loss 0.9032986728530942 - Accuracy 0.6848958730697632\n",
      "Epoch 0 - Batch 132 - Loss 0.9010012790672761 - Accuracy 0.6856790781021118\n",
      "Epoch 0 - Batch 133 - Loss 0.9003701543630059 - Accuracy 0.6856926083564758\n",
      "Epoch 0 - Batch 134 - Loss 0.8987083011203342 - Accuracy 0.6860532164573669\n",
      "Epoch 0 - Batch 135 - Loss 0.8986354834016632 - Accuracy 0.6858915686607361\n",
      "Epoch 0 - Batch 136 - Loss 0.898110911358882 - Accuracy 0.6861313581466675\n",
      "Epoch 0 - Batch 137 - Loss 0.897821816413299 - Accuracy 0.6859714984893799\n",
      "Epoch 0 - Batch 138 - Loss 0.8989816994118176 - Accuracy 0.6854766607284546\n",
      "Epoch 0 - Batch 139 - Loss 0.8974405122654778 - Accuracy 0.6857700943946838\n",
      "Epoch 0 - Batch 140 - Loss 0.8971274233033472 - Accuracy 0.6860039830207825\n",
      "Epoch 0 - Batch 141 - Loss 0.8961773892523537 - Accuracy 0.6862345933914185\n",
      "Epoch 0 - Batch 142 - Loss 0.8959142707444571 - Accuracy 0.6864619851112366\n",
      "Epoch 0 - Batch 143 - Loss 0.8945674681001239 - Accuracy 0.6871744990348816\n",
      "Epoch 0 - Batch 144 - Loss 0.8943797843209629 - Accuracy 0.687446117401123\n",
      "Epoch 0 - Batch 145 - Loss 0.8945103471409784 - Accuracy 0.6873929500579834\n",
      "Epoch 0 - Batch 146 - Loss 0.8938944595200675 - Accuracy 0.6873405575752258\n",
      "Epoch 0 - Batch 147 - Loss 0.8930942283288853 - Accuracy 0.6877111792564392\n",
      "Epoch 0 - Batch 148 - Loss 0.8931142319768868 - Accuracy 0.6877097487449646\n",
      "Epoch 0 - Batch 149 - Loss 0.8924198253949484 - Accuracy 0.6877083778381348\n",
      "Epoch 0 - Batch 150 - Loss 0.8918479842855441 - Accuracy 0.6879656314849854\n",
      "Epoch 0 - Batch 151 - Loss 0.8905978296932421 - Accuracy 0.6883223652839661\n",
      "Epoch 0 - Batch 152 - Loss 0.8909843174460667 - Accuracy 0.688112735748291\n",
      "Epoch 0 - Batch 153 - Loss 0.8909312157661884 - Accuracy 0.6880072951316833\n",
      "Epoch 0 - Batch 154 - Loss 0.890934564990382 - Accuracy 0.6878527998924255\n",
      "Epoch 0 - Batch 155 - Loss 0.8908540358146032 - Accuracy 0.6877503991127014\n",
      "Epoch 0 - Batch 156 - Loss 0.8902172617092254 - Accuracy 0.6881468892097473\n",
      "Epoch 0 - Batch 157 - Loss 0.8895715656159799 - Accuracy 0.6883406043052673\n",
      "Epoch 0 - Batch 158 - Loss 0.8894475218634935 - Accuracy 0.6883352994918823\n",
      "Epoch 0 - Batch 159 - Loss 0.8887106955051423 - Accuracy 0.6883301138877869\n",
      "Epoch 0 - Batch 160 - Loss 0.8880646954412046 - Accuracy 0.6887131333351135\n",
      "Epoch 0 - Batch 161 - Loss 0.8873195846875509 - Accuracy 0.6889950037002563\n",
      "Epoch 0 - Batch 162 - Loss 0.8869000336875213 - Accuracy 0.6891295909881592\n",
      "Epoch 0 - Batch 163 - Loss 0.8858526149174062 - Accuracy 0.6894054412841797\n",
      "Epoch 0 - Batch 164 - Loss 0.884733424764691 - Accuracy 0.6897727251052856\n",
      "Epoch 0 - Batch 165 - Loss 0.8839508503316397 - Accuracy 0.6900884509086609\n",
      "Epoch 0 - Batch 166 - Loss 0.8837765769330327 - Accuracy 0.6901198029518127\n",
      "Epoch 0 - Batch 167 - Loss 0.8837396786326454 - Accuracy 0.690011203289032\n",
      "Epoch 0 - Batch 168 - Loss 0.8833722394599012 - Accuracy 0.6900887489318848\n",
      "Epoch 0 - Batch 169 - Loss 0.8833580167854533 - Accuracy 0.6901654601097107\n",
      "Epoch 0 - Batch 170 - Loss 0.8834087360672086 - Accuracy 0.6899214386940002\n",
      "Epoch 0 - Batch 171 - Loss 0.8824247461418773 - Accuracy 0.6901798844337463\n",
      "Epoch 0 - Batch 172 - Loss 0.8819243797677101 - Accuracy 0.6900289058685303\n",
      "Epoch 0 - Batch 173 - Loss 0.8813381671220407 - Accuracy 0.6903286576271057\n",
      "Epoch 0 - Batch 174 - Loss 0.8807953984396798 - Accuracy 0.690625011920929\n",
      "Epoch 0 - Batch 175 - Loss 0.8808863318779252 - Accuracy 0.6903409361839294\n",
      "Epoch 0 - Batch 176 - Loss 0.8799528139459212 - Accuracy 0.6905896663665771\n",
      "Epoch 0 - Batch 177 - Loss 0.8791565489902925 - Accuracy 0.6909234523773193\n",
      "Epoch 0 - Batch 178 - Loss 0.8794513331445236 - Accuracy 0.6908606886863708\n",
      "Epoch 0 - Batch 179 - Loss 0.8788206395175722 - Accuracy 0.6911024451255798\n",
      "Epoch 0 - Batch 180 - Loss 0.8774840354260819 - Accuracy 0.6916436553001404\n",
      "Epoch 0 - Batch 181 - Loss 0.8768361515396244 - Accuracy 0.6920501589775085\n",
      "Epoch 0 - Batch 182 - Loss 0.8752559299677447 - Accuracy 0.6929217576980591\n",
      "Epoch 0 - Batch 183 - Loss 0.8753915315736895 - Accuracy 0.692722499370575\n",
      "Epoch 0 - Batch 184 - Loss 0.8749643490121172 - Accuracy 0.6928631663322449\n",
      "Epoch 0 - Batch 185 - Loss 0.8739247588060235 - Accuracy 0.6930863857269287\n",
      "Epoch 0 - Batch 186 - Loss 0.8727996897569952 - Accuracy 0.6935160756111145\n",
      "Epoch 0 - Batch 187 - Loss 0.8725741901930343 - Accuracy 0.6934009194374084\n",
      "Epoch 0 - Batch 188 - Loss 0.8721263112214507 - Accuracy 0.6934937238693237\n",
      "Epoch 0 - Batch 189 - Loss 0.8714992774160285 - Accuracy 0.6937500238418579\n",
      "Epoch 0 - Batch 190 - Loss 0.871143637527346 - Accuracy 0.693839967250824\n",
      "Epoch 0 - Batch 191 - Loss 0.871147054557999 - Accuracy 0.6936442255973816\n",
      "Epoch 0 - Batch 192 - Loss 0.8698493881546772 - Accuracy 0.6940576434135437\n",
      "Epoch 0 - Batch 193 - Loss 0.8706853589446274 - Accuracy 0.6940640807151794\n",
      "Epoch 0 - Batch 194 - Loss 0.8702464504119677 - Accuracy 0.6940705180168152\n",
      "Epoch 0 - Batch 195 - Loss 0.86934467815623 - Accuracy 0.6943159699440002\n",
      "Epoch 0 - Batch 196 - Loss 0.868860582712338 - Accuracy 0.6942417621612549\n",
      "Epoch 0 - Batch 197 - Loss 0.8688064515590668 - Accuracy 0.6941682696342468\n",
      "Epoch 0 - Batch 198 - Loss 0.86848393546876 - Accuracy 0.6942524909973145\n",
      "Epoch 0 - Batch 199 - Loss 0.8685554665327072 - Accuracy 0.6944531202316284\n",
      "Epoch 0 - Batch 200 - Loss 0.8685566326278952 - Accuracy 0.6947683095932007\n",
      "Epoch 0 - Batch 201 - Loss 0.8677222486769799 - Accuracy 0.6952351331710815\n",
      "Epoch 0 - Batch 202 - Loss 0.8674628021094599 - Accuracy 0.6953125\n",
      "Epoch 0 - Batch 203 - Loss 0.8673364368139529 - Accuracy 0.6955422759056091\n",
      "Epoch 0 - Batch 204 - Loss 0.8668458583878308 - Accuracy 0.6957698464393616\n",
      "Epoch 0 - Batch 205 - Loss 0.8665067423315882 - Accuracy 0.6958434581756592\n",
      "Epoch 0 - Batch 206 - Loss 0.8661938015965448 - Accuracy 0.695652186870575\n",
      "Epoch 0 - Batch 207 - Loss 0.8658078072162775 - Accuracy 0.6957632303237915\n",
      "Epoch 0 - Batch 208 - Loss 0.8657655396529932 - Accuracy 0.6959105730056763\n",
      "Epoch 0 - Batch 209 - Loss 0.8660296266987211 - Accuracy 0.6956101655960083\n",
      "Epoch 0 - Batch 210 - Loss 0.8658349869940518 - Accuracy 0.6956827640533447\n",
      "Epoch 0 - Batch 211 - Loss 0.866258220571392 - Accuracy 0.6956073045730591\n",
      "Epoch 0 - Batch 212 - Loss 0.8662866460325572 - Accuracy 0.6956059336662292\n",
      "Epoch 0 - Batch 213 - Loss 0.8657099490410813 - Accuracy 0.6957870721817017\n",
      "Epoch 0 - Batch 214 - Loss 0.8661437322927076 - Accuracy 0.6956758499145508\n",
      "Epoch 0 - Batch 215 - Loss 0.8654014705507843 - Accuracy 0.6960358619689941\n",
      "Epoch 0 - Batch 216 - Loss 0.8650907679087555 - Accuracy 0.6961405277252197\n",
      "Epoch 0 - Batch 217 - Loss 0.8652131582072021 - Accuracy 0.6962442398071289\n",
      "Epoch 0 - Batch 218 - Loss 0.8643898367881775 - Accuracy 0.6965967416763306\n",
      "Epoch 0 - Batch 219 - Loss 0.8643322402780707 - Accuracy 0.6967329382896423\n",
      "Epoch 0 - Batch 220 - Loss 0.8640215974048252 - Accuracy 0.696620523929596\n",
      "Epoch 0 - Batch 221 - Loss 0.8636737535665701 - Accuracy 0.6967905759811401\n",
      "Epoch 0 - Batch 222 - Loss 0.8639041417917328 - Accuracy 0.6966788172721863\n",
      "Epoch 0 - Batch 223 - Loss 0.8636339439877442 - Accuracy 0.696847140789032\n",
      "Epoch 0 - Batch 224 - Loss 0.863532817363739 - Accuracy 0.6968402862548828\n",
      "Epoch 0 - Batch 225 - Loss 0.8631181160433102 - Accuracy 0.6969717741012573\n",
      "Epoch 0 - Batch 226 - Loss 0.8624397768323117 - Accuracy 0.6972742080688477\n",
      "Epoch 0 - Batch 227 - Loss 0.8627404813703737 - Accuracy 0.6971970796585083\n",
      "Epoch 0 - Batch 228 - Loss 0.8623413857414213 - Accuracy 0.6971206665039062\n",
      "Epoch 0 - Batch 229 - Loss 0.8614690516306006 - Accuracy 0.6973844766616821\n",
      "Epoch 0 - Batch 230 - Loss 0.8606212350713226 - Accuracy 0.697578489780426\n",
      "Epoch 0 - Batch 231 - Loss 0.8601616441175856 - Accuracy 0.6977370381355286\n",
      "Epoch 0 - Batch 232 - Loss 0.8592491047576774 - Accuracy 0.6980955004692078\n",
      "Epoch 0 - Batch 233 - Loss 0.8586286347136538 - Accuracy 0.698350727558136\n",
      "Epoch 0 - Batch 234 - Loss 0.8578071360892437 - Accuracy 0.6984707117080688\n",
      "Epoch 0 - Batch 235 - Loss 0.8576829448594885 - Accuracy 0.6984904408454895\n",
      "Epoch 0 - Batch 236 - Loss 0.8567676463710607 - Accuracy 0.698806643486023\n",
      "Epoch 0 - Batch 237 - Loss 0.85608499666222 - Accuracy 0.6989561915397644\n",
      "Epoch 0 - Batch 238 - Loss 0.8558325675242117 - Accuracy 0.6992023587226868\n",
      "Epoch 0 - Batch 239 - Loss 0.8555933189888795 - Accuracy 0.6991536617279053\n",
      "Epoch 0 - Batch 240 - Loss 0.8557069820981797 - Accuracy 0.6989432573318481\n",
      "Epoch 0 - Batch 241 - Loss 0.8554915766085475 - Accuracy 0.6989927291870117\n",
      "Epoch 0 - Batch 242 - Loss 0.854728872638671 - Accuracy 0.6991705298423767\n",
      "Epoch 0 - Batch 243 - Loss 0.8547391683840361 - Accuracy 0.6990265846252441\n",
      "Epoch 0 - Batch 244 - Loss 0.8539797208747085 - Accuracy 0.6993303298950195\n",
      "Epoch 0 - Batch 245 - Loss 0.8535570778497835 - Accuracy 0.6995363235473633\n",
      "Epoch 0 - Batch 246 - Loss 0.8532974929944707 - Accuracy 0.699772298336029\n",
      "Epoch 0 - Batch 247 - Loss 0.8532428873642799 - Accuracy 0.6997227668762207\n",
      "Epoch 0 - Batch 248 - Loss 0.8526413792587189 - Accuracy 0.6999874114990234\n",
      "Epoch 0 - Batch 249 - Loss 0.8524680192470551 - Accuracy 0.6999687552452087\n",
      "Epoch 0 - Batch 250 - Loss 0.8525998737232618 - Accuracy 0.6998568177223206\n",
      "Epoch 0 - Batch 251 - Loss 0.8523546558996987 - Accuracy 0.6999008059501648\n",
      "Epoch 0 - Batch 252 - Loss 0.8522183063473154 - Accuracy 0.700067937374115\n",
      "Epoch 0 - Batch 253 - Loss 0.8521149092771876 - Accuracy 0.7000799775123596\n",
      "Epoch 0 - Batch 254 - Loss 0.8519482554173937 - Accuracy 0.7002757787704468\n",
      "Epoch 0 - Batch 255 - Loss 0.8516821288503706 - Accuracy 0.70025634765625\n",
      "Epoch 0 - Batch 256 - Loss 0.8518250932489387 - Accuracy 0.7002978920936584\n",
      "Epoch 0 - Batch 257 - Loss 0.8515003801778306 - Accuracy 0.7003694176673889\n",
      "Epoch 0 - Batch 258 - Loss 0.8511489703388287 - Accuracy 0.7005912065505981\n",
      "Epoch 0 - Batch 259 - Loss 0.8507934134740096 - Accuracy 0.7007511854171753\n",
      "Epoch 0 - Batch 260 - Loss 0.8509354623341469 - Accuracy 0.7005507349967957\n",
      "Epoch 0 - Batch 261 - Loss 0.8511962035230098 - Accuracy 0.7003518342971802\n",
      "Epoch 0 - Batch 262 - Loss 0.8515278425053499 - Accuracy 0.7003030180931091\n",
      "Epoch 0 - Batch 263 - Loss 0.8510552511522265 - Accuracy 0.7004024982452393\n",
      "Epoch 0 - Batch 264 - Loss 0.8508980339428164 - Accuracy 0.7004422545433044\n",
      "Epoch 0 - Batch 265 - Loss 0.851180558814142 - Accuracy 0.700393557548523\n",
      "Epoch 0 - Batch 266 - Loss 0.8503153835343065 - Accuracy 0.7008134722709656\n",
      "Epoch 0 - Batch 267 - Loss 0.8498464858354028 - Accuracy 0.7008220553398132\n",
      "Epoch 0 - Batch 268 - Loss 0.8501605883406884 - Accuracy 0.7005982995033264\n",
      "Epoch 0 - Batch 269 - Loss 0.8500387516286638 - Accuracy 0.7006075978279114\n",
      "Epoch 0 - Batch 270 - Loss 0.8497511221034061 - Accuracy 0.7007322311401367\n",
      "Epoch 0 - Batch 271 - Loss 0.8497334646389765 - Accuracy 0.7007697820663452\n",
      "Epoch 0 - Batch 272 - Loss 0.8494626528177506 - Accuracy 0.7008642554283142\n",
      "Epoch 0 - Batch 273 - Loss 0.8496929840014799 - Accuracy 0.7008439898490906\n",
      "Epoch 0 - Batch 274 - Loss 0.8496139394153248 - Accuracy 0.7009943127632141\n",
      "Epoch 0 - Batch 275 - Loss 0.8496035903260328 - Accuracy 0.7009454369544983\n",
      "Epoch 0 - Batch 276 - Loss 0.8490495468735264 - Accuracy 0.7009814977645874\n",
      "Epoch 0 - Batch 277 - Loss 0.848531647980642 - Accuracy 0.7011578679084778\n",
      "Epoch 0 - Batch 278 - Loss 0.8486643544661956 - Accuracy 0.701080858707428\n",
      "Epoch 0 - Batch 279 - Loss 0.8486646398901939 - Accuracy 0.7011160850524902\n",
      "Epoch 0 - Batch 280 - Loss 0.8484379549467691 - Accuracy 0.7011788487434387\n",
      "Epoch 0 - Batch 281 - Loss 0.8482247504359441 - Accuracy 0.701241135597229\n",
      "Epoch 0 - Batch 282 - Loss 0.8481291913733465 - Accuracy 0.7012478113174438\n",
      "Epoch 0 - Batch 283 - Loss 0.847720227191146 - Accuracy 0.7014469504356384\n",
      "Epoch 0 - Batch 284 - Loss 0.8476702409878112 - Accuracy 0.7015351057052612\n",
      "Epoch 0 - Batch 285 - Loss 0.8470880407970268 - Accuracy 0.701786458492279\n",
      "Epoch 0 - Batch 286 - Loss 0.8471092170539218 - Accuracy 0.7016822695732117\n",
      "Epoch 0 - Batch 287 - Loss 0.8468058943334553 - Accuracy 0.701768696308136\n",
      "Epoch 0 - Batch 288 - Loss 0.8468925301178929 - Accuracy 0.7018004059791565\n",
      "Epoch 0 - Batch 289 - Loss 0.8466152347367385 - Accuracy 0.7020204663276672\n",
      "Epoch 0 - Batch 290 - Loss 0.8468440658448079 - Accuracy 0.7018900513648987\n",
      "Epoch 0 - Batch 291 - Loss 0.8469137773938376 - Accuracy 0.701760470867157\n",
      "Epoch 0 - Batch 292 - Loss 0.8464747032614698 - Accuracy 0.7019250988960266\n",
      "Epoch 0 - Batch 293 - Loss 0.8461305148342029 - Accuracy 0.7020886540412903\n",
      "Epoch 0 - Batch 294 - Loss 0.8464435399588892 - Accuracy 0.7019597291946411\n",
      "Epoch 0 - Batch 295 - Loss 0.8460067438112723 - Accuracy 0.7021220326423645\n",
      "Epoch 0 - Batch 296 - Loss 0.8460526751348065 - Accuracy 0.7020201683044434\n",
      "Epoch 0 - Batch 297 - Loss 0.8458182573718512 - Accuracy 0.7021812200546265\n",
      "Epoch 0 - Batch 298 - Loss 0.8452037889821872 - Accuracy 0.7023411393165588\n",
      "Epoch 0 - Batch 299 - Loss 0.8450080541769663 - Accuracy 0.7023958563804626\n",
      "Epoch 0 - Batch 300 - Loss 0.8444511306246254 - Accuracy 0.702579915523529\n",
      "Epoch 0 - Batch 301 - Loss 0.8442344633948724 - Accuracy 0.7026852369308472\n",
      "Epoch 0 - Batch 302 - Loss 0.8438005075596346 - Accuracy 0.7028672099113464\n",
      "Epoch 0 - Batch 303 - Loss 0.842976571305802 - Accuracy 0.7030479311943054\n",
      "Epoch 0 - Batch 304 - Loss 0.8424483408693407 - Accuracy 0.7032018303871155\n",
      "Epoch 0 - Batch 305 - Loss 0.8423089525278877 - Accuracy 0.7032526731491089\n",
      "Epoch 0 - Batch 306 - Loss 0.8418867188090222 - Accuracy 0.703354001045227\n",
      "Epoch 0 - Batch 307 - Loss 0.8420467930180686 - Accuracy 0.7034040093421936\n",
      "Epoch 0 - Batch 308 - Loss 0.8419477206603608 - Accuracy 0.7034284472465515\n",
      "Epoch 0 - Batch 309 - Loss 0.8417857195100477 - Accuracy 0.7033517956733704\n",
      "Epoch 0 - Batch 310 - Loss 0.8422739385025294 - Accuracy 0.7030496001243591\n",
      "Epoch 0 - Batch 311 - Loss 0.8422224208330497 - Accuracy 0.7030999660491943\n",
      "Epoch 0 - Batch 312 - Loss 0.8415042797978313 - Accuracy 0.7033745646476746\n",
      "Epoch 0 - Batch 313 - Loss 0.8411239440653734 - Accuracy 0.7033737897872925\n",
      "Epoch 0 - Batch 314 - Loss 0.8409478448686145 - Accuracy 0.703397810459137\n",
      "Epoch 0 - Batch 315 - Loss 0.8409206870990463 - Accuracy 0.7034711241722107\n",
      "Epoch 0 - Batch 316 - Loss 0.8408970432326621 - Accuracy 0.7035439610481262\n",
      "Epoch 0 - Batch 317 - Loss 0.8408317080458755 - Accuracy 0.7035917639732361\n",
      "Epoch 0 - Batch 318 - Loss 0.8404187167699808 - Accuracy 0.7037372589111328\n",
      "Epoch 0 - Batch 319 - Loss 0.8406099274754524 - Accuracy 0.703662097454071\n",
      "Epoch 0 - Batch 320 - Loss 0.840564936492302 - Accuracy 0.7036847472190857\n",
      "Epoch 0 - Batch 321 - Loss 0.8400669877203355 - Accuracy 0.7039984464645386\n",
      "Epoch 0 - Batch 322 - Loss 0.8399903938497183 - Accuracy 0.7040199041366577\n",
      "Epoch 0 - Batch 323 - Loss 0.8394248159947219 - Accuracy 0.7041377425193787\n",
      "Epoch 0 - Batch 324 - Loss 0.8396940207481385 - Accuracy 0.7040625214576721\n",
      "Epoch 0 - Batch 325 - Loss 0.8390240031151683 - Accuracy 0.7042273879051208\n",
      "Epoch 0 - Batch 326 - Loss 0.8390526080714817 - Accuracy 0.7042717933654785\n",
      "Epoch 0 - Batch 327 - Loss 0.8390417089912949 - Accuracy 0.7043397426605225\n",
      "Epoch 0 - Batch 328 - Loss 0.8389324011411348 - Accuracy 0.704407274723053\n",
      "Epoch 0 - Batch 329 - Loss 0.8386521904757529 - Accuracy 0.7045691013336182\n",
      "Epoch 0 - Batch 330 - Loss 0.8376355475529443 - Accuracy 0.7050132155418396\n",
      "Epoch 0 - Batch 331 - Loss 0.8372827739600676 - Accuracy 0.7052663564682007\n",
      "Epoch 0 - Batch 332 - Loss 0.8376801126712078 - Accuracy 0.7050253748893738\n",
      "Epoch 0 - Batch 333 - Loss 0.83716548702674 - Accuracy 0.7051132321357727\n",
      "Epoch 0 - Batch 334 - Loss 0.8365334098018817 - Accuracy 0.7053171992301941\n",
      "Epoch 0 - Batch 335 - Loss 0.8369276115582103 - Accuracy 0.7052176594734192\n",
      "Epoch 0 - Batch 336 - Loss 0.8365267853001105 - Accuracy 0.7053505182266235\n",
      "Epoch 0 - Batch 337 - Loss 0.836193244309115 - Accuracy 0.7055751085281372\n",
      "Epoch 0 - Batch 338 - Loss 0.8360607110645215 - Accuracy 0.7056369781494141\n",
      "Epoch 0 - Batch 339 - Loss 0.8362026922843036 - Accuracy 0.7056066393852234\n",
      "Epoch 0 - Batch 340 - Loss 0.8357918033501969 - Accuracy 0.7057368159294128\n",
      "Epoch 0 - Batch 341 - Loss 0.8353557759209683 - Accuracy 0.705889105796814\n",
      "Epoch 0 - Batch 342 - Loss 0.8354258791003213 - Accuracy 0.7058126926422119\n",
      "Epoch 0 - Batch 343 - Loss 0.8352337623404902 - Accuracy 0.7058503031730652\n",
      "Epoch 0 - Batch 344 - Loss 0.8350059704504151 - Accuracy 0.7060235738754272\n",
      "Epoch 0 - Batch 345 - Loss 0.8348546860190486 - Accuracy 0.7061732411384583\n",
      "Epoch 0 - Batch 346 - Loss 0.834364061396816 - Accuracy 0.7063670754432678\n",
      "Epoch 0 - Batch 347 - Loss 0.8341574501032116 - Accuracy 0.7064475417137146\n",
      "Epoch 0 - Batch 348 - Loss 0.8340044547630244 - Accuracy 0.7064380645751953\n",
      "Epoch 0 - Batch 349 - Loss 0.8339047050476074 - Accuracy 0.7065625190734863\n",
      "Epoch 0 - Batch 350 - Loss 0.8340049793577602 - Accuracy 0.7065081596374512\n",
      "Epoch 0 - Batch 351 - Loss 0.8337372680279341 - Accuracy 0.7065873742103577\n",
      "Epoch 0 - Batch 352 - Loss 0.8331673263490369 - Accuracy 0.7068652510643005\n",
      "Epoch 0 - Batch 353 - Loss 0.8329837467037352 - Accuracy 0.7068547010421753\n",
      "Epoch 0 - Batch 354 - Loss 0.8323849087030115 - Accuracy 0.7070422172546387\n",
      "Epoch 0 - Batch 355 - Loss 0.8324066792311293 - Accuracy 0.7068337798118591\n",
      "Epoch 0 - Batch 356 - Loss 0.8318915380483248 - Accuracy 0.7069765329360962\n",
      "Epoch 0 - Batch 357 - Loss 0.8316143731165199 - Accuracy 0.7070748805999756\n",
      "Epoch 0 - Batch 358 - Loss 0.8313332513846394 - Accuracy 0.707150936126709\n",
      "Epoch 0 - Batch 359 - Loss 0.8313233580854203 - Accuracy 0.7072699666023254\n",
      "Epoch 0 - Batch 360 - Loss 0.8307439235769151 - Accuracy 0.7075397968292236\n",
      "Epoch 0 - Batch 361 - Loss 0.8308547226434254 - Accuracy 0.7075492143630981\n",
      "Epoch 0 - Batch 362 - Loss 0.8307902197207301 - Accuracy 0.7075800895690918\n",
      "Epoch 0 - Batch 363 - Loss 0.8309401304839732 - Accuracy 0.7074819803237915\n",
      "Epoch 0 - Batch 364 - Loss 0.8308608247809214 - Accuracy 0.7074700593948364\n",
      "Epoch 0 - Batch 365 - Loss 0.8305039814586848 - Accuracy 0.7075008153915405\n",
      "Epoch 0 - Batch 366 - Loss 0.830420025200545 - Accuracy 0.707510232925415\n",
      "Epoch 0 - Batch 367 - Loss 0.8303916091504304 - Accuracy 0.70754075050354\n",
      "Epoch 0 - Batch 368 - Loss 0.8300601730178688 - Accuracy 0.7076981663703918\n",
      "Epoch 0 - Batch 369 - Loss 0.8297294284846332 - Accuracy 0.7078758478164673\n",
      "Epoch 0 - Batch 370 - Loss 0.8296369987356695 - Accuracy 0.7078840732574463\n",
      "Epoch 0 - Batch 371 - Loss 0.8289521310919075 - Accuracy 0.7081233263015747\n",
      "Epoch 0 - Batch 372 - Loss 0.828882854361956 - Accuracy 0.7082146406173706\n",
      "Epoch 0 - Batch 373 - Loss 0.8287245549938895 - Accuracy 0.7081801891326904\n",
      "Epoch 0 - Batch 374 - Loss 0.8284017604192098 - Accuracy 0.7082499861717224\n",
      "Epoch 0 - Batch 375 - Loss 0.8288651818924762 - Accuracy 0.7080493569374084\n",
      "Epoch 0 - Batch 376 - Loss 0.8286863366235788 - Accuracy 0.7082228064537048\n",
      "Epoch 0 - Batch 377 - Loss 0.8280644664373348 - Accuracy 0.7084572911262512\n",
      "Epoch 0 - Batch 378 - Loss 0.827395334092797 - Accuracy 0.7087525129318237\n",
      "Epoch 0 - Batch 379 - Loss 0.8271456567864669 - Accuracy 0.7089021801948547\n",
      "Epoch 0 - Batch 380 - Loss 0.8269862272920884 - Accuracy 0.7090305089950562\n",
      "Epoch 0 - Batch 381 - Loss 0.8264078282560977 - Accuracy 0.7092195749282837\n",
      "Epoch 0 - Batch 382 - Loss 0.8258596501524703 - Accuracy 0.7094484567642212\n",
      "Epoch 0 - Batch 383 - Loss 0.8251408310607076 - Accuracy 0.70965576171875\n",
      "Epoch 0 - Batch 384 - Loss 0.8245303539486675 - Accuracy 0.7098823189735413\n",
      "Epoch 0 - Batch 385 - Loss 0.8245931883858894 - Accuracy 0.7098850011825562\n",
      "Epoch 0 - Batch 386 - Loss 0.8242728514572755 - Accuracy 0.7100290656089783\n",
      "Epoch 0 - Batch 387 - Loss 0.8241027911606523 - Accuracy 0.710091769695282\n",
      "Epoch 0 - Batch 388 - Loss 0.8237203569522553 - Accuracy 0.7102345824241638\n",
      "Epoch 0 - Batch 389 - Loss 0.8231679439544678 - Accuracy 0.7103966474533081\n",
      "Epoch 0 - Batch 390 - Loss 0.822787801170593 - Accuracy 0.7105618119239807\n",
      "Epoch 0 - Loss 0.822787801170593 - Accuracy 0.7105618119239807\n",
      "Testing...\n",
      "Epoch 0 - Batch 0 - Loss 0.7823761701583862 - Accuracy 0.75\n",
      "Epoch 0 - Batch 1 - Loss 0.8792810440063477 - Accuracy 0.71484375\n",
      "Epoch 0 - Batch 2 - Loss 0.867143710454305 - Accuracy 0.7109375\n",
      "Epoch 0 - Batch 3 - Loss 0.8770053535699844 - Accuracy 0.701171875\n",
      "Epoch 0 - Batch 4 - Loss 0.840397584438324 - Accuracy 0.706250011920929\n",
      "Epoch 0 - Batch 5 - Loss 0.8753154575824738 - Accuracy 0.6888021230697632\n",
      "Epoch 0 - Batch 6 - Loss 0.8760637385504586 - Accuracy 0.6908482313156128\n",
      "Epoch 0 - Batch 7 - Loss 0.8562890589237213 - Accuracy 0.6982421875\n",
      "Epoch 0 - Batch 8 - Loss 0.8553482823901706 - Accuracy 0.6970486044883728\n",
      "Epoch 0 - Batch 9 - Loss 0.8521474957466125 - Accuracy 0.6968750357627869\n",
      "Epoch 0 - Batch 10 - Loss 0.851516685702584 - Accuracy 0.6960227489471436\n",
      "Epoch 0 - Batch 11 - Loss 0.8455774933099747 - Accuracy 0.6966146230697632\n",
      "Epoch 0 - Batch 12 - Loss 0.8473492448146527 - Accuracy 0.6947115659713745\n",
      "Epoch 0 - Batch 13 - Loss 0.8498205712863377 - Accuracy 0.6930803656578064\n",
      "Epoch 0 - Batch 14 - Loss 0.8543689489364624 - Accuracy 0.6953125596046448\n",
      "Epoch 0 - Batch 15 - Loss 0.8600233159959316 - Accuracy 0.6943359375\n",
      "Epoch 0 - Batch 16 - Loss 0.8583959796849419 - Accuracy 0.6943933963775635\n",
      "Epoch 0 - Batch 17 - Loss 0.8609211279286278 - Accuracy 0.6931423544883728\n",
      "Epoch 0 - Batch 18 - Loss 0.8604604539118315 - Accuracy 0.6949013471603394\n",
      "Epoch 0 - Batch 19 - Loss 0.8675078719854354 - Accuracy 0.6929687857627869\n",
      "Epoch 0 - Batch 20 - Loss 0.8666425801458812 - Accuracy 0.6927083730697632\n",
      "Epoch 0 - Batch 21 - Loss 0.8709654184904966 - Accuracy 0.6903409361839294\n",
      "Epoch 0 - Batch 22 - Loss 0.8683322357094806 - Accuracy 0.692255437374115\n",
      "Epoch 0 - Batch 23 - Loss 0.8669028257330259 - Accuracy 0.6940104365348816\n",
      "Epoch 0 - Batch 24 - Loss 0.864707727432251 - Accuracy 0.692187488079071\n",
      "Epoch 0 - Batch 25 - Loss 0.8679001468878526 - Accuracy 0.692307710647583\n",
      "Epoch 0 - Batch 26 - Loss 0.8686054812537299 - Accuracy 0.6912615895271301\n",
      "Epoch 0 - Batch 27 - Loss 0.8624380614076342 - Accuracy 0.6947544813156128\n",
      "Epoch 0 - Batch 28 - Loss 0.8643761667711981 - Accuracy 0.6942349076271057\n",
      "Epoch 0 - Batch 29 - Loss 0.8625917732715607 - Accuracy 0.6950521469116211\n",
      "Epoch 0 - Batch 30 - Loss 0.8569798584907286 - Accuracy 0.6955645084381104\n",
      "Epoch 0 - Batch 31 - Loss 0.8553292881697416 - Accuracy 0.697021484375\n",
      "Epoch 0 - Batch 32 - Loss 0.8542887153047504 - Accuracy 0.698863685131073\n",
      "Epoch 0 - Batch 33 - Loss 0.8504068851470947 - Accuracy 0.6996783018112183\n",
      "Epoch 0 - Batch 34 - Loss 0.8477856976645334 - Accuracy 0.699999988079071\n",
      "Epoch 0 - Batch 35 - Loss 0.8470597167809805 - Accuracy 0.7007378339767456\n",
      "Epoch 0 - Batch 36 - Loss 0.8451596595145561 - Accuracy 0.7018581032752991\n",
      "Epoch 0 - Batch 37 - Loss 0.8430722340157157 - Accuracy 0.7023026347160339\n",
      "Epoch 0 - Batch 38 - Loss 0.8418490779705536 - Accuracy 0.7025240659713745\n",
      "Epoch 0 - Batch 39 - Loss 0.8397644773125649 - Accuracy 0.703125\n",
      "Epoch 0 - Batch 40 - Loss 0.8411613397481965 - Accuracy 0.7029344439506531\n",
      "Epoch 0 - Batch 41 - Loss 0.8398933297111875 - Accuracy 0.7027530074119568\n",
      "Epoch 0 - Batch 42 - Loss 0.8383664253146149 - Accuracy 0.7027616500854492\n",
      "Epoch 0 - Batch 43 - Loss 0.839241699738936 - Accuracy 0.7036576867103577\n",
      "Epoch 0 - Batch 44 - Loss 0.8363421797752381 - Accuracy 0.7041667103767395\n",
      "Epoch 0 - Batch 45 - Loss 0.8351194910381151 - Accuracy 0.704483687877655\n",
      "Epoch 0 - Batch 46 - Loss 0.837498943856422 - Accuracy 0.7034574151039124\n",
      "Epoch 0 - Batch 47 - Loss 0.8363366238772869 - Accuracy 0.7029622793197632\n",
      "Epoch 0 - Batch 48 - Loss 0.8341924085909006 - Accuracy 0.7028061151504517\n",
      "Epoch 0 - Batch 49 - Loss 0.8327188885211945 - Accuracy 0.703906238079071\n",
      "Epoch 0 - Batch 50 - Loss 0.8337855070245033 - Accuracy 0.7038909792900085\n",
      "Epoch 0 - Batch 51 - Loss 0.8318971613278756 - Accuracy 0.704026460647583\n",
      "Epoch 0 - Batch 52 - Loss 0.833356038579401 - Accuracy 0.7034198045730591\n",
      "Epoch 0 - Batch 53 - Loss 0.8364546365208096 - Accuracy 0.703125\n",
      "Epoch 0 - Batch 54 - Loss 0.8404531023719094 - Accuracy 0.7018465399742126\n",
      "Epoch 0 - Batch 55 - Loss 0.840308852493763 - Accuracy 0.7015904188156128\n",
      "Epoch 0 - Batch 56 - Loss 0.8403173570047345 - Accuracy 0.7013431787490845\n",
      "Epoch 0 - Batch 57 - Loss 0.8390529505137739 - Accuracy 0.7023168206214905\n",
      "Epoch 0 - Batch 58 - Loss 0.8380616479000803 - Accuracy 0.7025953531265259\n",
      "Epoch 0 - Batch 59 - Loss 0.8390008052190144 - Accuracy 0.7019531726837158\n",
      "Epoch 0 - Batch 60 - Loss 0.8379825851956352 - Accuracy 0.7019723057746887\n",
      "Epoch 0 - Batch 61 - Loss 0.840562681997976 - Accuracy 0.7018648982048035\n",
      "Epoch 0 - Batch 62 - Loss 0.8417798583469693 - Accuracy 0.701388955116272\n",
      "Epoch 0 - Batch 63 - Loss 0.842894115485251 - Accuracy 0.700927734375\n",
      "Epoch 0 - Batch 64 - Loss 0.8446621858156644 - Accuracy 0.7006009817123413\n",
      "Epoch 0 - Batch 65 - Loss 0.8444861534870032 - Accuracy 0.7004024982452393\n",
      "Epoch 0 - Batch 66 - Loss 0.844970897062501 - Accuracy 0.7004430890083313\n",
      "Epoch 0 - Batch 67 - Loss 0.8449510318391463 - Accuracy 0.7002527713775635\n",
      "Epoch 0 - Batch 68 - Loss 0.8448191855264746 - Accuracy 0.7001811861991882\n",
      "Epoch 0 - Batch 69 - Loss 0.8443760641983578 - Accuracy 0.7003348469734192\n",
      "Epoch 0 - Batch 70 - Loss 0.845439891580125 - Accuracy 0.7002640962600708\n",
      "Epoch 0 - Batch 71 - Loss 0.8420237973332405 - Accuracy 0.7014973759651184\n",
      "Epoch 0 - Batch 72 - Loss 0.8418019797703992 - Accuracy 0.7017337083816528\n",
      "Epoch 0 - Batch 73 - Loss 0.8419755979164226 - Accuracy 0.7018581032752991\n",
      "Epoch 0 - Batch 74 - Loss 0.8400268228848775 - Accuracy 0.70250004529953\n",
      "Epoch 0 - Batch 75 - Loss 0.83761754083006 - Accuracy 0.7032278180122375\n",
      "Epoch 0 - Batch 76 - Loss 0.8396540299638525 - Accuracy 0.7021104097366333\n",
      "Epoch 0 - Batch 77 - Loss 0.8403153534118946 - Accuracy 0.7017227411270142\n",
      "Epoch 0 - Batch 78 - Loss 0.8347018753425984 - Accuracy 0.703125\n",
      "Epoch 0 - Loss 0.8347018753425984 - Accuracy 0.703125\n",
      "Training...\n",
      "Epoch 1 - Batch 0 - Loss 0.9997710585594177 - Accuracy 0.640625\n",
      "Epoch 1 - Batch 1 - Loss 0.9794760942459106 - Accuracy 0.69140625\n",
      "Epoch 1 - Batch 2 - Loss 1.0172277688980103 - Accuracy 0.6979166865348816\n",
      "Epoch 1 - Batch 3 - Loss 1.092845231294632 - Accuracy 0.67578125\n",
      "Epoch 1 - Batch 4 - Loss 1.0487492680549622 - Accuracy 0.682812511920929\n",
      "Epoch 1 - Batch 5 - Loss 1.0744456152121227 - Accuracy 0.6770833730697632\n",
      "Epoch 1 - Batch 6 - Loss 1.0942899755069189 - Accuracy 0.6741071939468384\n",
      "Epoch 1 - Batch 7 - Loss 1.085548110306263 - Accuracy 0.6728515625\n",
      "Epoch 1 - Batch 8 - Loss 1.0741446084446378 - Accuracy 0.6762152910232544\n",
      "Epoch 1 - Batch 9 - Loss 1.0501085758209228 - Accuracy 0.6796875\n",
      "Epoch 1 - Batch 10 - Loss 1.0342024781487205 - Accuracy 0.6860795617103577\n",
      "Epoch 1 - Batch 11 - Loss 1.0463682810465496 - Accuracy 0.6868489980697632\n",
      "Epoch 1 - Batch 12 - Loss 1.0529138858501728 - Accuracy 0.6832932829856873\n",
      "Epoch 1 - Batch 13 - Loss 1.0541568653924125 - Accuracy 0.684151828289032\n",
      "Epoch 1 - Batch 14 - Loss 1.0435196002324423 - Accuracy 0.6864583492279053\n",
      "Epoch 1 - Batch 15 - Loss 1.0506459400057793 - Accuracy 0.681640625\n",
      "Epoch 1 - Batch 16 - Loss 1.0388668775558472 - Accuracy 0.6842830777168274\n",
      "Epoch 1 - Batch 17 - Loss 1.0329865978823767 - Accuracy 0.6848958134651184\n",
      "Epoch 1 - Batch 18 - Loss 1.0246859506556862 - Accuracy 0.6850329041481018\n",
      "Epoch 1 - Batch 19 - Loss 1.016620045900345 - Accuracy 0.685546875\n",
      "Epoch 1 - Batch 20 - Loss 0.9975508905592418 - Accuracy 0.6893601417541504\n",
      "Epoch 1 - Batch 21 - Loss 0.9919309914112091 - Accuracy 0.6878551244735718\n",
      "Epoch 1 - Batch 22 - Loss 0.9804447448771932 - Accuracy 0.68919837474823\n",
      "Epoch 1 - Batch 23 - Loss 0.9788460979859034 - Accuracy 0.6871744990348816\n",
      "Epoch 1 - Batch 24 - Loss 0.9794858527183533 - Accuracy 0.6850000023841858\n",
      "Epoch 1 - Batch 25 - Loss 0.9801521690992209 - Accuracy 0.685396671295166\n",
      "Epoch 1 - Batch 26 - Loss 0.9845260580380758 - Accuracy 0.6825810074806213\n",
      "Epoch 1 - Batch 27 - Loss 0.9781582036188671 - Accuracy 0.6824777126312256\n",
      "Epoch 1 - Batch 28 - Loss 0.9753556004885969 - Accuracy 0.681303858757019\n",
      "Epoch 1 - Batch 29 - Loss 0.9653891305128733 - Accuracy 0.6841146349906921\n",
      "Epoch 1 - Batch 30 - Loss 0.9598068633387166 - Accuracy 0.6869959235191345\n",
      "Epoch 1 - Batch 31 - Loss 0.9537259116768837 - Accuracy 0.6884765625\n",
      "Epoch 1 - Batch 32 - Loss 0.9548563758532206 - Accuracy 0.6882102489471436\n",
      "Epoch 1 - Batch 33 - Loss 0.9538068596054526 - Accuracy 0.6879595518112183\n",
      "Epoch 1 - Batch 34 - Loss 0.9494305218969072 - Accuracy 0.6895089149475098\n",
      "Epoch 1 - Batch 35 - Loss 0.949964991874165 - Accuracy 0.6892361044883728\n",
      "Epoch 1 - Batch 36 - Loss 0.9461162460816873 - Accuracy 0.6900337934494019\n",
      "Epoch 1 - Batch 37 - Loss 0.9465031796380093 - Accuracy 0.6899670958518982\n",
      "Epoch 1 - Batch 38 - Loss 0.9492127910638467 - Accuracy 0.6897035241127014\n",
      "Epoch 1 - Batch 39 - Loss 0.9484177097678185 - Accuracy 0.6884765625\n",
      "Epoch 1 - Batch 40 - Loss 0.9466888890033816 - Accuracy 0.6888338327407837\n",
      "Epoch 1 - Batch 41 - Loss 0.9435879233337584 - Accuracy 0.6899181604385376\n",
      "Epoch 1 - Batch 42 - Loss 0.9441099028254665 - Accuracy 0.6891351938247681\n",
      "Epoch 1 - Batch 43 - Loss 0.9406565265222029 - Accuracy 0.6903409361839294\n",
      "Epoch 1 - Batch 44 - Loss 0.937389530075921 - Accuracy 0.6909722685813904\n",
      "Epoch 1 - Batch 45 - Loss 0.9365518818730894 - Accuracy 0.6902173757553101\n",
      "Epoch 1 - Batch 46 - Loss 0.9312808665823429 - Accuracy 0.6916555762290955\n",
      "Epoch 1 - Batch 47 - Loss 0.9275176723798116 - Accuracy 0.6917318105697632\n",
      "Epoch 1 - Batch 48 - Loss 0.9247085074989163 - Accuracy 0.6924425959587097\n",
      "Epoch 1 - Batch 49 - Loss 0.9199145245552063 - Accuracy 0.6934374570846558\n",
      "Epoch 1 - Batch 50 - Loss 0.9204437826194015 - Accuracy 0.6931679248809814\n",
      "Epoch 1 - Batch 51 - Loss 0.9194121807813644 - Accuracy 0.693209171295166\n",
      "Epoch 1 - Batch 52 - Loss 0.9177660109861842 - Accuracy 0.6938384771347046\n",
      "Epoch 1 - Batch 53 - Loss 0.9162621233198378 - Accuracy 0.6940104365348816\n",
      "Epoch 1 - Batch 54 - Loss 0.913208544254303 - Accuracy 0.6946022510528564\n",
      "Epoch 1 - Batch 55 - Loss 0.9141682450260434 - Accuracy 0.693917453289032\n",
      "Epoch 1 - Batch 56 - Loss 0.912887994657483 - Accuracy 0.6933936476707458\n",
      "Epoch 1 - Batch 57 - Loss 0.9107578633160427 - Accuracy 0.6943696141242981\n",
      "Epoch 1 - Batch 58 - Loss 0.9085835036584886 - Accuracy 0.6947828531265259\n",
      "Epoch 1 - Batch 59 - Loss 0.9108547230561574 - Accuracy 0.6940104365348816\n",
      "Epoch 1 - Batch 60 - Loss 0.9105417601397781 - Accuracy 0.6937755942344666\n",
      "Epoch 1 - Batch 61 - Loss 0.9111566793534064 - Accuracy 0.6929183006286621\n",
      "Epoch 1 - Batch 62 - Loss 0.9102471574904427 - Accuracy 0.6928324103355408\n",
      "Epoch 1 - Batch 63 - Loss 0.9101009406149387 - Accuracy 0.6925048828125\n",
      "Epoch 1 - Batch 64 - Loss 0.9088008458797748 - Accuracy 0.6926682591438293\n",
      "Epoch 1 - Batch 65 - Loss 0.9069089663751198 - Accuracy 0.692945122718811\n",
      "Epoch 1 - Batch 66 - Loss 0.9089810287774499 - Accuracy 0.6922807693481445\n",
      "Epoch 1 - Batch 67 - Loss 0.9082303564338123 - Accuracy 0.6926700472831726\n",
      "Epoch 1 - Batch 68 - Loss 0.9080809855806655 - Accuracy 0.6923686861991882\n",
      "Epoch 1 - Batch 69 - Loss 0.9058297378676278 - Accuracy 0.6928571462631226\n",
      "Epoch 1 - Batch 70 - Loss 0.9058309130265679 - Accuracy 0.6927816867828369\n",
      "Epoch 1 - Batch 71 - Loss 0.9034723995460404 - Accuracy 0.6939018964767456\n",
      "Epoch 1 - Batch 72 - Loss 0.9026531250509497 - Accuracy 0.6941352486610413\n",
      "Epoch 1 - Batch 73 - Loss 0.901229809264879 - Accuracy 0.6947846412658691\n",
      "Epoch 1 - Batch 74 - Loss 0.8995529365539551 - Accuracy 0.6953125\n",
      "Epoch 1 - Batch 75 - Loss 0.8984413876345283 - Accuracy 0.6956208944320679\n",
      "Epoch 1 - Batch 76 - Loss 0.897955789968565 - Accuracy 0.6958197951316833\n",
      "Epoch 1 - Batch 77 - Loss 0.8973100498700753 - Accuracy 0.6959134936332703\n",
      "Epoch 1 - Batch 78 - Loss 0.8963871055011507 - Accuracy 0.6962025761604309\n",
      "Epoch 1 - Batch 79 - Loss 0.89563814625144 - Accuracy 0.6961914300918579\n",
      "Epoch 1 - Batch 80 - Loss 0.8948693032617923 - Accuracy 0.6964699029922485\n",
      "Epoch 1 - Batch 81 - Loss 0.8976255139199699 - Accuracy 0.6960746645927429\n",
      "Epoch 1 - Batch 82 - Loss 0.8969348927578294 - Accuracy 0.696536123752594\n",
      "Epoch 1 - Batch 83 - Loss 0.8958116528533754 - Accuracy 0.6966146230697632\n",
      "Epoch 1 - Batch 84 - Loss 0.8950959773624645 - Accuracy 0.6969669461250305\n",
      "Epoch 1 - Batch 85 - Loss 0.895127456548602 - Accuracy 0.6971293687820435\n",
      "Epoch 1 - Batch 86 - Loss 0.8961876555420887 - Accuracy 0.6963900923728943\n",
      "Epoch 1 - Batch 87 - Loss 0.895041514526714 - Accuracy 0.6965554356575012\n",
      "Epoch 1 - Batch 88 - Loss 0.8940494529316935 - Accuracy 0.6964536309242249\n",
      "Epoch 1 - Batch 89 - Loss 0.8923566434118483 - Accuracy 0.6972222328186035\n",
      "Epoch 1 - Batch 90 - Loss 0.8899411578754802 - Accuracy 0.6981456279754639\n",
      "Epoch 1 - Batch 91 - Loss 0.8896843486506006 - Accuracy 0.6981997489929199\n",
      "Epoch 1 - Batch 92 - Loss 0.8897659887549698 - Accuracy 0.6976646780967712\n",
      "Epoch 1 - Batch 93 - Loss 0.8886739402375323 - Accuracy 0.6977227330207825\n",
      "Epoch 1 - Batch 94 - Loss 0.8885307970799898 - Accuracy 0.6976151466369629\n",
      "Epoch 1 - Batch 95 - Loss 0.8877829319487015 - Accuracy 0.697509765625\n",
      "Epoch 1 - Batch 96 - Loss 0.8869411797867608 - Accuracy 0.6971649527549744\n",
      "Epoch 1 - Batch 97 - Loss 0.8871619640564432 - Accuracy 0.6968271732330322\n",
      "Epoch 1 - Batch 98 - Loss 0.8867673223668878 - Accuracy 0.6970486044883728\n",
      "Epoch 1 - Batch 99 - Loss 0.8864480930566788 - Accuracy 0.6968749761581421\n",
      "Epoch 1 - Batch 100 - Loss 0.8843344768675248 - Accuracy 0.6974009871482849\n",
      "Epoch 1 - Batch 101 - Loss 0.8837411041353264 - Accuracy 0.6974571347236633\n",
      "Epoch 1 - Batch 102 - Loss 0.8824727031791094 - Accuracy 0.6975879669189453\n",
      "Epoch 1 - Batch 103 - Loss 0.883891125711111 - Accuracy 0.6974158883094788\n",
      "Epoch 1 - Batch 104 - Loss 0.8834886738232204 - Accuracy 0.6976190805435181\n",
      "Epoch 1 - Batch 105 - Loss 0.8823558541963685 - Accuracy 0.6980395317077637\n",
      "Epoch 1 - Batch 106 - Loss 0.8826995514263617 - Accuracy 0.6980140209197998\n",
      "Epoch 1 - Batch 107 - Loss 0.8845005018843545 - Accuracy 0.6974102854728699\n",
      "Epoch 1 - Batch 108 - Loss 0.8829695538643303 - Accuracy 0.6979644298553467\n",
      "Epoch 1 - Batch 109 - Loss 0.8818791243163022 - Accuracy 0.6984374523162842\n",
      "Epoch 1 - Batch 110 - Loss 0.881576962299175 - Accuracy 0.6981981992721558\n",
      "Epoch 1 - Batch 111 - Loss 0.8814045627202306 - Accuracy 0.6981724500656128\n",
      "Epoch 1 - Batch 112 - Loss 0.8818832456538107 - Accuracy 0.6982162594795227\n",
      "Epoch 1 - Batch 113 - Loss 0.8806347182968206 - Accuracy 0.6981222629547119\n",
      "Epoch 1 - Batch 114 - Loss 0.880717981379965 - Accuracy 0.6979619264602661\n",
      "Epoch 1 - Batch 115 - Loss 0.8798235798704213 - Accuracy 0.6984779238700867\n",
      "Epoch 1 - Batch 116 - Loss 0.8794989804936271 - Accuracy 0.6981837749481201\n",
      "Epoch 1 - Batch 117 - Loss 0.8793842883433326 - Accuracy 0.6978945732116699\n",
      "Epoch 1 - Batch 118 - Loss 0.8795344804515358 - Accuracy 0.6978073120117188\n",
      "Epoch 1 - Batch 119 - Loss 0.8786128203074137 - Accuracy 0.6978515982627869\n",
      "Epoch 1 - Batch 120 - Loss 0.8775812446578475 - Accuracy 0.6983470916748047\n",
      "Epoch 1 - Batch 121 - Loss 0.8779427697424029 - Accuracy 0.6987063884735107\n",
      "Epoch 1 - Batch 122 - Loss 0.8777043286377821 - Accuracy 0.6985517740249634\n",
      "Epoch 1 - Batch 123 - Loss 0.8773032498936499 - Accuracy 0.6988406777381897\n",
      "Epoch 1 - Batch 124 - Loss 0.8775677018165589 - Accuracy 0.6991250514984131\n",
      "Epoch 1 - Batch 125 - Loss 0.8773248909957825 - Accuracy 0.6997148394584656\n",
      "Epoch 1 - Batch 126 - Loss 0.8764524206401795 - Accuracy 0.6997416019439697\n",
      "Epoch 1 - Batch 127 - Loss 0.8757939757779241 - Accuracy 0.69989013671875\n",
      "Epoch 1 - Batch 128 - Loss 0.8754671359247015 - Accuracy 0.7001574635505676\n",
      "Epoch 1 - Batch 129 - Loss 0.8757927564474253 - Accuracy 0.700120210647583\n",
      "Epoch 1 - Batch 130 - Loss 0.8747801826200412 - Accuracy 0.700441300868988\n",
      "Epoch 1 - Batch 131 - Loss 0.8740737171787204 - Accuracy 0.7005800604820251\n",
      "Epoch 1 - Batch 132 - Loss 0.8725297352425138 - Accuracy 0.7011865973472595\n",
      "Epoch 1 - Batch 133 - Loss 0.8722054798211625 - Accuracy 0.7014925479888916\n",
      "Epoch 1 - Batch 134 - Loss 0.8703550784676163 - Accuracy 0.7023147940635681\n",
      "Epoch 1 - Batch 135 - Loss 0.8705546075806898 - Accuracy 0.7022058963775635\n",
      "Epoch 1 - Batch 136 - Loss 0.8699535344638963 - Accuracy 0.7027258276939392\n",
      "Epoch 1 - Batch 137 - Loss 0.8691702498042065 - Accuracy 0.7028985619544983\n",
      "Epoch 1 - Batch 138 - Loss 0.8704430160762595 - Accuracy 0.7025629878044128\n",
      "Epoch 1 - Batch 139 - Loss 0.8689443835190365 - Accuracy 0.7028459906578064\n",
      "Epoch 1 - Batch 140 - Loss 0.8684776759316736 - Accuracy 0.7032358050346375\n",
      "Epoch 1 - Batch 141 - Loss 0.8679806258476955 - Accuracy 0.703125\n",
      "Epoch 1 - Batch 142 - Loss 0.8681357882239602 - Accuracy 0.703125\n",
      "Epoch 1 - Batch 143 - Loss 0.8684177560110887 - Accuracy 0.7031792402267456\n",
      "Epoch 1 - Batch 144 - Loss 0.8684428946725253 - Accuracy 0.7029094696044922\n",
      "Epoch 1 - Batch 145 - Loss 0.8686489769040722 - Accuracy 0.7031785249710083\n",
      "Epoch 1 - Batch 146 - Loss 0.8686239885635116 - Accuracy 0.7032312750816345\n",
      "Epoch 1 - Batch 147 - Loss 0.8680764154807942 - Accuracy 0.7033361792564392\n",
      "Epoch 1 - Batch 148 - Loss 0.8682240883776006 - Accuracy 0.7029677033424377\n",
      "Epoch 1 - Batch 149 - Loss 0.8678506052494049 - Accuracy 0.7028645873069763\n",
      "Epoch 1 - Batch 150 - Loss 0.8671232975081892 - Accuracy 0.7030215263366699\n",
      "Epoch 1 - Batch 151 - Loss 0.8664099260380393 - Accuracy 0.7033820152282715\n",
      "Epoch 1 - Batch 152 - Loss 0.866739912749895 - Accuracy 0.7032781839370728\n",
      "Epoch 1 - Batch 153 - Loss 0.8666906511628782 - Accuracy 0.7031757235527039\n",
      "Epoch 1 - Batch 154 - Loss 0.8666204056432171 - Accuracy 0.7028729915618896\n",
      "Epoch 1 - Batch 155 - Loss 0.8670425850611466 - Accuracy 0.7027243971824646\n",
      "Epoch 1 - Batch 156 - Loss 0.8667385039056182 - Accuracy 0.7028762102127075\n",
      "Epoch 1 - Batch 157 - Loss 0.8660817847976202 - Accuracy 0.7030261158943176\n",
      "Epoch 1 - Batch 158 - Loss 0.8663325504686847 - Accuracy 0.7027810215950012\n",
      "Epoch 1 - Batch 159 - Loss 0.865039200335741 - Accuracy 0.703125\n",
      "Epoch 1 - Batch 160 - Loss 0.8644802511108588 - Accuracy 0.7033191323280334\n",
      "Epoch 1 - Batch 161 - Loss 0.8639779157108731 - Accuracy 0.7033661603927612\n",
      "Epoch 1 - Batch 162 - Loss 0.8634275790372509 - Accuracy 0.7036042809486389\n",
      "Epoch 1 - Batch 163 - Loss 0.8628354505067919 - Accuracy 0.7038871645927429\n",
      "Epoch 1 - Batch 164 - Loss 0.8622576045267509 - Accuracy 0.704024612903595\n",
      "Epoch 1 - Batch 165 - Loss 0.8614243929644665 - Accuracy 0.7045839428901672\n",
      "Epoch 1 - Batch 166 - Loss 0.8604879257921687 - Accuracy 0.7047623991966248\n",
      "Epoch 1 - Batch 167 - Loss 0.8608734199688548 - Accuracy 0.7043805718421936\n",
      "Epoch 1 - Batch 168 - Loss 0.8601682940883749 - Accuracy 0.7044193744659424\n",
      "Epoch 1 - Batch 169 - Loss 0.8593125588753644 - Accuracy 0.7047334909439087\n",
      "Epoch 1 - Batch 170 - Loss 0.8588012547520866 - Accuracy 0.7048611044883728\n",
      "Epoch 1 - Batch 171 - Loss 0.8574903534595356 - Accuracy 0.7053506374359131\n",
      "Epoch 1 - Batch 172 - Loss 0.8571131046796809 - Accuracy 0.7052474617958069\n",
      "Epoch 1 - Batch 173 - Loss 0.8563509422472153 - Accuracy 0.705414891242981\n",
      "Epoch 1 - Batch 174 - Loss 0.8561271016938345 - Accuracy 0.7053571343421936\n",
      "Epoch 1 - Batch 175 - Loss 0.8566143973307176 - Accuracy 0.7050337791442871\n",
      "Epoch 1 - Batch 176 - Loss 0.8558054206061498 - Accuracy 0.7053760886192322\n",
      "Epoch 1 - Batch 177 - Loss 0.8549767853168959 - Accuracy 0.7056706547737122\n",
      "Epoch 1 - Batch 178 - Loss 0.8551853568860273 - Accuracy 0.7053945064544678\n",
      "Epoch 1 - Batch 179 - Loss 0.854039180609915 - Accuracy 0.7055989503860474\n",
      "Epoch 1 - Batch 180 - Loss 0.8529576451738895 - Accuracy 0.7058874368667603\n",
      "Epoch 1 - Batch 181 - Loss 0.8527831294379391 - Accuracy 0.7059152126312256\n",
      "Epoch 1 - Batch 182 - Loss 0.8520313191935013 - Accuracy 0.7061133980751038\n",
      "Epoch 1 - Batch 183 - Loss 0.8525266449736513 - Accuracy 0.70579993724823\n",
      "Epoch 1 - Batch 184 - Loss 0.8524745841284056 - Accuracy 0.7057432532310486\n",
      "Epoch 1 - Batch 185 - Loss 0.8516254328912304 - Accuracy 0.7058131694793701\n",
      "Epoch 1 - Batch 186 - Loss 0.8506113376846925 - Accuracy 0.70621657371521\n",
      "Epoch 1 - Batch 187 - Loss 0.8499349406424989 - Accuracy 0.706407904624939\n",
      "Epoch 1 - Batch 188 - Loss 0.849405879066104 - Accuracy 0.7063491940498352\n",
      "Epoch 1 - Batch 189 - Loss 0.8485254711226413 - Accuracy 0.7067845463752747\n",
      "Epoch 1 - Batch 190 - Loss 0.84869046891547 - Accuracy 0.7069290280342102\n",
      "Epoch 1 - Batch 191 - Loss 0.8477730297793945 - Accuracy 0.7070719599723816\n",
      "Epoch 1 - Batch 192 - Loss 0.8465208435923325 - Accuracy 0.707415759563446\n",
      "Epoch 1 - Batch 193 - Loss 0.8470638812202769 - Accuracy 0.7073936462402344\n",
      "Epoch 1 - Batch 194 - Loss 0.8472083553289755 - Accuracy 0.7073718309402466\n",
      "Epoch 1 - Batch 195 - Loss 0.8462021384312182 - Accuracy 0.7077088356018066\n",
      "Epoch 1 - Batch 196 - Loss 0.845751410813501 - Accuracy 0.7078441977500916\n",
      "Epoch 1 - Batch 197 - Loss 0.8458104058347568 - Accuracy 0.7078598737716675\n",
      "Epoch 1 - Batch 198 - Loss 0.8454873525916632 - Accuracy 0.7081108689308167\n",
      "Epoch 1 - Batch 199 - Loss 0.8460694888234138 - Accuracy 0.7083203196525574\n",
      "Epoch 1 - Batch 200 - Loss 0.8463476516714143 - Accuracy 0.7083333134651184\n",
      "Epoch 1 - Batch 201 - Loss 0.8450495290874255 - Accuracy 0.7087329626083374\n",
      "Epoch 1 - Batch 202 - Loss 0.8451183059532654 - Accuracy 0.7085514068603516\n",
      "Epoch 1 - Batch 203 - Loss 0.8448031757976494 - Accuracy 0.7084865570068359\n",
      "Epoch 1 - Batch 204 - Loss 0.8436436083258652 - Accuracy 0.7088414430618286\n",
      "Epoch 1 - Batch 205 - Loss 0.8428092156220408 - Accuracy 0.7093825936317444\n",
      "Epoch 1 - Batch 206 - Loss 0.8421657788004853 - Accuracy 0.7096920013427734\n",
      "Epoch 1 - Batch 207 - Loss 0.8423434134859306 - Accuracy 0.7097731828689575\n",
      "Epoch 1 - Batch 208 - Loss 0.8424367893255499 - Accuracy 0.70985347032547\n",
      "Epoch 1 - Batch 209 - Loss 0.8432383270490738 - Accuracy 0.7097470760345459\n",
      "Epoch 1 - Batch 210 - Loss 0.8432622927625032 - Accuracy 0.7097526788711548\n",
      "Epoch 1 - Batch 211 - Loss 0.8432889116822548 - Accuracy 0.7094634771347046\n",
      "Epoch 1 - Batch 212 - Loss 0.8434773591202749 - Accuracy 0.7092869877815247\n",
      "Epoch 1 - Batch 213 - Loss 0.8422981815360416 - Accuracy 0.7095867395401001\n",
      "Epoch 1 - Batch 214 - Loss 0.8420159730800363 - Accuracy 0.7098473906517029\n",
      "Epoch 1 - Batch 215 - Loss 0.8416784397429891 - Accuracy 0.7099971175193787\n",
      "Epoch 1 - Batch 216 - Loss 0.8413151524583315 - Accuracy 0.7100734710693359\n",
      "Epoch 1 - Batch 217 - Loss 0.8409208813938526 - Accuracy 0.710292398929596\n",
      "Epoch 1 - Batch 218 - Loss 0.840099490124341 - Accuracy 0.7104737162590027\n",
      "Epoch 1 - Batch 219 - Loss 0.839745035496625 - Accuracy 0.7106178998947144\n",
      "Epoch 1 - Batch 220 - Loss 0.838468948640435 - Accuracy 0.7111142873764038\n",
      "Epoch 1 - Batch 221 - Loss 0.8384234462235425 - Accuracy 0.711219072341919\n",
      "Epoch 1 - Batch 222 - Loss 0.8383967855051494 - Accuracy 0.7112878561019897\n",
      "Epoch 1 - Batch 223 - Loss 0.8380803175802741 - Accuracy 0.7113211750984192\n",
      "Epoch 1 - Batch 224 - Loss 0.8382800547281901 - Accuracy 0.711180567741394\n",
      "Epoch 1 - Batch 225 - Loss 0.8376696088672739 - Accuracy 0.7113868594169617\n",
      "Epoch 1 - Batch 226 - Loss 0.8373200426017661 - Accuracy 0.7115225195884705\n",
      "Epoch 1 - Batch 227 - Loss 0.837569331129392 - Accuracy 0.711485743522644\n",
      "Epoch 1 - Batch 228 - Loss 0.8373797364109988 - Accuracy 0.711483359336853\n",
      "Epoch 1 - Batch 229 - Loss 0.8367507919021274 - Accuracy 0.7118545770645142\n",
      "Epoch 1 - Batch 230 - Loss 0.8356435105398103 - Accuracy 0.7122564911842346\n",
      "Epoch 1 - Batch 231 - Loss 0.8351824846247147 - Accuracy 0.7125875353813171\n",
      "Epoch 1 - Batch 232 - Loss 0.8341635557714961 - Accuracy 0.712949275970459\n",
      "Epoch 1 - Batch 233 - Loss 0.8335282858620342 - Accuracy 0.7132745981216431\n",
      "Epoch 1 - Batch 234 - Loss 0.8327090925358711 - Accuracy 0.7136635184288025\n",
      "Epoch 1 - Batch 235 - Loss 0.8324890490305625 - Accuracy 0.7135195732116699\n",
      "Epoch 1 - Batch 236 - Loss 0.8317355772613976 - Accuracy 0.7139372229576111\n",
      "Epoch 1 - Batch 237 - Loss 0.8307264362062726 - Accuracy 0.7143841981887817\n",
      "Epoch 1 - Batch 238 - Loss 0.8306796889923607 - Accuracy 0.7144678235054016\n",
      "Epoch 1 - Batch 239 - Loss 0.8312074862420559 - Accuracy 0.7144206166267395\n",
      "Epoch 1 - Batch 240 - Loss 0.8311518354039964 - Accuracy 0.714373767375946\n",
      "Epoch 1 - Batch 241 - Loss 0.8313480884083047 - Accuracy 0.71445631980896\n",
      "Epoch 1 - Batch 242 - Loss 0.8307831957016463 - Accuracy 0.7146025896072388\n",
      "Epoch 1 - Batch 243 - Loss 0.8308119529583415 - Accuracy 0.7146195769309998\n",
      "Epoch 1 - Batch 244 - Loss 0.8302942470628388 - Accuracy 0.7148277759552002\n",
      "Epoch 1 - Batch 245 - Loss 0.8302457109699405 - Accuracy 0.7149389982223511\n",
      "Epoch 1 - Batch 246 - Loss 0.8300752154728661 - Accuracy 0.7149544954299927\n",
      "Epoch 1 - Batch 247 - Loss 0.8298857313010001 - Accuracy 0.7150012254714966\n",
      "Epoch 1 - Batch 248 - Loss 0.829716068195052 - Accuracy 0.7148280143737793\n",
      "Epoch 1 - Batch 249 - Loss 0.8294617578983307 - Accuracy 0.7147500514984131\n",
      "Epoch 1 - Batch 250 - Loss 0.8298128240136986 - Accuracy 0.7146414518356323\n",
      "Epoch 1 - Batch 251 - Loss 0.8296219351745787 - Accuracy 0.7146267890930176\n",
      "Epoch 1 - Batch 252 - Loss 0.8290344193990051 - Accuracy 0.7148283123970032\n",
      "Epoch 1 - Batch 253 - Loss 0.8287971977173813 - Accuracy 0.7149975299835205\n",
      "Epoch 1 - Batch 254 - Loss 0.8287401285825992 - Accuracy 0.7149816751480103\n",
      "Epoch 1 - Batch 255 - Loss 0.8283126323949546 - Accuracy 0.71502685546875\n",
      "Epoch 1 - Batch 256 - Loss 0.828670807385723 - Accuracy 0.7149197459220886\n",
      "Epoch 1 - Batch 257 - Loss 0.8285540841346564 - Accuracy 0.7148740291595459\n",
      "Epoch 1 - Batch 258 - Loss 0.8284644749173786 - Accuracy 0.7148286700248718\n",
      "Epoch 1 - Batch 259 - Loss 0.8280855029821396 - Accuracy 0.7150540947914124\n",
      "Epoch 1 - Batch 260 - Loss 0.8282113296775525 - Accuracy 0.7148886322975159\n",
      "Epoch 1 - Batch 261 - Loss 0.8284941327025872 - Accuracy 0.7146946787834167\n",
      "Epoch 1 - Batch 262 - Loss 0.8285694453199554 - Accuracy 0.7145912647247314\n",
      "Epoch 1 - Batch 263 - Loss 0.8279734994425918 - Accuracy 0.71484375\n",
      "Epoch 1 - Batch 264 - Loss 0.8276365943674772 - Accuracy 0.7148879766464233\n",
      "Epoch 1 - Batch 265 - Loss 0.8285460245788545 - Accuracy 0.7146381735801697\n",
      "Epoch 1 - Batch 266 - Loss 0.8275276134523113 - Accuracy 0.7151217460632324\n",
      "Epoch 1 - Batch 267 - Loss 0.8269802434230918 - Accuracy 0.7153101563453674\n",
      "Epoch 1 - Batch 268 - Loss 0.8274718525241299 - Accuracy 0.7151777148246765\n",
      "Epoch 1 - Batch 269 - Loss 0.8271567152606116 - Accuracy 0.7151909470558167\n",
      "Epoch 1 - Batch 270 - Loss 0.8267888642325173 - Accuracy 0.7153482437133789\n",
      "Epoch 1 - Batch 271 - Loss 0.8265719571534325 - Accuracy 0.7153894901275635\n",
      "Epoch 1 - Batch 272 - Loss 0.8262607252204811 - Accuracy 0.7154876589775085\n",
      "Epoch 1 - Batch 273 - Loss 0.8264331493499505 - Accuracy 0.7154139876365662\n",
      "Epoch 1 - Batch 274 - Loss 0.8266123860532587 - Accuracy 0.7153409123420715\n",
      "Epoch 1 - Batch 275 - Loss 0.8264279451923094 - Accuracy 0.7153249382972717\n",
      "Epoch 1 - Batch 276 - Loss 0.8260313257413651 - Accuracy 0.7154219150543213\n",
      "Epoch 1 - Batch 277 - Loss 0.8255373248093419 - Accuracy 0.7154901027679443\n",
      "Epoch 1 - Batch 278 - Loss 0.8254073401078529 - Accuracy 0.7153617739677429\n",
      "Epoch 1 - Batch 279 - Loss 0.8255567644323621 - Accuracy 0.7153180837631226\n",
      "Epoch 1 - Batch 280 - Loss 0.825260936365433 - Accuracy 0.7154415249824524\n",
      "Epoch 1 - Batch 281 - Loss 0.8250039891993746 - Accuracy 0.7154809236526489\n",
      "Epoch 1 - Batch 282 - Loss 0.8247441042859647 - Accuracy 0.7156581282615662\n",
      "Epoch 1 - Batch 283 - Loss 0.8242995079974054 - Accuracy 0.7158890962600708\n",
      "Epoch 1 - Batch 284 - Loss 0.8237830224790071 - Accuracy 0.7160087823867798\n",
      "Epoch 1 - Batch 285 - Loss 0.823251960160849 - Accuracy 0.7162095904350281\n",
      "Epoch 1 - Batch 286 - Loss 0.8230568936892918 - Accuracy 0.7162456512451172\n",
      "Epoch 1 - Batch 287 - Loss 0.8227857516871558 - Accuracy 0.7162543535232544\n",
      "Epoch 1 - Batch 288 - Loss 0.8230393479439626 - Accuracy 0.7161818742752075\n",
      "Epoch 1 - Batch 289 - Loss 0.8229180366828523 - Accuracy 0.7162984609603882\n",
      "Epoch 1 - Batch 290 - Loss 0.8233762008627665 - Accuracy 0.7163337469100952\n",
      "Epoch 1 - Batch 291 - Loss 0.8233976747891675 - Accuracy 0.7161547541618347\n",
      "Epoch 1 - Batch 292 - Loss 0.8233860761639201 - Accuracy 0.7162702679634094\n",
      "Epoch 1 - Batch 293 - Loss 0.8230100529534476 - Accuracy 0.7162786722183228\n",
      "Epoch 1 - Batch 294 - Loss 0.8230184304512154 - Accuracy 0.7162606120109558\n",
      "Epoch 1 - Batch 295 - Loss 0.8226558368753742 - Accuracy 0.7163745760917664\n",
      "Epoch 1 - Batch 296 - Loss 0.8226408733663334 - Accuracy 0.7163299322128296\n",
      "Epoch 1 - Batch 297 - Loss 0.8225911091638092 - Accuracy 0.7164167165756226\n",
      "Epoch 1 - Batch 298 - Loss 0.8220398587526685 - Accuracy 0.7165551781654358\n",
      "Epoch 1 - Batch 299 - Loss 0.821588764389356 - Accuracy 0.7166406512260437\n",
      "Epoch 1 - Batch 300 - Loss 0.821064523684226 - Accuracy 0.7167773842811584\n",
      "Epoch 1 - Batch 301 - Loss 0.8210844470570419 - Accuracy 0.7168098092079163\n",
      "Epoch 1 - Batch 302 - Loss 0.8204548968733734 - Accuracy 0.7169967293739319\n",
      "Epoch 1 - Batch 303 - Loss 0.8197965674886578 - Accuracy 0.7171052694320679\n",
      "Epoch 1 - Batch 304 - Loss 0.8194027660322971 - Accuracy 0.7171362638473511\n",
      "Epoch 1 - Batch 305 - Loss 0.8191613198495379 - Accuracy 0.7172181606292725\n",
      "Epoch 1 - Batch 306 - Loss 0.8190138648697919 - Accuracy 0.7172485589981079\n",
      "Epoch 1 - Batch 307 - Loss 0.8195475361176899 - Accuracy 0.7170758843421936\n",
      "Epoch 1 - Batch 308 - Loss 0.8190932673157998 - Accuracy 0.7173341512680054\n",
      "Epoch 1 - Batch 309 - Loss 0.8190365422156549 - Accuracy 0.7173891067504883\n",
      "Epoch 1 - Batch 310 - Loss 0.8191978689941946 - Accuracy 0.7172427773475647\n",
      "Epoch 1 - Batch 311 - Loss 0.8188278587200702 - Accuracy 0.7174229025840759\n",
      "Epoch 1 - Batch 312 - Loss 0.818307519530336 - Accuracy 0.7175768613815308\n",
      "Epoch 1 - Batch 313 - Loss 0.8184125823959424 - Accuracy 0.7174562215805054\n",
      "Epoch 1 - Batch 314 - Loss 0.8182935576590281 - Accuracy 0.7174851298332214\n",
      "Epoch 1 - Batch 315 - Loss 0.8181372858300994 - Accuracy 0.7175880074501038\n",
      "Epoch 1 - Batch 316 - Loss 0.8180510826667401 - Accuracy 0.7178134918212891\n",
      "Epoch 1 - Batch 317 - Loss 0.8182345580005046 - Accuracy 0.7178409695625305\n",
      "Epoch 1 - Batch 318 - Loss 0.8175760569243595 - Accuracy 0.7181132435798645\n",
      "Epoch 1 - Batch 319 - Loss 0.8178628101944924 - Accuracy 0.7181396484375\n",
      "Epoch 1 - Batch 320 - Loss 0.8179388826138505 - Accuracy 0.7180928587913513\n",
      "Epoch 1 - Batch 321 - Loss 0.8174732164566562 - Accuracy 0.7183617949485779\n",
      "Epoch 1 - Batch 322 - Loss 0.8171834512022627 - Accuracy 0.7185323238372803\n",
      "Epoch 1 - Batch 323 - Loss 0.8169511179497213 - Accuracy 0.7187017798423767\n",
      "Epoch 1 - Batch 324 - Loss 0.8170926033533537 - Accuracy 0.7185817360877991\n",
      "Epoch 1 - Batch 325 - Loss 0.8168014148992995 - Accuracy 0.7187020778656006\n",
      "Epoch 1 - Batch 326 - Loss 0.8164912323703825 - Accuracy 0.7188217043876648\n",
      "Epoch 1 - Batch 327 - Loss 0.816555616513985 - Accuracy 0.7188452482223511\n",
      "Epoch 1 - Batch 328 - Loss 0.8167945976315298 - Accuracy 0.718892514705658\n",
      "Epoch 1 - Batch 329 - Loss 0.8163511677221819 - Accuracy 0.7189866900444031\n",
      "Epoch 1 - Batch 330 - Loss 0.8153925935127224 - Accuracy 0.7193400859832764\n",
      "Epoch 1 - Batch 331 - Loss 0.8150062281862799 - Accuracy 0.7194324135780334\n",
      "Epoch 1 - Batch 332 - Loss 0.815294176698089 - Accuracy 0.7193834781646729\n",
      "Epoch 1 - Batch 333 - Loss 0.8148385331837716 - Accuracy 0.7195219397544861\n",
      "Epoch 1 - Batch 334 - Loss 0.8144563321746997 - Accuracy 0.7196362018585205\n",
      "Epoch 1 - Batch 335 - Loss 0.8149279456230856 - Accuracy 0.719424307346344\n",
      "Epoch 1 - Batch 336 - Loss 0.8145713347178892 - Accuracy 0.7196309566497803\n",
      "Epoch 1 - Batch 337 - Loss 0.814446869774683 - Accuracy 0.719651460647583\n",
      "Epoch 1 - Batch 338 - Loss 0.8145135881099026 - Accuracy 0.7194874882698059\n",
      "Epoch 1 - Batch 339 - Loss 0.8143088501165895 - Accuracy 0.7195542454719543\n",
      "Epoch 1 - Batch 340 - Loss 0.814046790959898 - Accuracy 0.7195289731025696\n",
      "Epoch 1 - Batch 341 - Loss 0.8136780421461975 - Accuracy 0.7196865677833557\n",
      "Epoch 1 - Batch 342 - Loss 0.8136905119822254 - Accuracy 0.7196155786514282\n",
      "Epoch 1 - Batch 343 - Loss 0.8136406219456085 - Accuracy 0.7196357250213623\n",
      "Epoch 1 - Batch 344 - Loss 0.8134451782357865 - Accuracy 0.7198370099067688\n",
      "Epoch 1 - Batch 345 - Loss 0.8134795178395475 - Accuracy 0.7198789715766907\n",
      "Epoch 1 - Batch 346 - Loss 0.8130902569816161 - Accuracy 0.7199657559394836\n",
      "Epoch 1 - Batch 347 - Loss 0.8129131556756195 - Accuracy 0.7200520634651184\n",
      "Epoch 1 - Batch 348 - Loss 0.8128319378397868 - Accuracy 0.7200707793235779\n",
      "Epoch 1 - Batch 349 - Loss 0.8124571205036981 - Accuracy 0.7202455401420593\n",
      "Epoch 1 - Batch 350 - Loss 0.8126858738582698 - Accuracy 0.7202190160751343\n",
      "Epoch 1 - Batch 351 - Loss 0.8121291386302222 - Accuracy 0.720348060131073\n",
      "Epoch 1 - Batch 352 - Loss 0.8117503945111553 - Accuracy 0.7204541563987732\n",
      "Epoch 1 - Batch 353 - Loss 0.8117206525162789 - Accuracy 0.7204272747039795\n",
      "Epoch 1 - Batch 354 - Loss 0.8111771396348174 - Accuracy 0.7205105423927307\n",
      "Epoch 1 - Batch 355 - Loss 0.8108670451165585 - Accuracy 0.7204397916793823\n",
      "Epoch 1 - Batch 356 - Loss 0.8105155195341724 - Accuracy 0.7205882668495178\n",
      "Epoch 1 - Batch 357 - Loss 0.81025407808786 - Accuracy 0.720626711845398\n",
      "Epoch 1 - Batch 358 - Loss 0.8101043848108116 - Accuracy 0.7205126881599426\n",
      "Epoch 1 - Batch 359 - Loss 0.809676281362772 - Accuracy 0.720507800579071\n",
      "Epoch 1 - Batch 360 - Loss 0.8091439977081859 - Accuracy 0.7207626104354858\n",
      "Epoch 1 - Batch 361 - Loss 0.8088367238064498 - Accuracy 0.7208434343338013\n",
      "Epoch 1 - Batch 362 - Loss 0.8087932693235802 - Accuracy 0.7207515835762024\n",
      "Epoch 1 - Batch 363 - Loss 0.808945027927121 - Accuracy 0.7205743789672852\n",
      "Epoch 1 - Batch 364 - Loss 0.8089312753448747 - Accuracy 0.7205051779747009\n",
      "Epoch 1 - Batch 365 - Loss 0.8085176074276856 - Accuracy 0.7205643653869629\n",
      "Epoch 1 - Batch 366 - Loss 0.8083451335858909 - Accuracy 0.7206233143806458\n",
      "Epoch 1 - Batch 367 - Loss 0.808201311480092 - Accuracy 0.7206182479858398\n",
      "Epoch 1 - Batch 368 - Loss 0.8074707152236121 - Accuracy 0.7208883762359619\n",
      "Epoch 1 - Batch 369 - Loss 0.8069010648373011 - Accuracy 0.7210093140602112\n",
      "Epoch 1 - Batch 370 - Loss 0.8069573296208908 - Accuracy 0.7209610939025879\n",
      "Epoch 1 - Batch 371 - Loss 0.8064968918440163 - Accuracy 0.7211231589317322\n",
      "Epoch 1 - Batch 372 - Loss 0.8064730471804059 - Accuracy 0.721095860004425\n",
      "Epoch 1 - Batch 373 - Loss 0.806231159975822 - Accuracy 0.7211522459983826\n",
      "Epoch 1 - Batch 374 - Loss 0.8062028054396312 - Accuracy 0.7211458086967468\n",
      "Epoch 1 - Batch 375 - Loss 0.806534995503248 - Accuracy 0.720910906791687\n",
      "Epoch 1 - Batch 376 - Loss 0.8062967894406154 - Accuracy 0.7208636999130249\n",
      "Epoch 1 - Batch 377 - Loss 0.8057632519612237 - Accuracy 0.7210648059844971\n",
      "Epoch 1 - Batch 378 - Loss 0.8052381520063707 - Accuracy 0.7213060855865479\n",
      "Epoch 1 - Batch 379 - Loss 0.8049420675949046 - Accuracy 0.7215460538864136\n",
      "Epoch 1 - Batch 380 - Loss 0.8046892059287374 - Accuracy 0.7216412425041199\n",
      "Epoch 1 - Batch 381 - Loss 0.8041488764641797 - Accuracy 0.7218586206436157\n",
      "Epoch 1 - Batch 382 - Loss 0.8034041924669599 - Accuracy 0.722115695476532\n",
      "Epoch 1 - Batch 383 - Loss 0.8032363461485753 - Accuracy 0.72210693359375\n",
      "Epoch 1 - Batch 384 - Loss 0.8027339818415704 - Accuracy 0.7222402691841125\n",
      "Epoch 1 - Batch 385 - Loss 0.8028190862483929 - Accuracy 0.7222514152526855\n",
      "Epoch 1 - Batch 386 - Loss 0.8024885359506583 - Accuracy 0.7222828269004822\n",
      "Epoch 1 - Batch 387 - Loss 0.8025873313398705 - Accuracy 0.7222334146499634\n",
      "Epoch 1 - Batch 388 - Loss 0.8021995871876076 - Accuracy 0.7223248481750488\n",
      "Epoch 1 - Batch 389 - Loss 0.8014126659967961 - Accuracy 0.7225761413574219\n",
      "Epoch 1 - Batch 390 - Loss 0.8010047383015723 - Accuracy 0.722774088382721\n",
      "Epoch 1 - Loss 0.8010047383015723 - Accuracy 0.722774088382721\n",
      "Testing...\n",
      "Epoch 1 - Batch 0 - Loss 1.7972261905670166 - Accuracy 0.3046875\n",
      "Epoch 1 - Batch 1 - Loss 1.7574166059494019 - Accuracy 0.3125\n",
      "Epoch 1 - Batch 2 - Loss 1.6753408908843994 - Accuracy 0.3619791865348816\n",
      "Epoch 1 - Batch 3 - Loss 1.6273621916770935 - Accuracy 0.38671875\n",
      "Epoch 1 - Batch 4 - Loss 1.5766820669174195 - Accuracy 0.4124999940395355\n",
      "Epoch 1 - Batch 5 - Loss 1.5549850662549336 - Accuracy 0.4192708432674408\n",
      "Epoch 1 - Batch 6 - Loss 1.5126573528562273 - Accuracy 0.4363839626312256\n",
      "Epoch 1 - Batch 7 - Loss 1.4592980295419693 - Accuracy 0.4619140625\n",
      "Epoch 1 - Batch 8 - Loss 1.4335633516311646 - Accuracy 0.46875\n",
      "Epoch 1 - Batch 9 - Loss 1.4053516387939453 - Accuracy 0.47968751192092896\n",
      "Epoch 1 - Batch 10 - Loss 1.3889653249220415 - Accuracy 0.484375\n",
      "Epoch 1 - Batch 11 - Loss 1.3651797374089558 - Accuracy 0.494140625\n",
      "Epoch 1 - Batch 12 - Loss 1.3384822882138765 - Accuracy 0.504807710647583\n",
      "Epoch 1 - Batch 13 - Loss 1.3201556205749512 - Accuracy 0.5094866156578064\n",
      "Epoch 1 - Batch 14 - Loss 1.3111146291097004 - Accuracy 0.5166667103767395\n",
      "Epoch 1 - Batch 15 - Loss 1.3010986596345901 - Accuracy 0.517578125\n",
      "Epoch 1 - Batch 16 - Loss 1.2827217649011051 - Accuracy 0.5229779481887817\n",
      "Epoch 1 - Batch 17 - Loss 1.2740853097703722 - Accuracy 0.5282118320465088\n",
      "Epoch 1 - Batch 18 - Loss 1.2613876116903204 - Accuracy 0.5345394611358643\n",
      "Epoch 1 - Batch 19 - Loss 1.253960907459259 - Accuracy 0.537890613079071\n",
      "Epoch 1 - Batch 20 - Loss 1.242804419426691 - Accuracy 0.5409226417541504\n",
      "Epoch 1 - Batch 21 - Loss 1.2320492321794683 - Accuracy 0.5440341234207153\n",
      "Epoch 1 - Batch 22 - Loss 1.2231678755387017 - Accuracy 0.5489130616188049\n",
      "Epoch 1 - Batch 23 - Loss 1.2113631516695023 - Accuracy 0.5543619990348816\n",
      "Epoch 1 - Batch 24 - Loss 1.1984853196144103 - Accuracy 0.5606250166893005\n",
      "Epoch 1 - Batch 25 - Loss 1.1943980065675883 - Accuracy 0.5625\n",
      "Epoch 1 - Batch 26 - Loss 1.185301367883329 - Accuracy 0.5665509104728699\n",
      "Epoch 1 - Batch 27 - Loss 1.1763808046068465 - Accuracy 0.5717076063156128\n",
      "Epoch 1 - Batch 28 - Loss 1.1663856033621163 - Accuracy 0.5751616358757019\n",
      "Epoch 1 - Batch 29 - Loss 1.1576612671216329 - Accuracy 0.5791667103767395\n",
      "Epoch 1 - Batch 30 - Loss 1.147853022621524 - Accuracy 0.5846773982048035\n",
      "Epoch 1 - Batch 31 - Loss 1.1393424272537231 - Accuracy 0.587890625\n",
      "Epoch 1 - Batch 32 - Loss 1.1319166241270122 - Accuracy 0.591382622718811\n",
      "Epoch 1 - Batch 33 - Loss 1.1232219057924606 - Accuracy 0.5939797759056091\n",
      "Epoch 1 - Batch 34 - Loss 1.1178624595914568 - Accuracy 0.596875011920929\n",
      "Epoch 1 - Batch 35 - Loss 1.1116287310918171 - Accuracy 0.6000434160232544\n",
      "Epoch 1 - Batch 36 - Loss 1.102581481675844 - Accuracy 0.6038851737976074\n",
      "Epoch 1 - Batch 37 - Loss 1.095101125930485 - Accuracy 0.6071134805679321\n",
      "Epoch 1 - Batch 38 - Loss 1.0886187293590643 - Accuracy 0.609375\n",
      "Epoch 1 - Batch 39 - Loss 1.081449595093727 - Accuracy 0.6119140982627869\n",
      "Epoch 1 - Batch 40 - Loss 1.0790888667106628 - Accuracy 0.6131859421730042\n",
      "Epoch 1 - Batch 41 - Loss 1.0725712251095545 - Accuracy 0.6158854365348816\n",
      "Epoch 1 - Batch 42 - Loss 1.067553345547166 - Accuracy 0.6170058250427246\n",
      "Epoch 1 - Batch 43 - Loss 1.065717033364556 - Accuracy 0.6193181872367859\n",
      "Epoch 1 - Batch 44 - Loss 1.0573668188518948 - Accuracy 0.621874988079071\n",
      "Epoch 1 - Batch 45 - Loss 1.0543348581894585 - Accuracy 0.62279212474823\n",
      "Epoch 1 - Batch 46 - Loss 1.0532225167497675 - Accuracy 0.6230052709579468\n",
      "Epoch 1 - Batch 47 - Loss 1.0507420947154362 - Accuracy 0.6240234375\n",
      "Epoch 1 - Batch 48 - Loss 1.0479961451219053 - Accuracy 0.6253188848495483\n",
      "Epoch 1 - Batch 49 - Loss 1.0431300699710846 - Accuracy 0.6271874904632568\n",
      "Epoch 1 - Batch 50 - Loss 1.040542579164692 - Accuracy 0.6277573704719543\n",
      "Epoch 1 - Batch 51 - Loss 1.0368050566086402 - Accuracy 0.6304087042808533\n",
      "Epoch 1 - Batch 52 - Loss 1.034201293621423 - Accuracy 0.6316332817077637\n",
      "Epoch 1 - Batch 53 - Loss 1.0331700289690937 - Accuracy 0.631944477558136\n",
      "Epoch 1 - Batch 54 - Loss 1.0364850000901655 - Accuracy 0.629687488079071\n",
      "Epoch 1 - Batch 55 - Loss 1.0327580528599876 - Accuracy 0.630859375\n",
      "Epoch 1 - Batch 56 - Loss 1.0285004251881649 - Accuracy 0.6321272253990173\n",
      "Epoch 1 - Batch 57 - Loss 1.0263736145249729 - Accuracy 0.6334859728813171\n",
      "Epoch 1 - Batch 58 - Loss 1.0222226512634147 - Accuracy 0.6350635886192322\n",
      "Epoch 1 - Batch 59 - Loss 1.019160192211469 - Accuracy 0.6363281607627869\n",
      "Epoch 1 - Batch 60 - Loss 1.0151792451983592 - Accuracy 0.6372950673103333\n",
      "Epoch 1 - Batch 61 - Loss 1.0148324043520036 - Accuracy 0.6372227668762207\n",
      "Epoch 1 - Batch 62 - Loss 1.014239536391364 - Accuracy 0.6374008059501648\n",
      "Epoch 1 - Batch 63 - Loss 1.0121155586093664 - Accuracy 0.6385498046875\n",
      "Epoch 1 - Batch 64 - Loss 1.0107416299673226 - Accuracy 0.6393029093742371\n",
      "Epoch 1 - Batch 65 - Loss 1.0079962846004602 - Accuracy 0.640269935131073\n",
      "Epoch 1 - Batch 66 - Loss 1.0064053215197664 - Accuracy 0.6412079930305481\n",
      "Epoch 1 - Batch 67 - Loss 1.0052094924099304 - Accuracy 0.6413143277168274\n",
      "Epoch 1 - Batch 68 - Loss 1.0030364549678306 - Accuracy 0.6420969367027283\n",
      "Epoch 1 - Batch 69 - Loss 1.0004682736737387 - Accuracy 0.6433035731315613\n",
      "Epoch 1 - Batch 70 - Loss 0.9992457317634368 - Accuracy 0.6432658433914185\n",
      "Epoch 1 - Batch 71 - Loss 0.9955903184082773 - Accuracy 0.6448567509651184\n",
      "Epoch 1 - Batch 72 - Loss 0.993709533181909 - Accuracy 0.645440936088562\n",
      "Epoch 1 - Batch 73 - Loss 0.9924833041590613 - Accuracy 0.6460093259811401\n",
      "Epoch 1 - Batch 74 - Loss 0.9886760131518046 - Accuracy 0.6473958492279053\n",
      "Epoch 1 - Batch 75 - Loss 0.9856375408800024 - Accuracy 0.6478207111358643\n",
      "Epoch 1 - Batch 76 - Loss 0.9845944968136874 - Accuracy 0.6482346057891846\n",
      "Epoch 1 - Batch 77 - Loss 0.9839718089653895 - Accuracy 0.6486378312110901\n",
      "Epoch 1 - Batch 78 - Loss 0.9766038795815238 - Accuracy 0.6515032052993774\n",
      "Epoch 1 - Loss 0.9766038795815238 - Accuracy 0.6515032052993774\n",
      "Training...\n",
      "Epoch 2 - Batch 0 - Loss 0.8987665772438049 - Accuracy 0.7109375\n",
      "Epoch 2 - Batch 1 - Loss 0.8915875554084778 - Accuracy 0.7421875\n",
      "Epoch 2 - Batch 2 - Loss 0.908329427242279 - Accuracy 0.71875\n",
      "Epoch 2 - Batch 3 - Loss 0.9020881801843643 - Accuracy 0.720703125\n",
      "Epoch 2 - Batch 4 - Loss 0.8716397881507874 - Accuracy 0.721875011920929\n",
      "Epoch 2 - Batch 5 - Loss 0.86270871758461 - Accuracy 0.71875\n",
      "Epoch 2 - Batch 6 - Loss 0.859358378819057 - Accuracy 0.7198660969734192\n",
      "Epoch 2 - Batch 7 - Loss 0.841906450688839 - Accuracy 0.7275390625\n",
      "Epoch 2 - Batch 8 - Loss 0.8487894336382548 - Accuracy 0.7282986044883728\n",
      "Epoch 2 - Batch 9 - Loss 0.8238861739635468 - Accuracy 0.737500011920929\n",
      "Epoch 2 - Batch 10 - Loss 0.8264962976629083 - Accuracy 0.737926185131073\n",
      "Epoch 2 - Batch 11 - Loss 0.8318310876687368 - Accuracy 0.7330729365348816\n",
      "Epoch 2 - Batch 12 - Loss 0.8506445976404043 - Accuracy 0.7277644276618958\n",
      "Epoch 2 - Batch 13 - Loss 0.8475644205297742 - Accuracy 0.7282366156578064\n",
      "Epoch 2 - Batch 14 - Loss 0.8354140440622966 - Accuracy 0.7343750596046448\n",
      "Epoch 2 - Batch 15 - Loss 0.8471780568361282 - Accuracy 0.7275390625\n",
      "Epoch 2 - Batch 16 - Loss 0.8380457688780392 - Accuracy 0.7274816036224365\n",
      "Epoch 2 - Batch 17 - Loss 0.8330194287829928 - Accuracy 0.7282986044883728\n",
      "Epoch 2 - Batch 18 - Loss 0.8282282728897897 - Accuracy 0.7294408082962036\n",
      "Epoch 2 - Batch 19 - Loss 0.8221790760755538 - Accuracy 0.727343738079071\n",
      "Epoch 2 - Batch 20 - Loss 0.8118126250448681 - Accuracy 0.730654776096344\n",
      "Epoch 2 - Batch 21 - Loss 0.8104609251022339 - Accuracy 0.7315341234207153\n",
      "Epoch 2 - Batch 22 - Loss 0.8023518479388693 - Accuracy 0.733016312122345\n",
      "Epoch 2 - Batch 23 - Loss 0.8112333168586096 - Accuracy 0.7311198115348816\n",
      "Epoch 2 - Batch 24 - Loss 0.8047592401504516 - Accuracy 0.7331249713897705\n",
      "Epoch 2 - Batch 25 - Loss 0.8067626861425546 - Accuracy 0.732271671295166\n",
      "Epoch 2 - Batch 26 - Loss 0.8104442755381266 - Accuracy 0.7303240895271301\n",
      "Epoch 2 - Batch 27 - Loss 0.80543766277177 - Accuracy 0.731026828289032\n",
      "Epoch 2 - Batch 28 - Loss 0.8053481476060276 - Accuracy 0.7311422228813171\n",
      "Epoch 2 - Batch 29 - Loss 0.7985338648160298 - Accuracy 0.7315104603767395\n",
      "Epoch 2 - Batch 30 - Loss 0.7972100742401615 - Accuracy 0.7321068048477173\n",
      "Epoch 2 - Batch 31 - Loss 0.7990701049566269 - Accuracy 0.72900390625\n",
      "Epoch 2 - Batch 32 - Loss 0.8008021134318728 - Accuracy 0.7279829978942871\n",
      "Epoch 2 - Batch 33 - Loss 0.8000502411056968 - Accuracy 0.728630542755127\n",
      "Epoch 2 - Batch 34 - Loss 0.8015524387359619 - Accuracy 0.7285714149475098\n",
      "Epoch 2 - Batch 35 - Loss 0.8047460433509614 - Accuracy 0.7269965410232544\n",
      "Epoch 2 - Batch 36 - Loss 0.8028124425862286 - Accuracy 0.7284628748893738\n",
      "Epoch 2 - Batch 37 - Loss 0.8032228193785015 - Accuracy 0.7290295958518982\n",
      "Epoch 2 - Batch 38 - Loss 0.804298249574808 - Accuracy 0.7289663553237915\n",
      "Epoch 2 - Batch 39 - Loss 0.8050214305520058 - Accuracy 0.7289062738418579\n",
      "Epoch 2 - Batch 40 - Loss 0.8036446978406209 - Accuracy 0.7286584973335266\n",
      "Epoch 2 - Batch 41 - Loss 0.8034181836105528 - Accuracy 0.7284226417541504\n",
      "Epoch 2 - Batch 42 - Loss 0.806014989697656 - Accuracy 0.7274709343910217\n",
      "Epoch 2 - Batch 43 - Loss 0.8032325032082471 - Accuracy 0.7276278734207153\n",
      "Epoch 2 - Batch 44 - Loss 0.8007382697529263 - Accuracy 0.7276042103767395\n",
      "Epoch 2 - Batch 45 - Loss 0.801524430513382 - Accuracy 0.7265625\n",
      "Epoch 2 - Batch 46 - Loss 0.7958933698370102 - Accuracy 0.7288895845413208\n",
      "Epoch 2 - Batch 47 - Loss 0.795324037472407 - Accuracy 0.7283529043197632\n",
      "Epoch 2 - Batch 48 - Loss 0.7922700643539429 - Accuracy 0.7291135191917419\n",
      "Epoch 2 - Batch 49 - Loss 0.7881363213062287 - Accuracy 0.7306249737739563\n",
      "Epoch 2 - Batch 50 - Loss 0.7889579300786934 - Accuracy 0.7310049533843994\n",
      "Epoch 2 - Batch 51 - Loss 0.7882094635413244 - Accuracy 0.7309194803237915\n",
      "Epoch 2 - Batch 52 - Loss 0.7885407726719694 - Accuracy 0.731869101524353\n",
      "Epoch 2 - Batch 53 - Loss 0.7888216574986776 - Accuracy 0.7313368320465088\n",
      "Epoch 2 - Batch 54 - Loss 0.7862249406901273 - Accuracy 0.7322443127632141\n",
      "Epoch 2 - Batch 55 - Loss 0.7860772907733917 - Accuracy 0.7322824001312256\n",
      "Epoch 2 - Batch 56 - Loss 0.7833136236458494 - Accuracy 0.7334156036376953\n",
      "Epoch 2 - Batch 57 - Loss 0.7817547485746187 - Accuracy 0.7338362336158752\n",
      "Epoch 2 - Batch 58 - Loss 0.7815154528213759 - Accuracy 0.733712911605835\n",
      "Epoch 2 - Batch 59 - Loss 0.7817781219879786 - Accuracy 0.7330729365348816\n",
      "Epoch 2 - Batch 60 - Loss 0.7825005621206566 - Accuracy 0.7330942153930664\n",
      "Epoch 2 - Batch 61 - Loss 0.783113548832555 - Accuracy 0.7327368855476379\n",
      "Epoch 2 - Batch 62 - Loss 0.7824237280421786 - Accuracy 0.7332589626312256\n",
      "Epoch 2 - Batch 63 - Loss 0.7804904887452722 - Accuracy 0.73388671875\n",
      "Epoch 2 - Batch 64 - Loss 0.7787716086094196 - Accuracy 0.7346153855323792\n",
      "Epoch 2 - Batch 65 - Loss 0.7769201099872589 - Accuracy 0.7349668741226196\n",
      "Epoch 2 - Batch 66 - Loss 0.7774316819746103 - Accuracy 0.7350746393203735\n",
      "Epoch 2 - Batch 67 - Loss 0.7771326671628391 - Accuracy 0.7350643277168274\n",
      "Epoch 2 - Batch 68 - Loss 0.7776416082313096 - Accuracy 0.7352808117866516\n",
      "Epoch 2 - Batch 69 - Loss 0.7769597939082554 - Accuracy 0.7356026768684387\n",
      "Epoch 2 - Batch 70 - Loss 0.7769448589271223 - Accuracy 0.7350351810455322\n",
      "Epoch 2 - Batch 71 - Loss 0.7764433556132846 - Accuracy 0.7347005009651184\n",
      "Epoch 2 - Batch 72 - Loss 0.7764736242490272 - Accuracy 0.7350171208381653\n",
      "Epoch 2 - Batch 73 - Loss 0.7757241597046723 - Accuracy 0.7359586358070374\n",
      "Epoch 2 - Batch 74 - Loss 0.7752179511388143 - Accuracy 0.7361458539962769\n",
      "Epoch 2 - Batch 75 - Loss 0.7747950773490103 - Accuracy 0.7360197305679321\n",
      "Epoch 2 - Batch 76 - Loss 0.7742872315567809 - Accuracy 0.736201286315918\n",
      "Epoch 2 - Batch 77 - Loss 0.7740779595497327 - Accuracy 0.7360777258872986\n",
      "Epoch 2 - Batch 78 - Loss 0.7724337540095365 - Accuracy 0.7369462251663208\n",
      "Epoch 2 - Batch 79 - Loss 0.7715785712003708 - Accuracy 0.737109363079071\n",
      "Epoch 2 - Batch 80 - Loss 0.7717718769002844 - Accuracy 0.7364969253540039\n",
      "Epoch 2 - Batch 81 - Loss 0.7742025234350344 - Accuracy 0.7356135249137878\n",
      "Epoch 2 - Batch 82 - Loss 0.7739207543522478 - Accuracy 0.7357868552207947\n",
      "Epoch 2 - Batch 83 - Loss 0.772689448935645 - Accuracy 0.7350260615348816\n",
      "Epoch 2 - Batch 84 - Loss 0.7732469523654265 - Accuracy 0.7351102828979492\n",
      "Epoch 2 - Batch 85 - Loss 0.7736404974793278 - Accuracy 0.7345566749572754\n",
      "Epoch 2 - Batch 86 - Loss 0.7734434967753531 - Accuracy 0.7347341775894165\n",
      "Epoch 2 - Batch 87 - Loss 0.7716688032854687 - Accuracy 0.7348189353942871\n",
      "Epoch 2 - Batch 88 - Loss 0.7716090317522541 - Accuracy 0.7344627976417542\n",
      "Epoch 2 - Batch 89 - Loss 0.7694654583930969 - Accuracy 0.7354167103767395\n",
      "Epoch 2 - Batch 90 - Loss 0.7690386673906348 - Accuracy 0.7353193759918213\n",
      "Epoch 2 - Batch 91 - Loss 0.7679753342400426 - Accuracy 0.7355638742446899\n",
      "Epoch 2 - Batch 92 - Loss 0.7684453475859857 - Accuracy 0.7347950339317322\n",
      "Epoch 2 - Batch 93 - Loss 0.7666950859922044 - Accuracy 0.7350398898124695\n",
      "Epoch 2 - Batch 94 - Loss 0.7679075730474372 - Accuracy 0.7342105507850647\n",
      "Epoch 2 - Batch 95 - Loss 0.7672774611661831 - Accuracy 0.734619140625\n",
      "Epoch 2 - Batch 96 - Loss 0.7678054239332062 - Accuracy 0.7344555258750916\n",
      "Epoch 2 - Batch 97 - Loss 0.7683759714875903 - Accuracy 0.7342952489852905\n",
      "Epoch 2 - Batch 98 - Loss 0.7690589722960887 - Accuracy 0.7340593338012695\n",
      "Epoch 2 - Batch 99 - Loss 0.7691584330797195 - Accuracy 0.7339062094688416\n",
      "Epoch 2 - Batch 100 - Loss 0.7690100486915891 - Accuracy 0.7341429591178894\n",
      "Epoch 2 - Batch 101 - Loss 0.7686058317913729 - Accuracy 0.7338388562202454\n",
      "Epoch 2 - Batch 102 - Loss 0.7673298490857615 - Accuracy 0.7341474294662476\n",
      "Epoch 2 - Batch 103 - Loss 0.7683903116446275 - Accuracy 0.7336238026618958\n",
      "Epoch 2 - Batch 104 - Loss 0.7680679241816203 - Accuracy 0.7340030074119568\n",
      "Epoch 2 - Batch 105 - Loss 0.7677348807172956 - Accuracy 0.7340801954269409\n",
      "Epoch 2 - Batch 106 - Loss 0.7669860826474484 - Accuracy 0.734375\n",
      "Epoch 2 - Batch 107 - Loss 0.7679071255304195 - Accuracy 0.7338686585426331\n",
      "Epoch 2 - Batch 108 - Loss 0.7673894123199883 - Accuracy 0.7338732481002808\n",
      "Epoch 2 - Batch 109 - Loss 0.7663151367144151 - Accuracy 0.7338067889213562\n",
      "Epoch 2 - Batch 110 - Loss 0.7660018087507369 - Accuracy 0.7338119745254517\n",
      "Epoch 2 - Batch 111 - Loss 0.7659342432660716 - Accuracy 0.733956515789032\n",
      "Epoch 2 - Batch 112 - Loss 0.7663663082418188 - Accuracy 0.7337527871131897\n",
      "Epoch 2 - Batch 113 - Loss 0.7654286586401755 - Accuracy 0.7339638471603394\n",
      "Epoch 2 - Batch 114 - Loss 0.765557617208232 - Accuracy 0.7339673638343811\n",
      "Epoch 2 - Batch 115 - Loss 0.7648995662557667 - Accuracy 0.7341055870056152\n",
      "Epoch 2 - Batch 116 - Loss 0.765090289278927 - Accuracy 0.7341747283935547\n",
      "Epoch 2 - Batch 117 - Loss 0.7648884315611952 - Accuracy 0.7344412207603455\n",
      "Epoch 2 - Batch 118 - Loss 0.7646723329520025 - Accuracy 0.7342437505722046\n",
      "Epoch 2 - Batch 119 - Loss 0.764279730618 - Accuracy 0.7342448234558105\n",
      "Epoch 2 - Batch 120 - Loss 0.7635416225953535 - Accuracy 0.734633207321167\n",
      "Epoch 2 - Batch 121 - Loss 0.7638963807801731 - Accuracy 0.7349513173103333\n",
      "Epoch 2 - Batch 122 - Loss 0.7632576193266768 - Accuracy 0.734946608543396\n",
      "Epoch 2 - Batch 123 - Loss 0.7624916862095555 - Accuracy 0.735446035861969\n",
      "Epoch 2 - Batch 124 - Loss 0.763492202758789 - Accuracy 0.7350625395774841\n",
      "Epoch 2 - Batch 125 - Loss 0.7626436016862355 - Accuracy 0.7354910969734192\n",
      "Epoch 2 - Batch 126 - Loss 0.7621889255178256 - Accuracy 0.735666811466217\n",
      "Epoch 2 - Batch 127 - Loss 0.7614756966941059 - Accuracy 0.7357177734375\n",
      "Epoch 2 - Batch 128 - Loss 0.7614738114120424 - Accuracy 0.7357073426246643\n",
      "Epoch 2 - Batch 129 - Loss 0.7625499972930321 - Accuracy 0.735276460647583\n",
      "Epoch 2 - Batch 130 - Loss 0.7618747098755291 - Accuracy 0.7353292107582092\n",
      "Epoch 2 - Batch 131 - Loss 0.7607694715261459 - Accuracy 0.7356179356575012\n",
      "Epoch 2 - Batch 132 - Loss 0.7597350218242273 - Accuracy 0.7359022498130798\n",
      "Epoch 2 - Batch 133 - Loss 0.7598129399676821 - Accuracy 0.7360657453536987\n",
      "Epoch 2 - Batch 134 - Loss 0.7587356474664476 - Accuracy 0.7365740537643433\n",
      "Epoch 2 - Batch 135 - Loss 0.7587754976223496 - Accuracy 0.7367302179336548\n",
      "Epoch 2 - Batch 136 - Loss 0.7587437533984219 - Accuracy 0.7368270754814148\n",
      "Epoch 2 - Batch 137 - Loss 0.7581693568955297 - Accuracy 0.736922562122345\n",
      "Epoch 2 - Batch 138 - Loss 0.7586044416153174 - Accuracy 0.736623227596283\n",
      "Epoch 2 - Batch 139 - Loss 0.757652564559664 - Accuracy 0.7366071343421936\n",
      "Epoch 2 - Batch 140 - Loss 0.758147343253413 - Accuracy 0.736258864402771\n",
      "Epoch 2 - Batch 141 - Loss 0.7571679164826031 - Accuracy 0.7363556027412415\n",
      "Epoch 2 - Batch 142 - Loss 0.757232129573822 - Accuracy 0.736068606376648\n",
      "Epoch 2 - Batch 143 - Loss 0.7570536649889417 - Accuracy 0.7362738847732544\n",
      "Epoch 2 - Batch 144 - Loss 0.7577166257233455 - Accuracy 0.7361530065536499\n",
      "Epoch 2 - Batch 145 - Loss 0.7577208905187371 - Accuracy 0.7363013625144958\n",
      "Epoch 2 - Batch 146 - Loss 0.7578263436855913 - Accuracy 0.7363945245742798\n",
      "Epoch 2 - Batch 147 - Loss 0.7583369089139474 - Accuracy 0.736328125\n",
      "Epoch 2 - Batch 148 - Loss 0.7584098313478815 - Accuracy 0.7362101674079895\n",
      "Epoch 2 - Batch 149 - Loss 0.7585342200597127 - Accuracy 0.7361458539962769\n",
      "Epoch 2 - Batch 150 - Loss 0.7584006360035069 - Accuracy 0.7361858487129211\n",
      "Epoch 2 - Batch 151 - Loss 0.757477196423631 - Accuracy 0.7366878986358643\n",
      "Epoch 2 - Batch 152 - Loss 0.7579236692852445 - Accuracy 0.7366217374801636\n",
      "Epoch 2 - Batch 153 - Loss 0.7584900565735706 - Accuracy 0.7366071343421936\n",
      "Epoch 2 - Batch 154 - Loss 0.758458770859626 - Accuracy 0.7363407015800476\n",
      "Epoch 2 - Batch 155 - Loss 0.758284086218247 - Accuracy 0.7363781929016113\n",
      "Epoch 2 - Batch 156 - Loss 0.7585250602406302 - Accuracy 0.7365645170211792\n",
      "Epoch 2 - Batch 157 - Loss 0.7587159524990034 - Accuracy 0.7365506291389465\n",
      "Epoch 2 - Batch 158 - Loss 0.7591242291642435 - Accuracy 0.7365860342979431\n",
      "Epoch 2 - Batch 159 - Loss 0.7585279405117035 - Accuracy 0.736621081829071\n",
      "Epoch 2 - Batch 160 - Loss 0.7577562013768261 - Accuracy 0.736801266670227\n",
      "Epoch 2 - Batch 161 - Loss 0.7583327698118892 - Accuracy 0.7364969253540039\n",
      "Epoch 2 - Batch 162 - Loss 0.7580318948242561 - Accuracy 0.7364359498023987\n",
      "Epoch 2 - Batch 163 - Loss 0.7578204597641782 - Accuracy 0.7365186214447021\n",
      "Epoch 2 - Batch 164 - Loss 0.7571491331765146 - Accuracy 0.736742377281189\n",
      "Epoch 2 - Batch 165 - Loss 0.7562826588211289 - Accuracy 0.736822247505188\n",
      "Epoch 2 - Batch 166 - Loss 0.7559848017321376 - Accuracy 0.7369012236595154\n",
      "Epoch 2 - Batch 167 - Loss 0.7568957145724978 - Accuracy 0.7365606427192688\n",
      "Epoch 2 - Batch 168 - Loss 0.756052908460064 - Accuracy 0.7366401553153992\n",
      "Epoch 2 - Batch 169 - Loss 0.7556990062489229 - Accuracy 0.7367187738418579\n",
      "Epoch 2 - Batch 170 - Loss 0.7560567622296295 - Accuracy 0.7365223169326782\n",
      "Epoch 2 - Batch 171 - Loss 0.7553525497747022 - Accuracy 0.7365552186965942\n",
      "Epoch 2 - Batch 172 - Loss 0.7547440766599137 - Accuracy 0.7365426421165466\n",
      "Epoch 2 - Batch 173 - Loss 0.7541793184033756 - Accuracy 0.736664891242981\n",
      "Epoch 2 - Batch 174 - Loss 0.7536190060206822 - Accuracy 0.7369642853736877\n",
      "Epoch 2 - Batch 175 - Loss 0.7533348609100688 - Accuracy 0.7368608117103577\n",
      "Epoch 2 - Batch 176 - Loss 0.7526902044560276 - Accuracy 0.736935019493103\n",
      "Epoch 2 - Batch 177 - Loss 0.752140806297238 - Accuracy 0.737052321434021\n",
      "Epoch 2 - Batch 178 - Loss 0.7521734940273136 - Accuracy 0.7370373606681824\n",
      "Epoch 2 - Batch 179 - Loss 0.7513312356339561 - Accuracy 0.7372395992279053\n",
      "Epoch 2 - Batch 180 - Loss 0.7504505742320698 - Accuracy 0.7376554012298584\n",
      "Epoch 2 - Batch 181 - Loss 0.7499317186219352 - Accuracy 0.7378520369529724\n",
      "Epoch 2 - Batch 182 - Loss 0.7488200869716581 - Accuracy 0.7381744980812073\n",
      "Epoch 2 - Batch 183 - Loss 0.7491125535705815 - Accuracy 0.7379840612411499\n",
      "Epoch 2 - Batch 184 - Loss 0.7486475950962789 - Accuracy 0.7380067706108093\n",
      "Epoch 2 - Batch 185 - Loss 0.7483477554013652 - Accuracy 0.7380712628364563\n",
      "Epoch 2 - Batch 186 - Loss 0.7475602005254776 - Accuracy 0.7384692430496216\n",
      "Epoch 2 - Batch 187 - Loss 0.7471816945583263 - Accuracy 0.7384058833122253\n",
      "Epoch 2 - Batch 188 - Loss 0.7463649978082647 - Accuracy 0.7384672164916992\n",
      "Epoch 2 - Batch 189 - Loss 0.7462262228915566 - Accuracy 0.738322377204895\n",
      "Epoch 2 - Batch 190 - Loss 0.7466688206058523 - Accuracy 0.738547146320343\n",
      "Epoch 2 - Batch 191 - Loss 0.7465809515366951 - Accuracy 0.73876953125\n",
      "Epoch 2 - Batch 192 - Loss 0.7459595580175133 - Accuracy 0.7388681769371033\n",
      "Epoch 2 - Batch 193 - Loss 0.7461797217118371 - Accuracy 0.7386839389801025\n",
      "Epoch 2 - Batch 194 - Loss 0.7461285640031864 - Accuracy 0.7386618852615356\n",
      "Epoch 2 - Batch 195 - Loss 0.7455344638045953 - Accuracy 0.7389190196990967\n",
      "Epoch 2 - Batch 196 - Loss 0.7451850160729462 - Accuracy 0.739133894443512\n",
      "Epoch 2 - Batch 197 - Loss 0.7451395437572942 - Accuracy 0.7393465638160706\n",
      "Epoch 2 - Batch 198 - Loss 0.7446171701253959 - Accuracy 0.7396749258041382\n",
      "Epoch 2 - Batch 199 - Loss 0.7451763656735421 - Accuracy 0.7397655844688416\n",
      "Epoch 2 - Batch 200 - Loss 0.745149371339314 - Accuracy 0.7399331331253052\n",
      "Epoch 2 - Batch 201 - Loss 0.7441832998601516 - Accuracy 0.7403697371482849\n",
      "Epoch 2 - Batch 202 - Loss 0.7443631297261845 - Accuracy 0.7402632236480713\n",
      "Epoch 2 - Batch 203 - Loss 0.7436962998380848 - Accuracy 0.7403109669685364\n",
      "Epoch 2 - Batch 204 - Loss 0.7431256198301548 - Accuracy 0.740434467792511\n",
      "Epoch 2 - Batch 205 - Loss 0.7430947003434005 - Accuracy 0.7405567169189453\n",
      "Epoch 2 - Batch 206 - Loss 0.7427226477775021 - Accuracy 0.7407910823822021\n",
      "Epoch 2 - Batch 207 - Loss 0.7428266030664628 - Accuracy 0.7406851053237915\n",
      "Epoch 2 - Batch 208 - Loss 0.7425644289363514 - Accuracy 0.7406922578811646\n",
      "Epoch 2 - Batch 209 - Loss 0.743433099701291 - Accuracy 0.7404389977455139\n",
      "Epoch 2 - Batch 210 - Loss 0.7439421178040346 - Accuracy 0.7403362393379211\n",
      "Epoch 2 - Batch 211 - Loss 0.7440844116345892 - Accuracy 0.7403081059455872\n",
      "Epoch 2 - Batch 212 - Loss 0.7444026475781006 - Accuracy 0.7402802109718323\n",
      "Epoch 2 - Batch 213 - Loss 0.7436408879600953 - Accuracy 0.740398645401001\n",
      "Epoch 2 - Batch 214 - Loss 0.7436838477156883 - Accuracy 0.7403706312179565\n",
      "Epoch 2 - Batch 215 - Loss 0.7431919400890669 - Accuracy 0.7406684160232544\n",
      "Epoch 2 - Batch 216 - Loss 0.7426783217263112 - Accuracy 0.7407473921775818\n",
      "Epoch 2 - Batch 217 - Loss 0.7423219858506404 - Accuracy 0.7407181262969971\n",
      "Epoch 2 - Batch 218 - Loss 0.7414985922373594 - Accuracy 0.7409389019012451\n",
      "Epoch 2 - Batch 219 - Loss 0.7410289447415959 - Accuracy 0.7409800887107849\n",
      "Epoch 2 - Batch 220 - Loss 0.7401429846275985 - Accuracy 0.7411623597145081\n",
      "Epoch 2 - Batch 221 - Loss 0.7397484228954659 - Accuracy 0.741378128528595\n",
      "Epoch 2 - Batch 222 - Loss 0.740052096779571 - Accuracy 0.7413467168807983\n",
      "Epoch 2 - Batch 223 - Loss 0.7397639597100871 - Accuracy 0.7413853406906128\n",
      "Epoch 2 - Batch 224 - Loss 0.739816235171424 - Accuracy 0.7413541674613953\n",
      "Epoch 2 - Batch 225 - Loss 0.7394245396145677 - Accuracy 0.7413232922554016\n",
      "Epoch 2 - Batch 226 - Loss 0.7392970859216699 - Accuracy 0.7413270473480225\n",
      "Epoch 2 - Batch 227 - Loss 0.7399173642982516 - Accuracy 0.7409881949424744\n",
      "Epoch 2 - Batch 228 - Loss 0.7399973596027324 - Accuracy 0.7408229112625122\n",
      "Epoch 2 - Batch 229 - Loss 0.739682639422624 - Accuracy 0.7408967018127441\n",
      "Epoch 2 - Batch 230 - Loss 0.7387928309894743 - Accuracy 0.741274356842041\n",
      "Epoch 2 - Batch 231 - Loss 0.7389304368146534 - Accuracy 0.7412446141242981\n",
      "Epoch 2 - Batch 232 - Loss 0.7383395643193322 - Accuracy 0.7413492202758789\n",
      "Epoch 2 - Batch 233 - Loss 0.7381401747210413 - Accuracy 0.7414196133613586\n",
      "Epoch 2 - Batch 234 - Loss 0.7373745228381867 - Accuracy 0.7417553067207336\n",
      "Epoch 2 - Batch 235 - Loss 0.7376589898840856 - Accuracy 0.7416578531265259\n",
      "Epoch 2 - Batch 236 - Loss 0.7367963888977147 - Accuracy 0.7420226335525513\n",
      "Epoch 2 - Batch 237 - Loss 0.7362430558986023 - Accuracy 0.7422531843185425\n",
      "Epoch 2 - Batch 238 - Loss 0.7362585683746816 - Accuracy 0.7422855496406555\n",
      "Epoch 2 - Batch 239 - Loss 0.7367040735979875 - Accuracy 0.7420573234558105\n",
      "Epoch 2 - Batch 240 - Loss 0.7368189452594741 - Accuracy 0.7418309450149536\n",
      "Epoch 2 - Batch 241 - Loss 0.7365169682778603 - Accuracy 0.74199378490448\n",
      "Epoch 2 - Batch 242 - Loss 0.7364701417738518 - Accuracy 0.7419945597648621\n",
      "Epoch 2 - Batch 243 - Loss 0.7367202016662379 - Accuracy 0.7418032288551331\n",
      "Epoch 2 - Batch 244 - Loss 0.7360512171472822 - Accuracy 0.7421236634254456\n",
      "Epoch 2 - Batch 245 - Loss 0.736265379238904 - Accuracy 0.7420604228973389\n",
      "Epoch 2 - Batch 246 - Loss 0.7362348287694367 - Accuracy 0.7419977188110352\n",
      "Epoch 2 - Batch 247 - Loss 0.7362738090657419 - Accuracy 0.7418724298477173\n",
      "Epoch 2 - Batch 248 - Loss 0.7360642763026747 - Accuracy 0.7417795658111572\n",
      "Epoch 2 - Batch 249 - Loss 0.7362695872783661 - Accuracy 0.7417812943458557\n",
      "Epoch 2 - Batch 250 - Loss 0.7360912934242492 - Accuracy 0.7418140172958374\n",
      "Epoch 2 - Batch 251 - Loss 0.7366829230671837 - Accuracy 0.7417845129966736\n",
      "Epoch 2 - Batch 252 - Loss 0.7367831360210072 - Accuracy 0.7417861223220825\n",
      "Epoch 2 - Batch 253 - Loss 0.7370887337707159 - Accuracy 0.7416953444480896\n",
      "Epoch 2 - Batch 254 - Loss 0.7366453617226844 - Accuracy 0.7418811917304993\n",
      "Epoch 2 - Batch 255 - Loss 0.7361649277154356 - Accuracy 0.741973876953125\n",
      "Epoch 2 - Batch 256 - Loss 0.7363349510074125 - Accuracy 0.7422482967376709\n",
      "Epoch 2 - Batch 257 - Loss 0.7361915603626606 - Accuracy 0.7423388957977295\n",
      "Epoch 2 - Batch 258 - Loss 0.7365563194263856 - Accuracy 0.7423081398010254\n",
      "Epoch 2 - Batch 259 - Loss 0.7359812793823389 - Accuracy 0.7424879670143127\n",
      "Epoch 2 - Batch 260 - Loss 0.7362392519625668 - Accuracy 0.742337167263031\n",
      "Epoch 2 - Batch 261 - Loss 0.7366617481217129 - Accuracy 0.7420682311058044\n",
      "Epoch 2 - Batch 262 - Loss 0.7370289697846533 - Accuracy 0.7419498562812805\n",
      "Epoch 2 - Batch 263 - Loss 0.7364077640302253 - Accuracy 0.7423058748245239\n",
      "Epoch 2 - Batch 264 - Loss 0.7362617231764883 - Accuracy 0.7423644065856934\n",
      "Epoch 2 - Batch 265 - Loss 0.7367573593344007 - Accuracy 0.7422168850898743\n",
      "Epoch 2 - Batch 266 - Loss 0.7358854709939564 - Accuracy 0.7425386309623718\n",
      "Epoch 2 - Batch 267 - Loss 0.73545014658081 - Accuracy 0.7426539063453674\n",
      "Epoch 2 - Batch 268 - Loss 0.7360295086101971 - Accuracy 0.7424488663673401\n",
      "Epoch 2 - Batch 269 - Loss 0.7362758899176562 - Accuracy 0.7423032522201538\n",
      "Epoch 2 - Batch 270 - Loss 0.736242800621089 - Accuracy 0.7423893213272095\n",
      "Epoch 2 - Batch 271 - Loss 0.7359193101087037 - Accuracy 0.7425321936607361\n",
      "Epoch 2 - Batch 272 - Loss 0.7353764438367152 - Accuracy 0.7426739931106567\n",
      "Epoch 2 - Batch 273 - Loss 0.735667104051061 - Accuracy 0.7426722049713135\n",
      "Epoch 2 - Batch 274 - Loss 0.735968664559451 - Accuracy 0.7426136136054993\n",
      "Epoch 2 - Batch 275 - Loss 0.7356961116842602 - Accuracy 0.7427253127098083\n",
      "Epoch 2 - Batch 276 - Loss 0.7353140257756202 - Accuracy 0.7429772019386292\n",
      "Epoch 2 - Batch 277 - Loss 0.734779227122986 - Accuracy 0.7431710958480835\n",
      "Epoch 2 - Batch 278 - Loss 0.7345615648881509 - Accuracy 0.7432515621185303\n",
      "Epoch 2 - Batch 279 - Loss 0.7343835400683539 - Accuracy 0.7432198524475098\n",
      "Epoch 2 - Batch 280 - Loss 0.7341236964239345 - Accuracy 0.7432717680931091\n",
      "Epoch 2 - Batch 281 - Loss 0.7339727684115687 - Accuracy 0.7433510422706604\n",
      "Epoch 2 - Batch 282 - Loss 0.7335646586367603 - Accuracy 0.7434849739074707\n",
      "Epoch 2 - Batch 283 - Loss 0.7329658975063915 - Accuracy 0.7437829971313477\n",
      "Epoch 2 - Batch 284 - Loss 0.7328669079563074 - Accuracy 0.7437500357627869\n",
      "Epoch 2 - Batch 285 - Loss 0.7324384434239848 - Accuracy 0.7439084053039551\n",
      "Epoch 2 - Batch 286 - Loss 0.7321616124608376 - Accuracy 0.7439568638801575\n",
      "Epoch 2 - Batch 287 - Loss 0.731926549019085 - Accuracy 0.7439778447151184\n",
      "Epoch 2 - Batch 288 - Loss 0.732538240591135 - Accuracy 0.7436743378639221\n",
      "Epoch 2 - Batch 289 - Loss 0.7323723560777203 - Accuracy 0.7437769174575806\n",
      "Epoch 2 - Batch 290 - Loss 0.7325539439404544 - Accuracy 0.7439325451850891\n",
      "Epoch 2 - Batch 291 - Loss 0.7324151690692118 - Accuracy 0.7438730597496033\n",
      "Epoch 2 - Batch 292 - Loss 0.7324425238391238 - Accuracy 0.7438672780990601\n",
      "Epoch 2 - Batch 293 - Loss 0.7319107726723159 - Accuracy 0.7441007494926453\n",
      "Epoch 2 - Batch 294 - Loss 0.7321223200377771 - Accuracy 0.7441472411155701\n",
      "Epoch 2 - Batch 295 - Loss 0.7318245061748737 - Accuracy 0.7443253993988037\n",
      "Epoch 2 - Batch 296 - Loss 0.7320468453847198 - Accuracy 0.744107723236084\n",
      "Epoch 2 - Batch 297 - Loss 0.7318542165644217 - Accuracy 0.744337260723114\n",
      "Epoch 2 - Batch 298 - Loss 0.7316374310282959 - Accuracy 0.7443039417266846\n",
      "Epoch 2 - Batch 299 - Loss 0.7313850895563762 - Accuracy 0.7443749904632568\n",
      "Epoch 2 - Batch 300 - Loss 0.7310484964586176 - Accuracy 0.744471549987793\n",
      "Epoch 2 - Batch 301 - Loss 0.7311260319308729 - Accuracy 0.7445157170295715\n",
      "Epoch 2 - Batch 302 - Loss 0.7309250145068656 - Accuracy 0.7446112036705017\n",
      "Epoch 2 - Batch 303 - Loss 0.7301900931879094 - Accuracy 0.7447574138641357\n",
      "Epoch 2 - Batch 304 - Loss 0.729758589971261 - Accuracy 0.7449538707733154\n",
      "Epoch 2 - Batch 305 - Loss 0.729747950056799 - Accuracy 0.7449703812599182\n",
      "Epoch 2 - Batch 306 - Loss 0.7297313157044327 - Accuracy 0.7450121641159058\n",
      "Epoch 2 - Batch 307 - Loss 0.7298227281539471 - Accuracy 0.745053768157959\n",
      "Epoch 2 - Batch 308 - Loss 0.7298778889634463 - Accuracy 0.7450950741767883\n",
      "Epoch 2 - Batch 309 - Loss 0.7295874486046453 - Accuracy 0.7451612949371338\n",
      "Epoch 2 - Batch 310 - Loss 0.7295453195786553 - Accuracy 0.7451768517494202\n",
      "Epoch 2 - Batch 311 - Loss 0.7293718478236443 - Accuracy 0.7452173829078674\n",
      "Epoch 2 - Batch 312 - Loss 0.7290270322808823 - Accuracy 0.7454822063446045\n",
      "Epoch 2 - Batch 313 - Loss 0.7291231200953198 - Accuracy 0.7454468607902527\n",
      "Epoch 2 - Batch 314 - Loss 0.7290417917191037 - Accuracy 0.7453868985176086\n",
      "Epoch 2 - Batch 315 - Loss 0.7289115467780753 - Accuracy 0.7454509735107422\n",
      "Epoch 2 - Batch 316 - Loss 0.7287881539823129 - Accuracy 0.7455639243125916\n",
      "Epoch 2 - Batch 317 - Loss 0.728971541865067 - Accuracy 0.7456514835357666\n",
      "Epoch 2 - Batch 318 - Loss 0.7284323365710745 - Accuracy 0.7457876205444336\n",
      "Epoch 2 - Batch 319 - Loss 0.7284578358754515 - Accuracy 0.745849609375\n",
      "Epoch 2 - Batch 320 - Loss 0.7283796859307452 - Accuracy 0.7458868622779846\n",
      "Epoch 2 - Batch 321 - Loss 0.7279540141176734 - Accuracy 0.7459967136383057\n",
      "Epoch 2 - Batch 322 - Loss 0.7280289134004906 - Accuracy 0.7458881139755249\n",
      "Epoch 2 - Batch 323 - Loss 0.7277777115871877 - Accuracy 0.74609375\n",
      "Epoch 2 - Batch 324 - Loss 0.727907121181488 - Accuracy 0.7462019324302673\n",
      "Epoch 2 - Batch 325 - Loss 0.727639571106507 - Accuracy 0.7462854385375977\n",
      "Epoch 2 - Batch 326 - Loss 0.7273152408614436 - Accuracy 0.7463446259498596\n",
      "Epoch 2 - Batch 327 - Loss 0.7275861965083494 - Accuracy 0.7462128400802612\n",
      "Epoch 2 - Batch 328 - Loss 0.7279373307720869 - Accuracy 0.7460581660270691\n",
      "Epoch 2 - Batch 329 - Loss 0.7276391097993562 - Accuracy 0.7461647391319275\n",
      "Epoch 2 - Batch 330 - Loss 0.7266539806145556 - Accuracy 0.7465068101882935\n",
      "Epoch 2 - Batch 331 - Loss 0.726279398314206 - Accuracy 0.7466819882392883\n",
      "Epoch 2 - Batch 332 - Loss 0.7267744540273249 - Accuracy 0.7464573979377747\n",
      "Epoch 2 - Batch 333 - Loss 0.726947127969679 - Accuracy 0.7463276982307434\n",
      "Epoch 2 - Batch 334 - Loss 0.7268836312329591 - Accuracy 0.7462686896324158\n",
      "Epoch 2 - Batch 335 - Loss 0.7277715109466087 - Accuracy 0.7460240125656128\n",
      "Epoch 2 - Batch 336 - Loss 0.7274935409117169 - Accuracy 0.7461053133010864\n",
      "Epoch 2 - Batch 337 - Loss 0.7272638108074312 - Accuracy 0.7462324500083923\n",
      "Epoch 2 - Batch 338 - Loss 0.7278157960524602 - Accuracy 0.7460361123085022\n",
      "Epoch 2 - Batch 339 - Loss 0.7275979698580854 - Accuracy 0.7459788918495178\n",
      "Epoch 2 - Batch 340 - Loss 0.7274088460154547 - Accuracy 0.7459448575973511\n",
      "Epoch 2 - Batch 341 - Loss 0.7271867773511953 - Accuracy 0.746070921421051\n",
      "Epoch 2 - Batch 342 - Loss 0.7271207750886244 - Accuracy 0.7460140585899353\n",
      "Epoch 2 - Batch 343 - Loss 0.7267877789604109 - Accuracy 0.7462072968482971\n",
      "Epoch 2 - Batch 344 - Loss 0.7267556982627813 - Accuracy 0.7462409734725952\n",
      "Epoch 2 - Batch 345 - Loss 0.7268086967268431 - Accuracy 0.7462066411972046\n",
      "Epoch 2 - Batch 346 - Loss 0.7264718431388953 - Accuracy 0.7465327382087708\n",
      "Epoch 2 - Batch 347 - Loss 0.7263121843851846 - Accuracy 0.7464978694915771\n",
      "Epoch 2 - Batch 348 - Loss 0.7261074763485217 - Accuracy 0.7466198205947876\n",
      "Epoch 2 - Batch 349 - Loss 0.7258347411666598 - Accuracy 0.7467857003211975\n",
      "Epoch 2 - Batch 350 - Loss 0.7258227174608116 - Accuracy 0.7468394041061401\n",
      "Epoch 2 - Batch 351 - Loss 0.7257470016960393 - Accuracy 0.7468705773353577\n",
      "Epoch 2 - Batch 352 - Loss 0.725548825166043 - Accuracy 0.7468793988227844\n",
      "Epoch 2 - Batch 353 - Loss 0.7258540337200219 - Accuracy 0.7468220591545105\n",
      "Epoch 2 - Batch 354 - Loss 0.7254974089038204 - Accuracy 0.7469409704208374\n",
      "Epoch 2 - Batch 355 - Loss 0.72540429125676 - Accuracy 0.747037410736084\n",
      "Epoch 2 - Batch 356 - Loss 0.7250297314145652 - Accuracy 0.7471332550048828\n",
      "Epoch 2 - Batch 357 - Loss 0.7248480587198748 - Accuracy 0.7471848726272583\n",
      "Epoch 2 - Batch 358 - Loss 0.7246181817938027 - Accuracy 0.7471491694450378\n",
      "Epoch 2 - Batch 359 - Loss 0.7244253710740143 - Accuracy 0.7472439408302307\n",
      "Epoch 2 - Batch 360 - Loss 0.723897285986475 - Accuracy 0.7474679350852966\n",
      "Epoch 2 - Batch 361 - Loss 0.723786944430836 - Accuracy 0.7474966049194336\n",
      "Epoch 2 - Batch 362 - Loss 0.7235845265802273 - Accuracy 0.7475249767303467\n",
      "Epoch 2 - Batch 363 - Loss 0.7236407817556307 - Accuracy 0.7474888563156128\n",
      "Epoch 2 - Batch 364 - Loss 0.7237253862701051 - Accuracy 0.7474743127822876\n",
      "Epoch 2 - Batch 365 - Loss 0.7236616898918412 - Accuracy 0.7474598288536072\n",
      "Epoch 2 - Batch 366 - Loss 0.7236005572109846 - Accuracy 0.7474880814552307\n",
      "Epoch 2 - Batch 367 - Loss 0.7235546329909045 - Accuracy 0.7475161552429199\n",
      "Epoch 2 - Batch 368 - Loss 0.7231336464565298 - Accuracy 0.7475440502166748\n",
      "Epoch 2 - Batch 369 - Loss 0.7227121813071741 - Accuracy 0.7476984858512878\n",
      "Epoch 2 - Batch 370 - Loss 0.722733564052299 - Accuracy 0.7477467656135559\n",
      "Epoch 2 - Batch 371 - Loss 0.7223707153111376 - Accuracy 0.7478788495063782\n",
      "Epoch 2 - Batch 372 - Loss 0.7222006588614978 - Accuracy 0.7479473948478699\n",
      "Epoch 2 - Batch 373 - Loss 0.7221509889963477 - Accuracy 0.7479110956192017\n",
      "Epoch 2 - Batch 374 - Loss 0.7220038588047027 - Accuracy 0.7478958368301392\n",
      "Epoch 2 - Batch 375 - Loss 0.7223544424360103 - Accuracy 0.7478806376457214\n",
      "Epoch 2 - Batch 376 - Loss 0.7222303665126982 - Accuracy 0.7478448152542114\n",
      "Epoch 2 - Batch 377 - Loss 0.7216555745040298 - Accuracy 0.7480365037918091\n",
      "Epoch 2 - Batch 378 - Loss 0.7210362111672877 - Accuracy 0.7481860518455505\n",
      "Epoch 2 - Batch 379 - Loss 0.7207848004604641 - Accuracy 0.7482319474220276\n",
      "Epoch 2 - Batch 380 - Loss 0.7204672156043566 - Accuracy 0.7483800649642944\n",
      "Epoch 2 - Batch 381 - Loss 0.7198113896615842 - Accuracy 0.7484865784645081\n",
      "Epoch 2 - Batch 382 - Loss 0.7192638971631272 - Accuracy 0.7487149238586426\n",
      "Epoch 2 - Batch 383 - Loss 0.7185395411215723 - Accuracy 0.7489420771598816\n",
      "Epoch 2 - Batch 384 - Loss 0.7179711830306362 - Accuracy 0.7491071224212646\n",
      "Epoch 2 - Batch 385 - Loss 0.718197739572105 - Accuracy 0.7490487098693848\n",
      "Epoch 2 - Batch 386 - Loss 0.7177683736464774 - Accuracy 0.7490915656089783\n",
      "Epoch 2 - Batch 387 - Loss 0.7179413005402407 - Accuracy 0.749033510684967\n",
      "Epoch 2 - Batch 388 - Loss 0.717542133708233 - Accuracy 0.7491966485977173\n",
      "Epoch 2 - Batch 389 - Loss 0.716975378149595 - Accuracy 0.7493389844894409\n",
      "Epoch 2 - Batch 390 - Loss 0.7167399962387426 - Accuracy 0.7495004534721375\n",
      "Epoch 2 - Loss 0.7167399962387426 - Accuracy 0.7495004534721375\n",
      "Testing...\n",
      "Epoch 2 - Batch 0 - Loss 1.5209237337112427 - Accuracy 0.4140625\n",
      "Epoch 2 - Batch 1 - Loss 1.5399114489555359 - Accuracy 0.4140625\n",
      "Epoch 2 - Batch 2 - Loss 1.459730625152588 - Accuracy 0.4635416865348816\n",
      "Epoch 2 - Batch 3 - Loss 1.4347085058689117 - Accuracy 0.48046875\n",
      "Epoch 2 - Batch 4 - Loss 1.3632007122039795 - Accuracy 0.4921875\n",
      "Epoch 2 - Batch 5 - Loss 1.3561707536379497 - Accuracy 0.5013021230697632\n",
      "Epoch 2 - Batch 6 - Loss 1.3215080329350062 - Accuracy 0.5145089626312256\n",
      "Epoch 2 - Batch 7 - Loss 1.266360618174076 - Accuracy 0.53515625\n",
      "Epoch 2 - Batch 8 - Loss 1.2561581863297357 - Accuracy 0.5390625\n",
      "Epoch 2 - Batch 9 - Loss 1.2430939853191376 - Accuracy 0.543749988079071\n",
      "Epoch 2 - Batch 10 - Loss 1.2277750914747065 - Accuracy 0.5461648106575012\n",
      "Epoch 2 - Batch 11 - Loss 1.2068496843179066 - Accuracy 0.5559896230697632\n",
      "Epoch 2 - Batch 12 - Loss 1.1858594646820655 - Accuracy 0.5661057829856873\n",
      "Epoch 2 - Batch 13 - Loss 1.1769894233771734 - Accuracy 0.5680803656578064\n",
      "Epoch 2 - Batch 14 - Loss 1.170973551273346 - Accuracy 0.5744792222976685\n",
      "Epoch 2 - Batch 15 - Loss 1.1596162542700768 - Accuracy 0.5791015625\n",
      "Epoch 2 - Batch 16 - Loss 1.1495105519014246 - Accuracy 0.5845588445663452\n",
      "Epoch 2 - Batch 17 - Loss 1.1472360690434773 - Accuracy 0.5863715410232544\n",
      "Epoch 2 - Batch 18 - Loss 1.137030868153823 - Accuracy 0.5900493264198303\n",
      "Epoch 2 - Batch 19 - Loss 1.133144035935402 - Accuracy 0.5933594107627869\n",
      "Epoch 2 - Batch 20 - Loss 1.1241759061813354 - Accuracy 0.5959821343421936\n",
      "Epoch 2 - Batch 21 - Loss 1.1182691780003635 - Accuracy 0.5994318127632141\n",
      "Epoch 2 - Batch 22 - Loss 1.1110123680985493 - Accuracy 0.6039402484893799\n",
      "Epoch 2 - Batch 23 - Loss 1.105841726064682 - Accuracy 0.6067708730697632\n",
      "Epoch 2 - Batch 24 - Loss 1.097261562347412 - Accuracy 0.6106249690055847\n",
      "Epoch 2 - Batch 25 - Loss 1.0920730026868672 - Accuracy 0.6126803159713745\n",
      "Epoch 2 - Batch 26 - Loss 1.0876490893187347 - Accuracy 0.6157407164573669\n",
      "Epoch 2 - Batch 27 - Loss 1.0794577172824316 - Accuracy 0.6188616156578064\n",
      "Epoch 2 - Batch 28 - Loss 1.0729004925694958 - Accuracy 0.6212284564971924\n",
      "Epoch 2 - Batch 29 - Loss 1.0646389206250508 - Accuracy 0.624218761920929\n",
      "Epoch 2 - Batch 30 - Loss 1.0541737137302276 - Accuracy 0.6282761693000793\n",
      "Epoch 2 - Batch 31 - Loss 1.045996917411685 - Accuracy 0.63232421875\n",
      "Epoch 2 - Batch 32 - Loss 1.0380152825153235 - Accuracy 0.6361269354820251\n",
      "Epoch 2 - Batch 33 - Loss 1.0314786732196808 - Accuracy 0.6394761204719543\n",
      "Epoch 2 - Batch 34 - Loss 1.0268642544746398 - Accuracy 0.6412946581840515\n",
      "Epoch 2 - Batch 35 - Loss 1.0216806050803926 - Accuracy 0.6423611044883728\n",
      "Epoch 2 - Batch 36 - Loss 1.0150795160113155 - Accuracy 0.6442145705223083\n",
      "Epoch 2 - Batch 37 - Loss 1.00849922079789 - Accuracy 0.6461759805679321\n",
      "Epoch 2 - Batch 38 - Loss 1.003238436503288 - Accuracy 0.6474359035491943\n",
      "Epoch 2 - Batch 39 - Loss 0.997770169377327 - Accuracy 0.649609386920929\n",
      "Epoch 2 - Batch 40 - Loss 0.9939615813697257 - Accuracy 0.6505334973335266\n",
      "Epoch 2 - Batch 41 - Loss 0.9885308941205343 - Accuracy 0.6538318395614624\n",
      "Epoch 2 - Batch 42 - Loss 0.9842783365138742 - Accuracy 0.6544331312179565\n",
      "Epoch 2 - Batch 43 - Loss 0.9808731458403848 - Accuracy 0.6569602489471436\n",
      "Epoch 2 - Batch 44 - Loss 0.9732055955462986 - Accuracy 0.6597222089767456\n",
      "Epoch 2 - Batch 45 - Loss 0.968274297921554 - Accuracy 0.661514937877655\n",
      "Epoch 2 - Batch 46 - Loss 0.9667642737956758 - Accuracy 0.6615691184997559\n",
      "Epoch 2 - Batch 47 - Loss 0.9631379346052805 - Accuracy 0.6629232168197632\n",
      "Epoch 2 - Batch 48 - Loss 0.9606132264039955 - Accuracy 0.6634247303009033\n",
      "Epoch 2 - Batch 49 - Loss 0.9560640060901642 - Accuracy 0.6656249761581421\n",
      "Epoch 2 - Batch 50 - Loss 0.9537815288001416 - Accuracy 0.6663603186607361\n",
      "Epoch 2 - Batch 51 - Loss 0.9509415615063447 - Accuracy 0.6681190133094788\n",
      "Epoch 2 - Batch 52 - Loss 0.9490581897069823 - Accuracy 0.6684846878051758\n",
      "Epoch 2 - Batch 53 - Loss 0.9469239237131896 - Accuracy 0.6688368320465088\n",
      "Epoch 2 - Batch 54 - Loss 0.949457247690721 - Accuracy 0.6667613387107849\n",
      "Epoch 2 - Batch 55 - Loss 0.9468824927295957 - Accuracy 0.6676897406578064\n",
      "Epoch 2 - Batch 56 - Loss 0.9432734522903174 - Accuracy 0.6694079041481018\n",
      "Epoch 2 - Batch 57 - Loss 0.942232321048605 - Accuracy 0.6697198152542114\n",
      "Epoch 2 - Batch 58 - Loss 0.938121348114337 - Accuracy 0.6710805296897888\n",
      "Epoch 2 - Batch 59 - Loss 0.93506085673968 - Accuracy 0.6723958849906921\n",
      "Epoch 2 - Batch 60 - Loss 0.9326950946792227 - Accuracy 0.6728995442390442\n",
      "Epoch 2 - Batch 61 - Loss 0.9319910676248612 - Accuracy 0.6735131144523621\n",
      "Epoch 2 - Batch 62 - Loss 0.9304566846953498 - Accuracy 0.6741071939468384\n",
      "Epoch 2 - Batch 63 - Loss 0.9285179087892175 - Accuracy 0.6748046875\n",
      "Epoch 2 - Batch 64 - Loss 0.9282220198557927 - Accuracy 0.6752403974533081\n",
      "Epoch 2 - Batch 65 - Loss 0.9246616751858683 - Accuracy 0.6768466234207153\n",
      "Epoch 2 - Batch 66 - Loss 0.9219982659638818 - Accuracy 0.6780550479888916\n",
      "Epoch 2 - Batch 67 - Loss 0.9201673470875796 - Accuracy 0.6785386204719543\n",
      "Epoch 2 - Batch 68 - Loss 0.918644438619199 - Accuracy 0.6794610619544983\n",
      "Epoch 2 - Batch 69 - Loss 0.9164341245378766 - Accuracy 0.6800222992897034\n",
      "Epoch 2 - Batch 70 - Loss 0.9155595554432399 - Accuracy 0.6804577112197876\n",
      "Epoch 2 - Batch 71 - Loss 0.9120515444212489 - Accuracy 0.6818576455116272\n",
      "Epoch 2 - Batch 72 - Loss 0.9103137736451136 - Accuracy 0.6824700236320496\n",
      "Epoch 2 - Batch 73 - Loss 0.9095486265582007 - Accuracy 0.6825380325317383\n",
      "Epoch 2 - Batch 74 - Loss 0.9063555820782979 - Accuracy 0.6835416555404663\n",
      "Epoch 2 - Batch 75 - Loss 0.9030713101750926 - Accuracy 0.6847245097160339\n",
      "Epoch 2 - Batch 76 - Loss 0.9021798140042788 - Accuracy 0.6849634647369385\n",
      "Epoch 2 - Batch 77 - Loss 0.9014503657817841 - Accuracy 0.6852964758872986\n",
      "Epoch 2 - Batch 78 - Loss 0.8929216218522832 - Accuracy 0.689280092716217\n",
      "Epoch 2 - Loss 0.8929216218522832 - Accuracy 0.689280092716217\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    print('Training...')\n",
    "    train_loop(train_loader, epoch)\n",
    "    \n",
    "    net.eval()\n",
    "    print('Testing...')\n",
    "    train_loop(test_loader, epoch)\n",
    "    net.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x71caa0d86350>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_data.data[1000]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape(1, 3, 32, 32)\n",
    "image = torch.tensor(image).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (activation): ReLU()\n",
       "  (bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=1152, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 233.9159,  181.9742, -363.3521, -195.6751, -447.3539, -356.2917,\n",
       "         -371.2379, -399.2553,   33.1954,  245.1355]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = net.forward(image.to(device))\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3408e-05, 3.7101e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9999e-01]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = F.softmax(forecast, dim=1)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = forecast.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x71caa0e857e0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a truck\n"
     ]
    }
   ],
   "source": [
    "print('The image is a', train_data.classes[result])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
