{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 14: Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(\n",
    "        degrees = 7,\n",
    "        translate = (0, 0.07),\n",
    "        shear = 7,\n",
    "        scale = (1, 1.2)\n",
    "    ),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='Datasets', download=True, train=True, transform=transform_train)\n",
    "test = datasets.MNIST(root='Datasets', download=True, train=False, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, (3,3))\n",
    "        self.activation = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(32*13*13, 128)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        X = self.pool(self.activation(self.conv1(x)))\n",
    "        X = self.flatten(X)\n",
    "        X = self.activation(self.linear(X))\n",
    "        X = self.output(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = classifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (activation): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=5408, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(loader, epoch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        ps = F.softmax(outputs)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        running_accuracy += accuracy.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Batch {i+1} - Loss: {loss:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "    print(f'Epoch {epoch+1} - Loss: {running_loss/len(loader):.3f}, Accuracy: {running_accuracy/len(loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1, Batch 1 - Loss: 0.946, Accuracy: 0.688\n",
      "Epoch 1, Batch 2 - Loss: 0.863, Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25671/1296387940.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ps = F.softmax(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 3 - Loss: 0.648, Accuracy: 0.820\n",
      "Epoch 1, Batch 4 - Loss: 0.798, Accuracy: 0.750\n",
      "Epoch 1, Batch 5 - Loss: 0.959, Accuracy: 0.656\n",
      "Epoch 1, Batch 6 - Loss: 0.808, Accuracy: 0.734\n",
      "Epoch 1, Batch 7 - Loss: 0.893, Accuracy: 0.742\n",
      "Epoch 1, Batch 8 - Loss: 1.004, Accuracy: 0.695\n",
      "Epoch 1, Batch 9 - Loss: 0.951, Accuracy: 0.617\n",
      "Epoch 1, Batch 10 - Loss: 0.820, Accuracy: 0.734\n",
      "Epoch 1, Batch 11 - Loss: 0.958, Accuracy: 0.672\n",
      "Epoch 1, Batch 12 - Loss: 0.837, Accuracy: 0.758\n",
      "Epoch 1, Batch 13 - Loss: 0.768, Accuracy: 0.805\n",
      "Epoch 1, Batch 14 - Loss: 0.768, Accuracy: 0.789\n",
      "Epoch 1, Batch 15 - Loss: 0.774, Accuracy: 0.758\n",
      "Epoch 1, Batch 16 - Loss: 0.698, Accuracy: 0.758\n",
      "Epoch 1, Batch 17 - Loss: 0.703, Accuracy: 0.789\n",
      "Epoch 1, Batch 18 - Loss: 0.797, Accuracy: 0.719\n",
      "Epoch 1, Batch 19 - Loss: 0.654, Accuracy: 0.820\n",
      "Epoch 1, Batch 20 - Loss: 0.869, Accuracy: 0.734\n",
      "Epoch 1, Batch 21 - Loss: 0.789, Accuracy: 0.789\n",
      "Epoch 1, Batch 22 - Loss: 0.754, Accuracy: 0.680\n",
      "Epoch 1, Batch 23 - Loss: 0.993, Accuracy: 0.688\n",
      "Epoch 1, Batch 24 - Loss: 0.722, Accuracy: 0.789\n",
      "Epoch 1, Batch 25 - Loss: 0.821, Accuracy: 0.727\n",
      "Epoch 1, Batch 26 - Loss: 0.881, Accuracy: 0.734\n",
      "Epoch 1, Batch 27 - Loss: 0.725, Accuracy: 0.727\n",
      "Epoch 1, Batch 28 - Loss: 0.841, Accuracy: 0.750\n",
      "Epoch 1, Batch 29 - Loss: 0.717, Accuracy: 0.773\n",
      "Epoch 1, Batch 30 - Loss: 0.712, Accuracy: 0.781\n",
      "Epoch 1, Batch 31 - Loss: 0.743, Accuracy: 0.773\n",
      "Epoch 1, Batch 32 - Loss: 0.879, Accuracy: 0.742\n",
      "Epoch 1, Batch 33 - Loss: 0.825, Accuracy: 0.750\n",
      "Epoch 1, Batch 34 - Loss: 0.807, Accuracy: 0.734\n",
      "Epoch 1, Batch 35 - Loss: 0.718, Accuracy: 0.781\n",
      "Epoch 1, Batch 36 - Loss: 0.633, Accuracy: 0.766\n",
      "Epoch 1, Batch 37 - Loss: 0.755, Accuracy: 0.719\n",
      "Epoch 1, Batch 38 - Loss: 0.847, Accuracy: 0.750\n",
      "Epoch 1, Batch 39 - Loss: 0.784, Accuracy: 0.766\n",
      "Epoch 1, Batch 40 - Loss: 0.751, Accuracy: 0.742\n",
      "Epoch 1, Batch 41 - Loss: 0.763, Accuracy: 0.734\n",
      "Epoch 1, Batch 42 - Loss: 0.677, Accuracy: 0.781\n",
      "Epoch 1, Batch 43 - Loss: 0.594, Accuracy: 0.805\n",
      "Epoch 1, Batch 44 - Loss: 0.726, Accuracy: 0.742\n",
      "Epoch 1, Batch 45 - Loss: 0.760, Accuracy: 0.742\n",
      "Epoch 1, Batch 46 - Loss: 0.761, Accuracy: 0.727\n",
      "Epoch 1, Batch 47 - Loss: 0.728, Accuracy: 0.750\n",
      "Epoch 1, Batch 48 - Loss: 0.588, Accuracy: 0.820\n",
      "Epoch 1, Batch 49 - Loss: 0.649, Accuracy: 0.758\n",
      "Epoch 1, Batch 50 - Loss: 0.603, Accuracy: 0.812\n",
      "Epoch 1, Batch 51 - Loss: 0.606, Accuracy: 0.789\n",
      "Epoch 1, Batch 52 - Loss: 0.504, Accuracy: 0.836\n",
      "Epoch 1, Batch 53 - Loss: 0.654, Accuracy: 0.812\n",
      "Epoch 1, Batch 54 - Loss: 0.880, Accuracy: 0.742\n",
      "Epoch 1, Batch 55 - Loss: 0.846, Accuracy: 0.734\n",
      "Epoch 1, Batch 56 - Loss: 0.645, Accuracy: 0.828\n",
      "Epoch 1, Batch 57 - Loss: 0.835, Accuracy: 0.750\n",
      "Epoch 1, Batch 58 - Loss: 0.752, Accuracy: 0.766\n",
      "Epoch 1, Batch 59 - Loss: 0.792, Accuracy: 0.727\n",
      "Epoch 1, Batch 60 - Loss: 0.716, Accuracy: 0.758\n",
      "Epoch 1, Batch 61 - Loss: 0.708, Accuracy: 0.750\n",
      "Epoch 1, Batch 62 - Loss: 0.885, Accuracy: 0.734\n",
      "Epoch 1, Batch 63 - Loss: 0.806, Accuracy: 0.734\n",
      "Epoch 1, Batch 64 - Loss: 0.714, Accuracy: 0.797\n",
      "Epoch 1, Batch 65 - Loss: 0.825, Accuracy: 0.773\n",
      "Epoch 1, Batch 66 - Loss: 0.531, Accuracy: 0.844\n",
      "Epoch 1, Batch 67 - Loss: 0.561, Accuracy: 0.828\n",
      "Epoch 1, Batch 68 - Loss: 0.910, Accuracy: 0.703\n",
      "Epoch 1, Batch 69 - Loss: 0.805, Accuracy: 0.719\n",
      "Epoch 1, Batch 70 - Loss: 0.863, Accuracy: 0.703\n",
      "Epoch 1, Batch 71 - Loss: 0.467, Accuracy: 0.852\n",
      "Epoch 1, Batch 72 - Loss: 0.641, Accuracy: 0.789\n",
      "Epoch 1, Batch 73 - Loss: 0.737, Accuracy: 0.773\n",
      "Epoch 1, Batch 74 - Loss: 0.902, Accuracy: 0.719\n",
      "Epoch 1, Batch 75 - Loss: 0.756, Accuracy: 0.742\n",
      "Epoch 1, Batch 76 - Loss: 0.614, Accuracy: 0.805\n",
      "Epoch 1, Batch 77 - Loss: 0.567, Accuracy: 0.859\n",
      "Epoch 1, Batch 78 - Loss: 0.553, Accuracy: 0.875\n",
      "Epoch 1, Batch 79 - Loss: 0.668, Accuracy: 0.828\n",
      "Epoch 1, Batch 80 - Loss: 0.810, Accuracy: 0.742\n",
      "Epoch 1, Batch 81 - Loss: 0.924, Accuracy: 0.672\n",
      "Epoch 1, Batch 82 - Loss: 0.697, Accuracy: 0.750\n",
      "Epoch 1, Batch 83 - Loss: 0.548, Accuracy: 0.812\n",
      "Epoch 1, Batch 84 - Loss: 0.504, Accuracy: 0.844\n",
      "Epoch 1, Batch 85 - Loss: 0.680, Accuracy: 0.812\n",
      "Epoch 1, Batch 86 - Loss: 0.615, Accuracy: 0.789\n",
      "Epoch 1, Batch 87 - Loss: 0.484, Accuracy: 0.836\n",
      "Epoch 1, Batch 88 - Loss: 0.856, Accuracy: 0.750\n",
      "Epoch 1, Batch 89 - Loss: 0.555, Accuracy: 0.781\n",
      "Epoch 1, Batch 90 - Loss: 0.492, Accuracy: 0.828\n",
      "Epoch 1, Batch 91 - Loss: 0.832, Accuracy: 0.711\n",
      "Epoch 1, Batch 92 - Loss: 0.841, Accuracy: 0.719\n",
      "Epoch 1, Batch 93 - Loss: 0.577, Accuracy: 0.805\n",
      "Epoch 1, Batch 94 - Loss: 0.601, Accuracy: 0.812\n",
      "Epoch 1, Batch 95 - Loss: 0.709, Accuracy: 0.797\n",
      "Epoch 1, Batch 96 - Loss: 0.652, Accuracy: 0.758\n",
      "Epoch 1, Batch 97 - Loss: 0.780, Accuracy: 0.727\n",
      "Epoch 1, Batch 98 - Loss: 0.767, Accuracy: 0.797\n",
      "Epoch 1, Batch 99 - Loss: 0.797, Accuracy: 0.703\n",
      "Epoch 1, Batch 100 - Loss: 0.656, Accuracy: 0.805\n",
      "Epoch 1, Batch 101 - Loss: 0.623, Accuracy: 0.820\n",
      "Epoch 1, Batch 102 - Loss: 1.019, Accuracy: 0.688\n",
      "Epoch 1, Batch 103 - Loss: 0.803, Accuracy: 0.742\n",
      "Epoch 1, Batch 104 - Loss: 0.632, Accuracy: 0.766\n",
      "Epoch 1, Batch 105 - Loss: 0.737, Accuracy: 0.727\n",
      "Epoch 1, Batch 106 - Loss: 0.408, Accuracy: 0.852\n",
      "Epoch 1, Batch 107 - Loss: 0.559, Accuracy: 0.836\n",
      "Epoch 1, Batch 108 - Loss: 0.599, Accuracy: 0.805\n",
      "Epoch 1, Batch 109 - Loss: 0.700, Accuracy: 0.773\n",
      "Epoch 1, Batch 110 - Loss: 0.642, Accuracy: 0.773\n",
      "Epoch 1, Batch 111 - Loss: 0.707, Accuracy: 0.773\n",
      "Epoch 1, Batch 112 - Loss: 0.721, Accuracy: 0.758\n",
      "Epoch 1, Batch 113 - Loss: 0.768, Accuracy: 0.742\n",
      "Epoch 1, Batch 114 - Loss: 0.670, Accuracy: 0.758\n",
      "Epoch 1, Batch 115 - Loss: 0.758, Accuracy: 0.719\n",
      "Epoch 1, Batch 116 - Loss: 0.838, Accuracy: 0.711\n",
      "Epoch 1, Batch 117 - Loss: 0.553, Accuracy: 0.828\n",
      "Epoch 1, Batch 118 - Loss: 0.524, Accuracy: 0.836\n",
      "Epoch 1, Batch 119 - Loss: 0.567, Accuracy: 0.828\n",
      "Epoch 1, Batch 120 - Loss: 0.482, Accuracy: 0.852\n",
      "Epoch 1, Batch 121 - Loss: 0.486, Accuracy: 0.883\n",
      "Epoch 1, Batch 122 - Loss: 0.629, Accuracy: 0.820\n",
      "Epoch 1, Batch 123 - Loss: 0.646, Accuracy: 0.789\n",
      "Epoch 1, Batch 124 - Loss: 0.653, Accuracy: 0.766\n",
      "Epoch 1, Batch 125 - Loss: 0.636, Accuracy: 0.828\n",
      "Epoch 1, Batch 126 - Loss: 0.688, Accuracy: 0.750\n",
      "Epoch 1, Batch 127 - Loss: 0.456, Accuracy: 0.836\n",
      "Epoch 1, Batch 128 - Loss: 0.527, Accuracy: 0.836\n",
      "Epoch 1, Batch 129 - Loss: 0.555, Accuracy: 0.852\n",
      "Epoch 1, Batch 130 - Loss: 0.491, Accuracy: 0.867\n",
      "Epoch 1, Batch 131 - Loss: 0.707, Accuracy: 0.750\n",
      "Epoch 1, Batch 132 - Loss: 0.671, Accuracy: 0.773\n",
      "Epoch 1, Batch 133 - Loss: 0.625, Accuracy: 0.797\n",
      "Epoch 1, Batch 134 - Loss: 0.691, Accuracy: 0.773\n",
      "Epoch 1, Batch 135 - Loss: 0.635, Accuracy: 0.805\n",
      "Epoch 1, Batch 136 - Loss: 0.558, Accuracy: 0.781\n",
      "Epoch 1, Batch 137 - Loss: 0.601, Accuracy: 0.797\n",
      "Epoch 1, Batch 138 - Loss: 0.666, Accuracy: 0.711\n",
      "Epoch 1, Batch 139 - Loss: 0.620, Accuracy: 0.781\n",
      "Epoch 1, Batch 140 - Loss: 0.539, Accuracy: 0.820\n",
      "Epoch 1, Batch 141 - Loss: 0.389, Accuracy: 0.891\n",
      "Epoch 1, Batch 142 - Loss: 0.530, Accuracy: 0.828\n",
      "Epoch 1, Batch 143 - Loss: 0.369, Accuracy: 0.898\n",
      "Epoch 1, Batch 144 - Loss: 0.634, Accuracy: 0.867\n",
      "Epoch 1, Batch 145 - Loss: 0.431, Accuracy: 0.875\n",
      "Epoch 1, Batch 146 - Loss: 0.613, Accuracy: 0.820\n",
      "Epoch 1, Batch 147 - Loss: 0.416, Accuracy: 0.852\n",
      "Epoch 1, Batch 148 - Loss: 0.317, Accuracy: 0.938\n",
      "Epoch 1, Batch 149 - Loss: 0.506, Accuracy: 0.844\n",
      "Epoch 1, Batch 150 - Loss: 0.523, Accuracy: 0.812\n",
      "Epoch 1, Batch 151 - Loss: 0.485, Accuracy: 0.852\n",
      "Epoch 1, Batch 152 - Loss: 0.403, Accuracy: 0.891\n",
      "Epoch 1, Batch 153 - Loss: 0.539, Accuracy: 0.820\n",
      "Epoch 1, Batch 154 - Loss: 0.398, Accuracy: 0.875\n",
      "Epoch 1, Batch 155 - Loss: 0.442, Accuracy: 0.828\n",
      "Epoch 1, Batch 156 - Loss: 0.595, Accuracy: 0.766\n",
      "Epoch 1, Batch 157 - Loss: 0.717, Accuracy: 0.781\n",
      "Epoch 1, Batch 158 - Loss: 0.636, Accuracy: 0.781\n",
      "Epoch 1, Batch 159 - Loss: 0.552, Accuracy: 0.789\n",
      "Epoch 1, Batch 160 - Loss: 0.315, Accuracy: 0.906\n",
      "Epoch 1, Batch 161 - Loss: 0.561, Accuracy: 0.805\n",
      "Epoch 1, Batch 162 - Loss: 0.550, Accuracy: 0.828\n",
      "Epoch 1, Batch 163 - Loss: 0.502, Accuracy: 0.852\n",
      "Epoch 1, Batch 164 - Loss: 0.643, Accuracy: 0.797\n",
      "Epoch 1, Batch 165 - Loss: 0.414, Accuracy: 0.898\n",
      "Epoch 1, Batch 166 - Loss: 0.463, Accuracy: 0.852\n",
      "Epoch 1, Batch 167 - Loss: 0.463, Accuracy: 0.844\n",
      "Epoch 1, Batch 168 - Loss: 0.617, Accuracy: 0.773\n",
      "Epoch 1, Batch 169 - Loss: 0.519, Accuracy: 0.867\n",
      "Epoch 1, Batch 170 - Loss: 0.389, Accuracy: 0.883\n",
      "Epoch 1, Batch 171 - Loss: 0.397, Accuracy: 0.891\n",
      "Epoch 1, Batch 172 - Loss: 0.500, Accuracy: 0.867\n",
      "Epoch 1, Batch 173 - Loss: 0.467, Accuracy: 0.836\n",
      "Epoch 1, Batch 174 - Loss: 0.631, Accuracy: 0.797\n",
      "Epoch 1, Batch 175 - Loss: 0.431, Accuracy: 0.867\n",
      "Epoch 1, Batch 176 - Loss: 0.734, Accuracy: 0.805\n",
      "Epoch 1, Batch 177 - Loss: 0.711, Accuracy: 0.797\n",
      "Epoch 1, Batch 178 - Loss: 0.429, Accuracy: 0.875\n",
      "Epoch 1, Batch 179 - Loss: 0.335, Accuracy: 0.883\n",
      "Epoch 1, Batch 180 - Loss: 0.338, Accuracy: 0.875\n",
      "Epoch 1, Batch 181 - Loss: 0.488, Accuracy: 0.836\n",
      "Epoch 1, Batch 182 - Loss: 0.450, Accuracy: 0.844\n",
      "Epoch 1, Batch 183 - Loss: 0.489, Accuracy: 0.836\n",
      "Epoch 1, Batch 184 - Loss: 0.381, Accuracy: 0.883\n",
      "Epoch 1, Batch 185 - Loss: 0.370, Accuracy: 0.906\n",
      "Epoch 1, Batch 186 - Loss: 0.634, Accuracy: 0.812\n",
      "Epoch 1, Batch 187 - Loss: 0.466, Accuracy: 0.828\n",
      "Epoch 1, Batch 188 - Loss: 0.560, Accuracy: 0.812\n",
      "Epoch 1, Batch 189 - Loss: 0.398, Accuracy: 0.852\n",
      "Epoch 1, Batch 190 - Loss: 0.543, Accuracy: 0.820\n",
      "Epoch 1, Batch 191 - Loss: 0.383, Accuracy: 0.883\n",
      "Epoch 1, Batch 192 - Loss: 0.553, Accuracy: 0.867\n",
      "Epoch 1, Batch 193 - Loss: 0.648, Accuracy: 0.789\n",
      "Epoch 1, Batch 194 - Loss: 0.596, Accuracy: 0.805\n",
      "Epoch 1, Batch 195 - Loss: 0.420, Accuracy: 0.828\n",
      "Epoch 1, Batch 196 - Loss: 0.399, Accuracy: 0.875\n",
      "Epoch 1, Batch 197 - Loss: 0.420, Accuracy: 0.891\n",
      "Epoch 1, Batch 198 - Loss: 0.513, Accuracy: 0.844\n",
      "Epoch 1, Batch 199 - Loss: 0.340, Accuracy: 0.891\n",
      "Epoch 1, Batch 200 - Loss: 0.461, Accuracy: 0.891\n",
      "Epoch 1, Batch 201 - Loss: 0.450, Accuracy: 0.820\n",
      "Epoch 1, Batch 202 - Loss: 0.406, Accuracy: 0.867\n",
      "Epoch 1, Batch 203 - Loss: 0.380, Accuracy: 0.875\n",
      "Epoch 1, Batch 204 - Loss: 0.404, Accuracy: 0.859\n",
      "Epoch 1, Batch 205 - Loss: 0.374, Accuracy: 0.883\n",
      "Epoch 1, Batch 206 - Loss: 0.401, Accuracy: 0.914\n",
      "Epoch 1, Batch 207 - Loss: 0.569, Accuracy: 0.828\n",
      "Epoch 1, Batch 208 - Loss: 0.525, Accuracy: 0.781\n",
      "Epoch 1, Batch 209 - Loss: 0.693, Accuracy: 0.766\n",
      "Epoch 1, Batch 210 - Loss: 0.387, Accuracy: 0.867\n",
      "Epoch 1, Batch 211 - Loss: 0.346, Accuracy: 0.906\n",
      "Epoch 1, Batch 212 - Loss: 0.478, Accuracy: 0.828\n",
      "Epoch 1, Batch 213 - Loss: 0.658, Accuracy: 0.812\n",
      "Epoch 1, Batch 214 - Loss: 0.395, Accuracy: 0.875\n",
      "Epoch 1, Batch 215 - Loss: 0.431, Accuracy: 0.875\n",
      "Epoch 1, Batch 216 - Loss: 0.472, Accuracy: 0.844\n",
      "Epoch 1, Batch 217 - Loss: 0.458, Accuracy: 0.844\n",
      "Epoch 1, Batch 218 - Loss: 0.488, Accuracy: 0.844\n",
      "Epoch 1, Batch 219 - Loss: 0.337, Accuracy: 0.898\n",
      "Epoch 1, Batch 220 - Loss: 0.279, Accuracy: 0.938\n",
      "Epoch 1, Batch 221 - Loss: 0.508, Accuracy: 0.812\n",
      "Epoch 1, Batch 222 - Loss: 0.532, Accuracy: 0.797\n",
      "Epoch 1, Batch 223 - Loss: 0.447, Accuracy: 0.844\n",
      "Epoch 1, Batch 224 - Loss: 0.627, Accuracy: 0.773\n",
      "Epoch 1, Batch 225 - Loss: 0.453, Accuracy: 0.844\n",
      "Epoch 1, Batch 226 - Loss: 0.564, Accuracy: 0.836\n",
      "Epoch 1, Batch 227 - Loss: 0.406, Accuracy: 0.867\n",
      "Epoch 1, Batch 228 - Loss: 0.549, Accuracy: 0.836\n",
      "Epoch 1, Batch 229 - Loss: 0.462, Accuracy: 0.844\n",
      "Epoch 1, Batch 230 - Loss: 0.441, Accuracy: 0.875\n",
      "Epoch 1, Batch 231 - Loss: 0.323, Accuracy: 0.922\n",
      "Epoch 1, Batch 232 - Loss: 0.463, Accuracy: 0.828\n",
      "Epoch 1, Batch 233 - Loss: 0.615, Accuracy: 0.844\n",
      "Epoch 1, Batch 234 - Loss: 0.600, Accuracy: 0.820\n",
      "Epoch 1, Batch 235 - Loss: 0.519, Accuracy: 0.852\n",
      "Epoch 1, Batch 236 - Loss: 0.593, Accuracy: 0.820\n",
      "Epoch 1, Batch 237 - Loss: 0.456, Accuracy: 0.859\n",
      "Epoch 1, Batch 238 - Loss: 0.534, Accuracy: 0.789\n",
      "Epoch 1, Batch 239 - Loss: 0.630, Accuracy: 0.766\n",
      "Epoch 1, Batch 240 - Loss: 0.484, Accuracy: 0.852\n",
      "Epoch 1, Batch 241 - Loss: 0.419, Accuracy: 0.859\n",
      "Epoch 1, Batch 242 - Loss: 0.419, Accuracy: 0.883\n",
      "Epoch 1, Batch 243 - Loss: 0.393, Accuracy: 0.875\n",
      "Epoch 1, Batch 244 - Loss: 0.575, Accuracy: 0.852\n",
      "Epoch 1, Batch 245 - Loss: 0.630, Accuracy: 0.750\n",
      "Epoch 1, Batch 246 - Loss: 0.436, Accuracy: 0.852\n",
      "Epoch 1, Batch 247 - Loss: 0.495, Accuracy: 0.867\n",
      "Epoch 1, Batch 248 - Loss: 0.614, Accuracy: 0.797\n",
      "Epoch 1, Batch 249 - Loss: 0.397, Accuracy: 0.867\n",
      "Epoch 1, Batch 250 - Loss: 0.428, Accuracy: 0.859\n",
      "Epoch 1, Batch 251 - Loss: 0.475, Accuracy: 0.844\n",
      "Epoch 1, Batch 252 - Loss: 0.466, Accuracy: 0.867\n",
      "Epoch 1, Batch 253 - Loss: 0.545, Accuracy: 0.836\n",
      "Epoch 1, Batch 254 - Loss: 0.744, Accuracy: 0.750\n",
      "Epoch 1, Batch 255 - Loss: 0.350, Accuracy: 0.883\n",
      "Epoch 1, Batch 256 - Loss: 0.356, Accuracy: 0.867\n",
      "Epoch 1, Batch 257 - Loss: 0.421, Accuracy: 0.914\n",
      "Epoch 1, Batch 258 - Loss: 0.363, Accuracy: 0.898\n",
      "Epoch 1, Batch 259 - Loss: 0.494, Accuracy: 0.836\n",
      "Epoch 1, Batch 260 - Loss: 0.453, Accuracy: 0.906\n",
      "Epoch 1, Batch 261 - Loss: 0.534, Accuracy: 0.828\n",
      "Epoch 1, Batch 262 - Loss: 0.420, Accuracy: 0.867\n",
      "Epoch 1, Batch 263 - Loss: 0.343, Accuracy: 0.867\n",
      "Epoch 1, Batch 264 - Loss: 0.462, Accuracy: 0.836\n",
      "Epoch 1, Batch 265 - Loss: 0.329, Accuracy: 0.891\n",
      "Epoch 1, Batch 266 - Loss: 0.311, Accuracy: 0.906\n",
      "Epoch 1, Batch 267 - Loss: 0.411, Accuracy: 0.844\n",
      "Epoch 1, Batch 268 - Loss: 0.251, Accuracy: 0.938\n",
      "Epoch 1, Batch 269 - Loss: 0.437, Accuracy: 0.859\n",
      "Epoch 1, Batch 270 - Loss: 0.493, Accuracy: 0.844\n",
      "Epoch 1, Batch 271 - Loss: 0.396, Accuracy: 0.875\n",
      "Epoch 1, Batch 272 - Loss: 0.459, Accuracy: 0.859\n",
      "Epoch 1, Batch 273 - Loss: 0.469, Accuracy: 0.852\n",
      "Epoch 1, Batch 274 - Loss: 0.365, Accuracy: 0.906\n",
      "Epoch 1, Batch 275 - Loss: 0.306, Accuracy: 0.891\n",
      "Epoch 1, Batch 276 - Loss: 0.412, Accuracy: 0.891\n",
      "Epoch 1, Batch 277 - Loss: 0.345, Accuracy: 0.891\n",
      "Epoch 1, Batch 278 - Loss: 0.315, Accuracy: 0.906\n",
      "Epoch 1, Batch 279 - Loss: 0.449, Accuracy: 0.867\n",
      "Epoch 1, Batch 280 - Loss: 0.335, Accuracy: 0.891\n",
      "Epoch 1, Batch 281 - Loss: 0.301, Accuracy: 0.906\n",
      "Epoch 1, Batch 282 - Loss: 0.438, Accuracy: 0.828\n",
      "Epoch 1, Batch 283 - Loss: 0.388, Accuracy: 0.883\n",
      "Epoch 1, Batch 284 - Loss: 0.385, Accuracy: 0.859\n",
      "Epoch 1, Batch 285 - Loss: 0.493, Accuracy: 0.828\n",
      "Epoch 1, Batch 286 - Loss: 0.364, Accuracy: 0.875\n",
      "Epoch 1, Batch 287 - Loss: 0.299, Accuracy: 0.938\n",
      "Epoch 1, Batch 288 - Loss: 0.368, Accuracy: 0.883\n",
      "Epoch 1, Batch 289 - Loss: 0.396, Accuracy: 0.891\n",
      "Epoch 1, Batch 290 - Loss: 0.516, Accuracy: 0.836\n",
      "Epoch 1, Batch 291 - Loss: 0.377, Accuracy: 0.875\n",
      "Epoch 1, Batch 292 - Loss: 0.459, Accuracy: 0.867\n",
      "Epoch 1, Batch 293 - Loss: 0.548, Accuracy: 0.852\n",
      "Epoch 1, Batch 294 - Loss: 0.451, Accuracy: 0.820\n",
      "Epoch 1, Batch 295 - Loss: 0.467, Accuracy: 0.867\n",
      "Epoch 1, Batch 296 - Loss: 0.392, Accuracy: 0.883\n",
      "Epoch 1, Batch 297 - Loss: 0.328, Accuracy: 0.891\n",
      "Epoch 1, Batch 298 - Loss: 0.384, Accuracy: 0.828\n",
      "Epoch 1, Batch 299 - Loss: 0.343, Accuracy: 0.898\n",
      "Epoch 1, Batch 300 - Loss: 0.388, Accuracy: 0.898\n",
      "Epoch 1, Batch 301 - Loss: 0.293, Accuracy: 0.898\n",
      "Epoch 1, Batch 302 - Loss: 0.349, Accuracy: 0.891\n",
      "Epoch 1, Batch 303 - Loss: 0.328, Accuracy: 0.906\n",
      "Epoch 1, Batch 304 - Loss: 0.341, Accuracy: 0.875\n",
      "Epoch 1, Batch 305 - Loss: 0.291, Accuracy: 0.891\n",
      "Epoch 1, Batch 306 - Loss: 0.287, Accuracy: 0.898\n",
      "Epoch 1, Batch 307 - Loss: 0.373, Accuracy: 0.883\n",
      "Epoch 1, Batch 308 - Loss: 0.515, Accuracy: 0.828\n",
      "Epoch 1, Batch 309 - Loss: 0.384, Accuracy: 0.875\n",
      "Epoch 1, Batch 310 - Loss: 0.386, Accuracy: 0.867\n",
      "Epoch 1, Batch 311 - Loss: 0.304, Accuracy: 0.906\n",
      "Epoch 1, Batch 312 - Loss: 0.383, Accuracy: 0.883\n",
      "Epoch 1, Batch 313 - Loss: 0.442, Accuracy: 0.836\n",
      "Epoch 1, Batch 314 - Loss: 0.363, Accuracy: 0.883\n",
      "Epoch 1, Batch 315 - Loss: 0.344, Accuracy: 0.898\n",
      "Epoch 1, Batch 316 - Loss: 0.353, Accuracy: 0.898\n",
      "Epoch 1, Batch 317 - Loss: 0.481, Accuracy: 0.867\n",
      "Epoch 1, Batch 318 - Loss: 0.402, Accuracy: 0.891\n",
      "Epoch 1, Batch 319 - Loss: 0.413, Accuracy: 0.859\n",
      "Epoch 1, Batch 320 - Loss: 0.267, Accuracy: 0.891\n",
      "Epoch 1, Batch 321 - Loss: 0.366, Accuracy: 0.867\n",
      "Epoch 1, Batch 322 - Loss: 0.391, Accuracy: 0.867\n",
      "Epoch 1, Batch 323 - Loss: 0.482, Accuracy: 0.852\n",
      "Epoch 1, Batch 324 - Loss: 0.519, Accuracy: 0.867\n",
      "Epoch 1, Batch 325 - Loss: 0.436, Accuracy: 0.828\n",
      "Epoch 1, Batch 326 - Loss: 0.374, Accuracy: 0.891\n",
      "Epoch 1, Batch 327 - Loss: 0.330, Accuracy: 0.883\n",
      "Epoch 1, Batch 328 - Loss: 0.359, Accuracy: 0.883\n",
      "Epoch 1, Batch 329 - Loss: 0.356, Accuracy: 0.906\n",
      "Epoch 1, Batch 330 - Loss: 0.505, Accuracy: 0.812\n",
      "Epoch 1, Batch 331 - Loss: 0.417, Accuracy: 0.828\n",
      "Epoch 1, Batch 332 - Loss: 0.476, Accuracy: 0.836\n",
      "Epoch 1, Batch 333 - Loss: 0.274, Accuracy: 0.898\n",
      "Epoch 1, Batch 334 - Loss: 0.452, Accuracy: 0.844\n",
      "Epoch 1, Batch 335 - Loss: 0.321, Accuracy: 0.883\n",
      "Epoch 1, Batch 336 - Loss: 0.459, Accuracy: 0.828\n",
      "Epoch 1, Batch 337 - Loss: 0.482, Accuracy: 0.836\n",
      "Epoch 1, Batch 338 - Loss: 0.360, Accuracy: 0.875\n",
      "Epoch 1, Batch 339 - Loss: 0.286, Accuracy: 0.898\n",
      "Epoch 1, Batch 340 - Loss: 0.358, Accuracy: 0.867\n",
      "Epoch 1, Batch 341 - Loss: 0.311, Accuracy: 0.914\n",
      "Epoch 1, Batch 342 - Loss: 0.340, Accuracy: 0.898\n",
      "Epoch 1, Batch 343 - Loss: 0.414, Accuracy: 0.844\n",
      "Epoch 1, Batch 344 - Loss: 0.371, Accuracy: 0.898\n",
      "Epoch 1, Batch 345 - Loss: 0.480, Accuracy: 0.852\n",
      "Epoch 1, Batch 346 - Loss: 0.286, Accuracy: 0.922\n",
      "Epoch 1, Batch 347 - Loss: 0.277, Accuracy: 0.922\n",
      "Epoch 1, Batch 348 - Loss: 0.344, Accuracy: 0.906\n",
      "Epoch 1, Batch 349 - Loss: 0.271, Accuracy: 0.906\n",
      "Epoch 1, Batch 350 - Loss: 0.399, Accuracy: 0.844\n",
      "Epoch 1, Batch 351 - Loss: 0.562, Accuracy: 0.812\n",
      "Epoch 1, Batch 352 - Loss: 0.452, Accuracy: 0.812\n",
      "Epoch 1, Batch 353 - Loss: 0.341, Accuracy: 0.883\n",
      "Epoch 1, Batch 354 - Loss: 0.350, Accuracy: 0.836\n",
      "Epoch 1, Batch 355 - Loss: 0.352, Accuracy: 0.883\n",
      "Epoch 1, Batch 356 - Loss: 0.427, Accuracy: 0.797\n",
      "Epoch 1, Batch 357 - Loss: 0.413, Accuracy: 0.820\n",
      "Epoch 1, Batch 358 - Loss: 0.393, Accuracy: 0.875\n",
      "Epoch 1, Batch 359 - Loss: 0.475, Accuracy: 0.859\n",
      "Epoch 1, Batch 360 - Loss: 0.460, Accuracy: 0.820\n",
      "Epoch 1, Batch 361 - Loss: 0.413, Accuracy: 0.883\n",
      "Epoch 1, Batch 362 - Loss: 0.471, Accuracy: 0.820\n",
      "Epoch 1, Batch 363 - Loss: 0.523, Accuracy: 0.828\n",
      "Epoch 1, Batch 364 - Loss: 0.280, Accuracy: 0.922\n",
      "Epoch 1, Batch 365 - Loss: 0.356, Accuracy: 0.891\n",
      "Epoch 1, Batch 366 - Loss: 0.337, Accuracy: 0.891\n",
      "Epoch 1, Batch 367 - Loss: 0.314, Accuracy: 0.883\n",
      "Epoch 1, Batch 368 - Loss: 0.499, Accuracy: 0.836\n",
      "Epoch 1, Batch 369 - Loss: 0.361, Accuracy: 0.891\n",
      "Epoch 1, Batch 370 - Loss: 0.561, Accuracy: 0.820\n",
      "Epoch 1, Batch 371 - Loss: 0.504, Accuracy: 0.836\n",
      "Epoch 1, Batch 372 - Loss: 0.495, Accuracy: 0.859\n",
      "Epoch 1, Batch 373 - Loss: 0.340, Accuracy: 0.883\n",
      "Epoch 1, Batch 374 - Loss: 0.433, Accuracy: 0.875\n",
      "Epoch 1, Batch 375 - Loss: 0.455, Accuracy: 0.797\n",
      "Epoch 1, Batch 376 - Loss: 0.393, Accuracy: 0.867\n",
      "Epoch 1, Batch 377 - Loss: 0.234, Accuracy: 0.914\n",
      "Epoch 1, Batch 378 - Loss: 0.615, Accuracy: 0.836\n",
      "Epoch 1, Batch 379 - Loss: 0.356, Accuracy: 0.859\n",
      "Epoch 1, Batch 380 - Loss: 0.396, Accuracy: 0.844\n",
      "Epoch 1, Batch 381 - Loss: 0.302, Accuracy: 0.891\n",
      "Epoch 1, Batch 382 - Loss: 0.286, Accuracy: 0.922\n",
      "Epoch 1, Batch 383 - Loss: 0.558, Accuracy: 0.836\n",
      "Epoch 1, Batch 384 - Loss: 0.457, Accuracy: 0.852\n",
      "Epoch 1, Batch 385 - Loss: 0.494, Accuracy: 0.812\n",
      "Epoch 1, Batch 386 - Loss: 0.252, Accuracy: 0.922\n",
      "Epoch 1, Batch 387 - Loss: 0.506, Accuracy: 0.805\n",
      "Epoch 1, Batch 388 - Loss: 0.646, Accuracy: 0.797\n",
      "Epoch 1, Batch 389 - Loss: 0.322, Accuracy: 0.898\n",
      "Epoch 1, Batch 390 - Loss: 0.446, Accuracy: 0.867\n",
      "Epoch 1, Batch 391 - Loss: 0.370, Accuracy: 0.859\n",
      "Epoch 1, Batch 392 - Loss: 0.344, Accuracy: 0.867\n",
      "Epoch 1, Batch 393 - Loss: 0.356, Accuracy: 0.875\n",
      "Epoch 1, Batch 394 - Loss: 0.595, Accuracy: 0.789\n",
      "Epoch 1, Batch 395 - Loss: 0.432, Accuracy: 0.828\n",
      "Epoch 1, Batch 396 - Loss: 0.413, Accuracy: 0.867\n",
      "Epoch 1, Batch 397 - Loss: 0.482, Accuracy: 0.828\n",
      "Epoch 1, Batch 398 - Loss: 0.410, Accuracy: 0.867\n",
      "Epoch 1, Batch 399 - Loss: 0.240, Accuracy: 0.906\n",
      "Epoch 1, Batch 400 - Loss: 0.306, Accuracy: 0.891\n",
      "Epoch 1, Batch 401 - Loss: 0.440, Accuracy: 0.828\n",
      "Epoch 1, Batch 402 - Loss: 0.317, Accuracy: 0.891\n",
      "Epoch 1, Batch 403 - Loss: 0.292, Accuracy: 0.930\n",
      "Epoch 1, Batch 404 - Loss: 0.297, Accuracy: 0.891\n",
      "Epoch 1, Batch 405 - Loss: 0.294, Accuracy: 0.906\n",
      "Epoch 1, Batch 406 - Loss: 0.370, Accuracy: 0.867\n",
      "Epoch 1, Batch 407 - Loss: 0.352, Accuracy: 0.859\n",
      "Epoch 1, Batch 408 - Loss: 0.464, Accuracy: 0.836\n",
      "Epoch 1, Batch 409 - Loss: 0.335, Accuracy: 0.914\n",
      "Epoch 1, Batch 410 - Loss: 0.339, Accuracy: 0.875\n",
      "Epoch 1, Batch 411 - Loss: 0.185, Accuracy: 0.961\n",
      "Epoch 1, Batch 412 - Loss: 0.282, Accuracy: 0.945\n",
      "Epoch 1, Batch 413 - Loss: 0.366, Accuracy: 0.922\n",
      "Epoch 1, Batch 414 - Loss: 0.574, Accuracy: 0.797\n",
      "Epoch 1, Batch 415 - Loss: 0.409, Accuracy: 0.852\n",
      "Epoch 1, Batch 416 - Loss: 0.391, Accuracy: 0.867\n",
      "Epoch 1, Batch 417 - Loss: 0.210, Accuracy: 0.930\n",
      "Epoch 1, Batch 418 - Loss: 0.339, Accuracy: 0.883\n",
      "Epoch 1, Batch 419 - Loss: 0.432, Accuracy: 0.844\n",
      "Epoch 1, Batch 420 - Loss: 0.432, Accuracy: 0.844\n",
      "Epoch 1, Batch 421 - Loss: 0.302, Accuracy: 0.922\n",
      "Epoch 1, Batch 422 - Loss: 0.425, Accuracy: 0.836\n",
      "Epoch 1, Batch 423 - Loss: 0.274, Accuracy: 0.922\n",
      "Epoch 1, Batch 424 - Loss: 0.284, Accuracy: 0.906\n",
      "Epoch 1, Batch 425 - Loss: 0.270, Accuracy: 0.898\n",
      "Epoch 1, Batch 426 - Loss: 0.367, Accuracy: 0.883\n",
      "Epoch 1, Batch 427 - Loss: 0.326, Accuracy: 0.875\n",
      "Epoch 1, Batch 428 - Loss: 0.286, Accuracy: 0.930\n",
      "Epoch 1, Batch 429 - Loss: 0.467, Accuracy: 0.828\n",
      "Epoch 1, Batch 430 - Loss: 0.454, Accuracy: 0.852\n",
      "Epoch 1, Batch 431 - Loss: 0.233, Accuracy: 0.922\n",
      "Epoch 1, Batch 432 - Loss: 0.332, Accuracy: 0.898\n",
      "Epoch 1, Batch 433 - Loss: 0.377, Accuracy: 0.898\n",
      "Epoch 1, Batch 434 - Loss: 0.286, Accuracy: 0.922\n",
      "Epoch 1, Batch 435 - Loss: 0.240, Accuracy: 0.930\n",
      "Epoch 1, Batch 436 - Loss: 0.398, Accuracy: 0.883\n",
      "Epoch 1, Batch 437 - Loss: 0.336, Accuracy: 0.922\n",
      "Epoch 1, Batch 438 - Loss: 0.228, Accuracy: 0.938\n",
      "Epoch 1, Batch 439 - Loss: 0.287, Accuracy: 0.883\n",
      "Epoch 1, Batch 440 - Loss: 0.282, Accuracy: 0.914\n",
      "Epoch 1, Batch 441 - Loss: 0.291, Accuracy: 0.891\n",
      "Epoch 1, Batch 442 - Loss: 0.387, Accuracy: 0.859\n",
      "Epoch 1, Batch 443 - Loss: 0.314, Accuracy: 0.867\n",
      "Epoch 1, Batch 444 - Loss: 0.302, Accuracy: 0.914\n",
      "Epoch 1, Batch 445 - Loss: 0.212, Accuracy: 0.930\n",
      "Epoch 1, Batch 446 - Loss: 0.310, Accuracy: 0.898\n",
      "Epoch 1, Batch 447 - Loss: 0.174, Accuracy: 0.953\n",
      "Epoch 1, Batch 448 - Loss: 0.340, Accuracy: 0.875\n",
      "Epoch 1, Batch 449 - Loss: 0.194, Accuracy: 0.953\n",
      "Epoch 1, Batch 450 - Loss: 0.397, Accuracy: 0.852\n",
      "Epoch 1, Batch 451 - Loss: 0.333, Accuracy: 0.875\n",
      "Epoch 1, Batch 452 - Loss: 0.257, Accuracy: 0.938\n",
      "Epoch 1, Batch 453 - Loss: 0.178, Accuracy: 0.953\n",
      "Epoch 1, Batch 454 - Loss: 0.242, Accuracy: 0.945\n",
      "Epoch 1, Batch 455 - Loss: 0.159, Accuracy: 0.961\n",
      "Epoch 1, Batch 456 - Loss: 0.137, Accuracy: 0.969\n",
      "Epoch 1, Batch 457 - Loss: 0.351, Accuracy: 0.898\n",
      "Epoch 1, Batch 458 - Loss: 0.257, Accuracy: 0.938\n",
      "Epoch 1, Batch 459 - Loss: 0.185, Accuracy: 0.953\n",
      "Epoch 1, Batch 460 - Loss: 0.233, Accuracy: 0.914\n",
      "Epoch 1, Batch 461 - Loss: 0.104, Accuracy: 0.969\n",
      "Epoch 1, Batch 462 - Loss: 0.164, Accuracy: 0.961\n",
      "Epoch 1, Batch 463 - Loss: 0.156, Accuracy: 0.945\n",
      "Epoch 1, Batch 464 - Loss: 0.511, Accuracy: 0.812\n",
      "Epoch 1, Batch 465 - Loss: 0.364, Accuracy: 0.859\n",
      "Epoch 1, Batch 466 - Loss: 0.191, Accuracy: 0.945\n",
      "Epoch 1, Batch 467 - Loss: 0.636, Accuracy: 0.859\n",
      "Epoch 1, Batch 468 - Loss: 0.154, Accuracy: 0.953\n",
      "Epoch 1, Batch 469 - Loss: 0.508, Accuracy: 0.875\n",
      "Epoch 1 - Loss: 0.500, Accuracy: 0.838\n",
      "Testing...\n",
      "Epoch 1, Batch 1 - Loss: 0.257, Accuracy: 0.922\n",
      "Epoch 1, Batch 2 - Loss: 0.307, Accuracy: 0.891\n",
      "Epoch 1, Batch 3 - Loss: 0.424, Accuracy: 0.820\n",
      "Epoch 1, Batch 4 - Loss: 0.294, Accuracy: 0.898\n",
      "Epoch 1, Batch 5 - Loss: 0.307, Accuracy: 0.875\n",
      "Epoch 1, Batch 6 - Loss: 0.296, Accuracy: 0.906\n",
      "Epoch 1, Batch 7 - Loss: 0.241, Accuracy: 0.922\n",
      "Epoch 1, Batch 8 - Loss: 0.279, Accuracy: 0.906\n",
      "Epoch 1, Batch 9 - Loss: 0.269, Accuracy: 0.898\n",
      "Epoch 1, Batch 10 - Loss: 0.424, Accuracy: 0.883\n",
      "Epoch 1, Batch 11 - Loss: 0.214, Accuracy: 0.922\n",
      "Epoch 1, Batch 12 - Loss: 0.228, Accuracy: 0.945\n",
      "Epoch 1, Batch 13 - Loss: 0.256, Accuracy: 0.891\n",
      "Epoch 1, Batch 14 - Loss: 0.292, Accuracy: 0.914\n",
      "Epoch 1, Batch 15 - Loss: 0.157, Accuracy: 0.969\n",
      "Epoch 1, Batch 16 - Loss: 0.174, Accuracy: 0.953\n",
      "Epoch 1, Batch 17 - Loss: 0.295, Accuracy: 0.922\n",
      "Epoch 1, Batch 18 - Loss: 0.327, Accuracy: 0.898\n",
      "Epoch 1, Batch 19 - Loss: 0.223, Accuracy: 0.922\n",
      "Epoch 1, Batch 20 - Loss: 0.206, Accuracy: 0.930\n",
      "Epoch 1, Batch 21 - Loss: 0.212, Accuracy: 0.945\n",
      "Epoch 1, Batch 22 - Loss: 0.203, Accuracy: 0.953\n",
      "Epoch 1, Batch 23 - Loss: 0.163, Accuracy: 0.945\n",
      "Epoch 1, Batch 24 - Loss: 0.176, Accuracy: 0.953\n",
      "Epoch 1, Batch 25 - Loss: 0.229, Accuracy: 0.953\n",
      "Epoch 1, Batch 26 - Loss: 0.136, Accuracy: 0.953\n",
      "Epoch 1, Batch 27 - Loss: 0.191, Accuracy: 0.953\n",
      "Epoch 1, Batch 28 - Loss: 0.201, Accuracy: 0.938\n",
      "Epoch 1, Batch 29 - Loss: 0.145, Accuracy: 0.953\n",
      "Epoch 1, Batch 30 - Loss: 0.277, Accuracy: 0.898\n",
      "Epoch 1, Batch 31 - Loss: 0.327, Accuracy: 0.922\n",
      "Epoch 1, Batch 32 - Loss: 0.196, Accuracy: 0.945\n",
      "Epoch 1, Batch 33 - Loss: 0.213, Accuracy: 0.938\n",
      "Epoch 1, Batch 34 - Loss: 0.185, Accuracy: 0.945\n",
      "Epoch 1, Batch 35 - Loss: 0.154, Accuracy: 0.961\n",
      "Epoch 1, Batch 36 - Loss: 0.116, Accuracy: 0.984\n",
      "Epoch 1, Batch 37 - Loss: 0.165, Accuracy: 0.945\n",
      "Epoch 1, Batch 38 - Loss: 0.189, Accuracy: 0.938\n",
      "Epoch 1, Batch 39 - Loss: 0.171, Accuracy: 0.922\n",
      "Epoch 1, Batch 40 - Loss: 0.138, Accuracy: 0.961\n",
      "Epoch 1, Batch 41 - Loss: 0.170, Accuracy: 0.953\n",
      "Epoch 1, Batch 42 - Loss: 0.059, Accuracy: 0.992\n",
      "Epoch 1, Batch 43 - Loss: 0.028, Accuracy: 1.000\n",
      "Epoch 1, Batch 44 - Loss: 0.065, Accuracy: 0.977\n",
      "Epoch 1, Batch 45 - Loss: 0.135, Accuracy: 0.969\n",
      "Epoch 1, Batch 46 - Loss: 0.109, Accuracy: 0.945\n",
      "Epoch 1, Batch 47 - Loss: 0.290, Accuracy: 0.875\n",
      "Epoch 1, Batch 48 - Loss: 0.231, Accuracy: 0.930\n",
      "Epoch 1, Batch 49 - Loss: 0.138, Accuracy: 0.969\n",
      "Epoch 1, Batch 50 - Loss: 0.041, Accuracy: 0.992\n",
      "Epoch 1, Batch 51 - Loss: 0.133, Accuracy: 0.961\n",
      "Epoch 1, Batch 52 - Loss: 0.408, Accuracy: 0.883\n",
      "Epoch 1, Batch 53 - Loss: 0.160, Accuracy: 0.961\n",
      "Epoch 1, Batch 54 - Loss: 0.074, Accuracy: 0.977\n",
      "Epoch 1, Batch 55 - Loss: 0.072, Accuracy: 0.992\n",
      "Epoch 1, Batch 56 - Loss: 0.042, Accuracy: 0.992\n",
      "Epoch 1, Batch 57 - Loss: 0.117, Accuracy: 0.969\n",
      "Epoch 1, Batch 58 - Loss: 0.104, Accuracy: 0.961\n",
      "Epoch 1, Batch 59 - Loss: 0.163, Accuracy: 0.922\n",
      "Epoch 1, Batch 60 - Loss: 0.093, Accuracy: 0.977\n",
      "Epoch 1, Batch 61 - Loss: 0.051, Accuracy: 0.992\n",
      "Epoch 1, Batch 62 - Loss: 0.270, Accuracy: 0.898\n",
      "Epoch 1, Batch 63 - Loss: 0.071, Accuracy: 0.969\n",
      "Epoch 1, Batch 64 - Loss: 0.081, Accuracy: 0.992\n",
      "Epoch 1, Batch 65 - Loss: 0.109, Accuracy: 0.969\n",
      "Epoch 1, Batch 66 - Loss: 0.272, Accuracy: 0.898\n",
      "Epoch 1, Batch 67 - Loss: 0.076, Accuracy: 0.984\n",
      "Epoch 1, Batch 68 - Loss: 0.019, Accuracy: 1.000\n",
      "Epoch 1, Batch 69 - Loss: 0.007, Accuracy: 1.000\n",
      "Epoch 1, Batch 70 - Loss: 0.018, Accuracy: 1.000\n",
      "Epoch 1, Batch 71 - Loss: 0.130, Accuracy: 0.969\n",
      "Epoch 1, Batch 72 - Loss: 0.044, Accuracy: 0.984\n",
      "Epoch 1, Batch 73 - Loss: 0.044, Accuracy: 0.992\n",
      "Epoch 1, Batch 74 - Loss: 0.044, Accuracy: 0.992\n",
      "Epoch 1, Batch 75 - Loss: 0.079, Accuracy: 0.977\n",
      "Epoch 1, Batch 76 - Loss: 0.226, Accuracy: 0.906\n",
      "Epoch 1, Batch 77 - Loss: 0.357, Accuracy: 0.906\n",
      "Epoch 1, Batch 78 - Loss: 0.271, Accuracy: 0.914\n",
      "Epoch 1, Batch 79 - Loss: 0.057, Accuracy: 1.000\n",
      "Epoch 1 - Loss: 0.179, Accuracy: 0.945\n",
      "Training...\n",
      "Epoch 2, Batch 1 - Loss: 0.613, Accuracy: 0.828\n",
      "Epoch 2, Batch 2 - Loss: 0.480, Accuracy: 0.844\n",
      "Epoch 2, Batch 3 - Loss: 0.295, Accuracy: 0.875\n",
      "Epoch 2, Batch 4 - Loss: 0.514, Accuracy: 0.852\n",
      "Epoch 2, Batch 5 - Loss: 0.556, Accuracy: 0.836\n",
      "Epoch 2, Batch 6 - Loss: 0.357, Accuracy: 0.875\n",
      "Epoch 2, Batch 7 - Loss: 0.561, Accuracy: 0.883\n",
      "Epoch 2, Batch 8 - Loss: 0.521, Accuracy: 0.852\n",
      "Epoch 2, Batch 9 - Loss: 0.541, Accuracy: 0.797\n",
      "Epoch 2, Batch 10 - Loss: 0.405, Accuracy: 0.891\n",
      "Epoch 2, Batch 11 - Loss: 0.759, Accuracy: 0.758\n",
      "Epoch 2, Batch 12 - Loss: 0.394, Accuracy: 0.859\n",
      "Epoch 2, Batch 13 - Loss: 0.272, Accuracy: 0.914\n",
      "Epoch 2, Batch 14 - Loss: 0.228, Accuracy: 0.914\n",
      "Epoch 2, Batch 15 - Loss: 0.308, Accuracy: 0.891\n",
      "Epoch 2, Batch 16 - Loss: 0.392, Accuracy: 0.852\n",
      "Epoch 2, Batch 17 - Loss: 0.291, Accuracy: 0.891\n",
      "Epoch 2, Batch 18 - Loss: 0.411, Accuracy: 0.867\n",
      "Epoch 2, Batch 19 - Loss: 0.286, Accuracy: 0.891\n",
      "Epoch 2, Batch 20 - Loss: 0.207, Accuracy: 0.914\n",
      "Epoch 2, Batch 21 - Loss: 0.354, Accuracy: 0.906\n",
      "Epoch 2, Batch 22 - Loss: 0.400, Accuracy: 0.867\n",
      "Epoch 2, Batch 23 - Loss: 0.428, Accuracy: 0.852\n",
      "Epoch 2, Batch 24 - Loss: 0.293, Accuracy: 0.922\n",
      "Epoch 2, Batch 25 - Loss: 0.231, Accuracy: 0.922\n",
      "Epoch 2, Batch 26 - Loss: 0.276, Accuracy: 0.906\n",
      "Epoch 2, Batch 27 - Loss: 0.420, Accuracy: 0.898\n",
      "Epoch 2, Batch 28 - Loss: 0.423, Accuracy: 0.867\n",
      "Epoch 2, Batch 29 - Loss: 0.258, Accuracy: 0.922\n",
      "Epoch 2, Batch 30 - Loss: 0.311, Accuracy: 0.914\n",
      "Epoch 2, Batch 31 - Loss: 0.204, Accuracy: 0.930\n",
      "Epoch 2, Batch 32 - Loss: 0.379, Accuracy: 0.891\n",
      "Epoch 2, Batch 33 - Loss: 0.336, Accuracy: 0.914\n",
      "Epoch 2, Batch 34 - Loss: 0.239, Accuracy: 0.898\n",
      "Epoch 2, Batch 35 - Loss: 0.274, Accuracy: 0.914\n",
      "Epoch 2, Batch 36 - Loss: 0.240, Accuracy: 0.930\n",
      "Epoch 2, Batch 37 - Loss: 0.343, Accuracy: 0.852\n",
      "Epoch 2, Batch 38 - Loss: 0.233, Accuracy: 0.922\n",
      "Epoch 2, Batch 39 - Loss: 0.349, Accuracy: 0.914\n",
      "Epoch 2, Batch 40 - Loss: 0.344, Accuracy: 0.891\n",
      "Epoch 2, Batch 41 - Loss: 0.473, Accuracy: 0.852\n",
      "Epoch 2, Batch 42 - Loss: 0.244, Accuracy: 0.945\n",
      "Epoch 2, Batch 43 - Loss: 0.247, Accuracy: 0.898\n",
      "Epoch 2, Batch 44 - Loss: 0.335, Accuracy: 0.883\n",
      "Epoch 2, Batch 45 - Loss: 0.426, Accuracy: 0.867\n",
      "Epoch 2, Batch 46 - Loss: 0.291, Accuracy: 0.914\n",
      "Epoch 2, Batch 47 - Loss: 0.232, Accuracy: 0.914\n",
      "Epoch 2, Batch 48 - Loss: 0.285, Accuracy: 0.953\n",
      "Epoch 2, Batch 49 - Loss: 0.242, Accuracy: 0.898\n",
      "Epoch 2, Batch 50 - Loss: 0.283, Accuracy: 0.922\n",
      "Epoch 2, Batch 51 - Loss: 0.318, Accuracy: 0.914\n",
      "Epoch 2, Batch 52 - Loss: 0.182, Accuracy: 0.938\n",
      "Epoch 2, Batch 53 - Loss: 0.304, Accuracy: 0.906\n",
      "Epoch 2, Batch 54 - Loss: 0.407, Accuracy: 0.867\n",
      "Epoch 2, Batch 55 - Loss: 0.429, Accuracy: 0.844\n",
      "Epoch 2, Batch 56 - Loss: 0.301, Accuracy: 0.891\n",
      "Epoch 2, Batch 57 - Loss: 0.358, Accuracy: 0.891\n",
      "Epoch 2, Batch 58 - Loss: 0.247, Accuracy: 0.914\n",
      "Epoch 2, Batch 59 - Loss: 0.277, Accuracy: 0.891\n",
      "Epoch 2, Batch 60 - Loss: 0.268, Accuracy: 0.922\n",
      "Epoch 2, Batch 61 - Loss: 0.261, Accuracy: 0.938\n",
      "Epoch 2, Batch 62 - Loss: 0.307, Accuracy: 0.914\n",
      "Epoch 2, Batch 63 - Loss: 0.314, Accuracy: 0.891\n",
      "Epoch 2, Batch 64 - Loss: 0.275, Accuracy: 0.898\n",
      "Epoch 2, Batch 65 - Loss: 0.408, Accuracy: 0.891\n",
      "Epoch 2, Batch 66 - Loss: 0.247, Accuracy: 0.922\n",
      "Epoch 2, Batch 67 - Loss: 0.254, Accuracy: 0.914\n",
      "Epoch 2, Batch 68 - Loss: 0.427, Accuracy: 0.883\n",
      "Epoch 2, Batch 69 - Loss: 0.429, Accuracy: 0.844\n",
      "Epoch 2, Batch 70 - Loss: 0.579, Accuracy: 0.781\n",
      "Epoch 2, Batch 71 - Loss: 0.253, Accuracy: 0.883\n",
      "Epoch 2, Batch 72 - Loss: 0.274, Accuracy: 0.922\n",
      "Epoch 2, Batch 73 - Loss: 0.237, Accuracy: 0.906\n",
      "Epoch 2, Batch 74 - Loss: 0.399, Accuracy: 0.836\n",
      "Epoch 2, Batch 75 - Loss: 0.299, Accuracy: 0.875\n",
      "Epoch 2, Batch 76 - Loss: 0.375, Accuracy: 0.867\n",
      "Epoch 2, Batch 77 - Loss: 0.202, Accuracy: 0.930\n",
      "Epoch 2, Batch 78 - Loss: 0.167, Accuracy: 0.953\n",
      "Epoch 2, Batch 79 - Loss: 0.260, Accuracy: 0.922\n",
      "Epoch 2, Batch 80 - Loss: 0.361, Accuracy: 0.898\n",
      "Epoch 2, Batch 81 - Loss: 0.303, Accuracy: 0.906\n",
      "Epoch 2, Batch 82 - Loss: 0.232, Accuracy: 0.930\n",
      "Epoch 2, Batch 83 - Loss: 0.225, Accuracy: 0.922\n",
      "Epoch 2, Batch 84 - Loss: 0.210, Accuracy: 0.906\n",
      "Epoch 2, Batch 85 - Loss: 0.294, Accuracy: 0.938\n",
      "Epoch 2, Batch 86 - Loss: 0.239, Accuracy: 0.906\n",
      "Epoch 2, Batch 87 - Loss: 0.225, Accuracy: 0.938\n",
      "Epoch 2, Batch 88 - Loss: 0.305, Accuracy: 0.891\n",
      "Epoch 2, Batch 89 - Loss: 0.335, Accuracy: 0.891\n",
      "Epoch 2, Batch 90 - Loss: 0.205, Accuracy: 0.945\n",
      "Epoch 2, Batch 91 - Loss: 0.501, Accuracy: 0.828\n",
      "Epoch 2, Batch 92 - Loss: 0.430, Accuracy: 0.875\n",
      "Epoch 2, Batch 93 - Loss: 0.352, Accuracy: 0.875\n",
      "Epoch 2, Batch 94 - Loss: 0.311, Accuracy: 0.891\n",
      "Epoch 2, Batch 95 - Loss: 0.173, Accuracy: 0.945\n",
      "Epoch 2, Batch 96 - Loss: 0.407, Accuracy: 0.898\n",
      "Epoch 2, Batch 97 - Loss: 0.334, Accuracy: 0.867\n",
      "Epoch 2, Batch 98 - Loss: 0.379, Accuracy: 0.859\n",
      "Epoch 2, Batch 99 - Loss: 0.519, Accuracy: 0.852\n",
      "Epoch 2, Batch 100 - Loss: 0.327, Accuracy: 0.906\n",
      "Epoch 2, Batch 101 - Loss: 0.292, Accuracy: 0.898\n",
      "Epoch 2, Batch 102 - Loss: 0.335, Accuracy: 0.883\n",
      "Epoch 2, Batch 103 - Loss: 0.369, Accuracy: 0.906\n",
      "Epoch 2, Batch 104 - Loss: 0.257, Accuracy: 0.922\n",
      "Epoch 2, Batch 105 - Loss: 0.274, Accuracy: 0.914\n",
      "Epoch 2, Batch 106 - Loss: 0.205, Accuracy: 0.922\n",
      "Epoch 2, Batch 107 - Loss: 0.295, Accuracy: 0.914\n",
      "Epoch 2, Batch 108 - Loss: 0.292, Accuracy: 0.906\n",
      "Epoch 2, Batch 109 - Loss: 0.327, Accuracy: 0.883\n",
      "Epoch 2, Batch 110 - Loss: 0.341, Accuracy: 0.914\n",
      "Epoch 2, Batch 111 - Loss: 0.281, Accuracy: 0.906\n",
      "Epoch 2, Batch 112 - Loss: 0.323, Accuracy: 0.875\n",
      "Epoch 2, Batch 113 - Loss: 0.363, Accuracy: 0.852\n",
      "Epoch 2, Batch 114 - Loss: 0.366, Accuracy: 0.891\n",
      "Epoch 2, Batch 115 - Loss: 0.415, Accuracy: 0.852\n",
      "Epoch 2, Batch 116 - Loss: 0.490, Accuracy: 0.844\n",
      "Epoch 2, Batch 117 - Loss: 0.321, Accuracy: 0.906\n",
      "Epoch 2, Batch 118 - Loss: 0.214, Accuracy: 0.922\n",
      "Epoch 2, Batch 119 - Loss: 0.418, Accuracy: 0.828\n",
      "Epoch 2, Batch 120 - Loss: 0.285, Accuracy: 0.883\n",
      "Epoch 2, Batch 121 - Loss: 0.305, Accuracy: 0.914\n",
      "Epoch 2, Batch 122 - Loss: 0.218, Accuracy: 0.969\n",
      "Epoch 2, Batch 123 - Loss: 0.258, Accuracy: 0.906\n",
      "Epoch 2, Batch 124 - Loss: 0.415, Accuracy: 0.852\n",
      "Epoch 2, Batch 125 - Loss: 0.411, Accuracy: 0.883\n",
      "Epoch 2, Batch 126 - Loss: 0.395, Accuracy: 0.867\n",
      "Epoch 2, Batch 127 - Loss: 0.217, Accuracy: 0.938\n",
      "Epoch 2, Batch 128 - Loss: 0.268, Accuracy: 0.898\n",
      "Epoch 2, Batch 129 - Loss: 0.286, Accuracy: 0.867\n",
      "Epoch 2, Batch 130 - Loss: 0.286, Accuracy: 0.914\n",
      "Epoch 2, Batch 131 - Loss: 0.301, Accuracy: 0.906\n",
      "Epoch 2, Batch 132 - Loss: 0.319, Accuracy: 0.867\n",
      "Epoch 2, Batch 133 - Loss: 0.461, Accuracy: 0.852\n",
      "Epoch 2, Batch 134 - Loss: 0.475, Accuracy: 0.844\n",
      "Epoch 2, Batch 135 - Loss: 0.246, Accuracy: 0.898\n",
      "Epoch 2, Batch 136 - Loss: 0.200, Accuracy: 0.938\n",
      "Epoch 2, Batch 137 - Loss: 0.268, Accuracy: 0.922\n",
      "Epoch 2, Batch 138 - Loss: 0.280, Accuracy: 0.898\n",
      "Epoch 2, Batch 139 - Loss: 0.223, Accuracy: 0.938\n",
      "Epoch 2, Batch 140 - Loss: 0.342, Accuracy: 0.883\n",
      "Epoch 2, Batch 141 - Loss: 0.226, Accuracy: 0.914\n",
      "Epoch 2, Batch 142 - Loss: 0.292, Accuracy: 0.914\n",
      "Epoch 2, Batch 143 - Loss: 0.141, Accuracy: 0.961\n",
      "Epoch 2, Batch 144 - Loss: 0.277, Accuracy: 0.922\n",
      "Epoch 2, Batch 145 - Loss: 0.201, Accuracy: 0.938\n",
      "Epoch 2, Batch 146 - Loss: 0.242, Accuracy: 0.914\n",
      "Epoch 2, Batch 147 - Loss: 0.198, Accuracy: 0.906\n",
      "Epoch 2, Batch 148 - Loss: 0.154, Accuracy: 0.953\n",
      "Epoch 2, Batch 149 - Loss: 0.282, Accuracy: 0.898\n",
      "Epoch 2, Batch 150 - Loss: 0.356, Accuracy: 0.891\n",
      "Epoch 2, Batch 151 - Loss: 0.279, Accuracy: 0.922\n",
      "Epoch 2, Batch 152 - Loss: 0.258, Accuracy: 0.930\n",
      "Epoch 2, Batch 153 - Loss: 0.222, Accuracy: 0.938\n",
      "Epoch 2, Batch 154 - Loss: 0.224, Accuracy: 0.906\n",
      "Epoch 2, Batch 155 - Loss: 0.285, Accuracy: 0.914\n",
      "Epoch 2, Batch 156 - Loss: 0.435, Accuracy: 0.836\n",
      "Epoch 2, Batch 157 - Loss: 0.499, Accuracy: 0.820\n",
      "Epoch 2, Batch 158 - Loss: 0.384, Accuracy: 0.859\n",
      "Epoch 2, Batch 159 - Loss: 0.298, Accuracy: 0.883\n",
      "Epoch 2, Batch 160 - Loss: 0.184, Accuracy: 0.930\n",
      "Epoch 2, Batch 161 - Loss: 0.270, Accuracy: 0.938\n",
      "Epoch 2, Batch 162 - Loss: 0.349, Accuracy: 0.906\n",
      "Epoch 2, Batch 163 - Loss: 0.309, Accuracy: 0.898\n",
      "Epoch 2, Batch 164 - Loss: 0.396, Accuracy: 0.852\n",
      "Epoch 2, Batch 165 - Loss: 0.263, Accuracy: 0.898\n",
      "Epoch 2, Batch 166 - Loss: 0.319, Accuracy: 0.867\n",
      "Epoch 2, Batch 167 - Loss: 0.217, Accuracy: 0.938\n",
      "Epoch 2, Batch 168 - Loss: 0.322, Accuracy: 0.906\n",
      "Epoch 2, Batch 169 - Loss: 0.318, Accuracy: 0.922\n",
      "Epoch 2, Batch 170 - Loss: 0.286, Accuracy: 0.891\n",
      "Epoch 2, Batch 171 - Loss: 0.180, Accuracy: 0.938\n",
      "Epoch 2, Batch 172 - Loss: 0.243, Accuracy: 0.914\n",
      "Epoch 2, Batch 173 - Loss: 0.262, Accuracy: 0.922\n",
      "Epoch 2, Batch 174 - Loss: 0.306, Accuracy: 0.883\n",
      "Epoch 2, Batch 175 - Loss: 0.221, Accuracy: 0.930\n",
      "Epoch 2, Batch 176 - Loss: 0.395, Accuracy: 0.867\n",
      "Epoch 2, Batch 177 - Loss: 0.386, Accuracy: 0.852\n",
      "Epoch 2, Batch 178 - Loss: 0.255, Accuracy: 0.898\n",
      "Epoch 2, Batch 179 - Loss: 0.199, Accuracy: 0.938\n",
      "Epoch 2, Batch 180 - Loss: 0.123, Accuracy: 0.977\n",
      "Epoch 2, Batch 181 - Loss: 0.159, Accuracy: 0.945\n",
      "Epoch 2, Batch 182 - Loss: 0.253, Accuracy: 0.922\n",
      "Epoch 2, Batch 183 - Loss: 0.238, Accuracy: 0.922\n",
      "Epoch 2, Batch 184 - Loss: 0.289, Accuracy: 0.891\n",
      "Epoch 2, Batch 185 - Loss: 0.199, Accuracy: 0.922\n",
      "Epoch 2, Batch 186 - Loss: 0.303, Accuracy: 0.875\n",
      "Epoch 2, Batch 187 - Loss: 0.347, Accuracy: 0.875\n",
      "Epoch 2, Batch 188 - Loss: 0.281, Accuracy: 0.906\n",
      "Epoch 2, Batch 189 - Loss: 0.282, Accuracy: 0.930\n",
      "Epoch 2, Batch 190 - Loss: 0.249, Accuracy: 0.938\n",
      "Epoch 2, Batch 191 - Loss: 0.294, Accuracy: 0.914\n",
      "Epoch 2, Batch 192 - Loss: 0.345, Accuracy: 0.883\n",
      "Epoch 2, Batch 193 - Loss: 0.485, Accuracy: 0.852\n",
      "Epoch 2, Batch 194 - Loss: 0.320, Accuracy: 0.875\n",
      "Epoch 2, Batch 195 - Loss: 0.270, Accuracy: 0.891\n",
      "Epoch 2, Batch 196 - Loss: 0.207, Accuracy: 0.914\n",
      "Epoch 2, Batch 197 - Loss: 0.249, Accuracy: 0.906\n",
      "Epoch 2, Batch 198 - Loss: 0.302, Accuracy: 0.906\n",
      "Epoch 2, Batch 199 - Loss: 0.224, Accuracy: 0.930\n",
      "Epoch 2, Batch 200 - Loss: 0.360, Accuracy: 0.906\n",
      "Epoch 2, Batch 201 - Loss: 0.265, Accuracy: 0.922\n",
      "Epoch 2, Batch 202 - Loss: 0.254, Accuracy: 0.930\n",
      "Epoch 2, Batch 203 - Loss: 0.253, Accuracy: 0.914\n",
      "Epoch 2, Batch 204 - Loss: 0.222, Accuracy: 0.930\n",
      "Epoch 2, Batch 205 - Loss: 0.207, Accuracy: 0.938\n",
      "Epoch 2, Batch 206 - Loss: 0.199, Accuracy: 0.938\n",
      "Epoch 2, Batch 207 - Loss: 0.411, Accuracy: 0.875\n",
      "Epoch 2, Batch 208 - Loss: 0.302, Accuracy: 0.883\n",
      "Epoch 2, Batch 209 - Loss: 0.406, Accuracy: 0.875\n",
      "Epoch 2, Batch 210 - Loss: 0.214, Accuracy: 0.914\n",
      "Epoch 2, Batch 211 - Loss: 0.263, Accuracy: 0.891\n",
      "Epoch 2, Batch 212 - Loss: 0.340, Accuracy: 0.891\n",
      "Epoch 2, Batch 213 - Loss: 0.360, Accuracy: 0.836\n",
      "Epoch 2, Batch 214 - Loss: 0.291, Accuracy: 0.898\n",
      "Epoch 2, Batch 215 - Loss: 0.281, Accuracy: 0.891\n",
      "Epoch 2, Batch 216 - Loss: 0.187, Accuracy: 0.938\n",
      "Epoch 2, Batch 217 - Loss: 0.251, Accuracy: 0.898\n",
      "Epoch 2, Batch 218 - Loss: 0.336, Accuracy: 0.906\n",
      "Epoch 2, Batch 219 - Loss: 0.200, Accuracy: 0.945\n",
      "Epoch 2, Batch 220 - Loss: 0.199, Accuracy: 0.938\n",
      "Epoch 2, Batch 221 - Loss: 0.363, Accuracy: 0.859\n",
      "Epoch 2, Batch 222 - Loss: 0.286, Accuracy: 0.891\n",
      "Epoch 2, Batch 223 - Loss: 0.192, Accuracy: 0.938\n",
      "Epoch 2, Batch 224 - Loss: 0.392, Accuracy: 0.844\n",
      "Epoch 2, Batch 225 - Loss: 0.275, Accuracy: 0.938\n",
      "Epoch 2, Batch 226 - Loss: 0.288, Accuracy: 0.914\n",
      "Epoch 2, Batch 227 - Loss: 0.292, Accuracy: 0.898\n",
      "Epoch 2, Batch 228 - Loss: 0.320, Accuracy: 0.906\n",
      "Epoch 2, Batch 229 - Loss: 0.326, Accuracy: 0.859\n",
      "Epoch 2, Batch 230 - Loss: 0.230, Accuracy: 0.961\n",
      "Epoch 2, Batch 231 - Loss: 0.194, Accuracy: 0.938\n",
      "Epoch 2, Batch 232 - Loss: 0.249, Accuracy: 0.922\n",
      "Epoch 2, Batch 233 - Loss: 0.368, Accuracy: 0.859\n",
      "Epoch 2, Batch 234 - Loss: 0.406, Accuracy: 0.875\n",
      "Epoch 2, Batch 235 - Loss: 0.252, Accuracy: 0.914\n",
      "Epoch 2, Batch 236 - Loss: 0.380, Accuracy: 0.859\n",
      "Epoch 2, Batch 237 - Loss: 0.229, Accuracy: 0.945\n",
      "Epoch 2, Batch 238 - Loss: 0.268, Accuracy: 0.906\n",
      "Epoch 2, Batch 239 - Loss: 0.336, Accuracy: 0.891\n",
      "Epoch 2, Batch 240 - Loss: 0.293, Accuracy: 0.914\n",
      "Epoch 2, Batch 241 - Loss: 0.273, Accuracy: 0.922\n",
      "Epoch 2, Batch 242 - Loss: 0.276, Accuracy: 0.906\n",
      "Epoch 2, Batch 243 - Loss: 0.321, Accuracy: 0.898\n",
      "Epoch 2, Batch 244 - Loss: 0.327, Accuracy: 0.930\n",
      "Epoch 2, Batch 245 - Loss: 0.342, Accuracy: 0.875\n",
      "Epoch 2, Batch 246 - Loss: 0.262, Accuracy: 0.914\n",
      "Epoch 2, Batch 247 - Loss: 0.295, Accuracy: 0.867\n",
      "Epoch 2, Batch 248 - Loss: 0.441, Accuracy: 0.859\n",
      "Epoch 2, Batch 249 - Loss: 0.289, Accuracy: 0.930\n",
      "Epoch 2, Batch 250 - Loss: 0.244, Accuracy: 0.938\n",
      "Epoch 2, Batch 251 - Loss: 0.245, Accuracy: 0.914\n",
      "Epoch 2, Batch 252 - Loss: 0.229, Accuracy: 0.930\n",
      "Epoch 2, Batch 253 - Loss: 0.378, Accuracy: 0.883\n",
      "Epoch 2, Batch 254 - Loss: 0.429, Accuracy: 0.867\n",
      "Epoch 2, Batch 255 - Loss: 0.221, Accuracy: 0.906\n",
      "Epoch 2, Batch 256 - Loss: 0.264, Accuracy: 0.945\n",
      "Epoch 2, Batch 257 - Loss: 0.252, Accuracy: 0.945\n",
      "Epoch 2, Batch 258 - Loss: 0.179, Accuracy: 0.953\n",
      "Epoch 2, Batch 259 - Loss: 0.260, Accuracy: 0.914\n",
      "Epoch 2, Batch 260 - Loss: 0.241, Accuracy: 0.938\n",
      "Epoch 2, Batch 261 - Loss: 0.259, Accuracy: 0.922\n",
      "Epoch 2, Batch 262 - Loss: 0.280, Accuracy: 0.922\n",
      "Epoch 2, Batch 263 - Loss: 0.191, Accuracy: 0.938\n",
      "Epoch 2, Batch 264 - Loss: 0.262, Accuracy: 0.898\n",
      "Epoch 2, Batch 265 - Loss: 0.139, Accuracy: 0.961\n",
      "Epoch 2, Batch 266 - Loss: 0.179, Accuracy: 0.945\n",
      "Epoch 2, Batch 267 - Loss: 0.216, Accuracy: 0.906\n",
      "Epoch 2, Batch 268 - Loss: 0.114, Accuracy: 0.961\n",
      "Epoch 2, Batch 269 - Loss: 0.294, Accuracy: 0.914\n",
      "Epoch 2, Batch 270 - Loss: 0.295, Accuracy: 0.898\n",
      "Epoch 2, Batch 271 - Loss: 0.287, Accuracy: 0.914\n",
      "Epoch 2, Batch 272 - Loss: 0.298, Accuracy: 0.914\n",
      "Epoch 2, Batch 273 - Loss: 0.410, Accuracy: 0.844\n",
      "Epoch 2, Batch 274 - Loss: 0.210, Accuracy: 0.945\n",
      "Epoch 2, Batch 275 - Loss: 0.209, Accuracy: 0.930\n",
      "Epoch 2, Batch 276 - Loss: 0.231, Accuracy: 0.922\n",
      "Epoch 2, Batch 277 - Loss: 0.229, Accuracy: 0.961\n",
      "Epoch 2, Batch 278 - Loss: 0.171, Accuracy: 0.961\n",
      "Epoch 2, Batch 279 - Loss: 0.357, Accuracy: 0.906\n",
      "Epoch 2, Batch 280 - Loss: 0.175, Accuracy: 0.922\n",
      "Epoch 2, Batch 281 - Loss: 0.325, Accuracy: 0.898\n",
      "Epoch 2, Batch 282 - Loss: 0.363, Accuracy: 0.891\n",
      "Epoch 2, Batch 283 - Loss: 0.245, Accuracy: 0.898\n",
      "Epoch 2, Batch 284 - Loss: 0.264, Accuracy: 0.914\n",
      "Epoch 2, Batch 285 - Loss: 0.367, Accuracy: 0.875\n",
      "Epoch 2, Batch 286 - Loss: 0.243, Accuracy: 0.898\n",
      "Epoch 2, Batch 287 - Loss: 0.209, Accuracy: 0.922\n",
      "Epoch 2, Batch 288 - Loss: 0.260, Accuracy: 0.914\n",
      "Epoch 2, Batch 289 - Loss: 0.248, Accuracy: 0.922\n",
      "Epoch 2, Batch 290 - Loss: 0.392, Accuracy: 0.883\n",
      "Epoch 2, Batch 291 - Loss: 0.299, Accuracy: 0.906\n",
      "Epoch 2, Batch 292 - Loss: 0.453, Accuracy: 0.852\n",
      "Epoch 2, Batch 293 - Loss: 0.467, Accuracy: 0.859\n",
      "Epoch 2, Batch 294 - Loss: 0.399, Accuracy: 0.859\n",
      "Epoch 2, Batch 295 - Loss: 0.307, Accuracy: 0.898\n",
      "Epoch 2, Batch 296 - Loss: 0.258, Accuracy: 0.914\n",
      "Epoch 2, Batch 297 - Loss: 0.193, Accuracy: 0.953\n",
      "Epoch 2, Batch 298 - Loss: 0.215, Accuracy: 0.922\n",
      "Epoch 2, Batch 299 - Loss: 0.206, Accuracy: 0.945\n",
      "Epoch 2, Batch 300 - Loss: 0.332, Accuracy: 0.891\n",
      "Epoch 2, Batch 301 - Loss: 0.228, Accuracy: 0.930\n",
      "Epoch 2, Batch 302 - Loss: 0.344, Accuracy: 0.867\n",
      "Epoch 2, Batch 303 - Loss: 0.240, Accuracy: 0.945\n",
      "Epoch 2, Batch 304 - Loss: 0.205, Accuracy: 0.922\n",
      "Epoch 2, Batch 305 - Loss: 0.176, Accuracy: 0.930\n",
      "Epoch 2, Batch 306 - Loss: 0.146, Accuracy: 0.945\n",
      "Epoch 2, Batch 307 - Loss: 0.312, Accuracy: 0.914\n",
      "Epoch 2, Batch 308 - Loss: 0.418, Accuracy: 0.852\n",
      "Epoch 2, Batch 309 - Loss: 0.273, Accuracy: 0.914\n",
      "Epoch 2, Batch 310 - Loss: 0.272, Accuracy: 0.906\n",
      "Epoch 2, Batch 311 - Loss: 0.331, Accuracy: 0.891\n",
      "Epoch 2, Batch 312 - Loss: 0.296, Accuracy: 0.914\n",
      "Epoch 2, Batch 313 - Loss: 0.287, Accuracy: 0.891\n",
      "Epoch 2, Batch 314 - Loss: 0.165, Accuracy: 0.953\n",
      "Epoch 2, Batch 315 - Loss: 0.243, Accuracy: 0.930\n",
      "Epoch 2, Batch 316 - Loss: 0.276, Accuracy: 0.891\n",
      "Epoch 2, Batch 317 - Loss: 0.373, Accuracy: 0.914\n",
      "Epoch 2, Batch 318 - Loss: 0.374, Accuracy: 0.875\n",
      "Epoch 2, Batch 319 - Loss: 0.174, Accuracy: 0.945\n",
      "Epoch 2, Batch 320 - Loss: 0.145, Accuracy: 0.953\n",
      "Epoch 2, Batch 321 - Loss: 0.306, Accuracy: 0.898\n",
      "Epoch 2, Batch 322 - Loss: 0.231, Accuracy: 0.938\n",
      "Epoch 2, Batch 323 - Loss: 0.353, Accuracy: 0.883\n",
      "Epoch 2, Batch 324 - Loss: 0.352, Accuracy: 0.930\n",
      "Epoch 2, Batch 325 - Loss: 0.466, Accuracy: 0.844\n",
      "Epoch 2, Batch 326 - Loss: 0.135, Accuracy: 0.961\n",
      "Epoch 2, Batch 327 - Loss: 0.176, Accuracy: 0.938\n",
      "Epoch 2, Batch 328 - Loss: 0.138, Accuracy: 0.969\n",
      "Epoch 2, Batch 329 - Loss: 0.213, Accuracy: 0.945\n",
      "Epoch 2, Batch 330 - Loss: 0.326, Accuracy: 0.883\n",
      "Epoch 2, Batch 331 - Loss: 0.373, Accuracy: 0.859\n",
      "Epoch 2, Batch 332 - Loss: 0.348, Accuracy: 0.891\n",
      "Epoch 2, Batch 333 - Loss: 0.227, Accuracy: 0.914\n",
      "Epoch 2, Batch 334 - Loss: 0.275, Accuracy: 0.891\n",
      "Epoch 2, Batch 335 - Loss: 0.275, Accuracy: 0.906\n",
      "Epoch 2, Batch 336 - Loss: 0.262, Accuracy: 0.914\n",
      "Epoch 2, Batch 337 - Loss: 0.330, Accuracy: 0.883\n",
      "Epoch 2, Batch 338 - Loss: 0.182, Accuracy: 0.922\n",
      "Epoch 2, Batch 339 - Loss: 0.134, Accuracy: 0.930\n",
      "Epoch 2, Batch 340 - Loss: 0.260, Accuracy: 0.922\n",
      "Epoch 2, Batch 341 - Loss: 0.191, Accuracy: 0.945\n",
      "Epoch 2, Batch 342 - Loss: 0.240, Accuracy: 0.930\n",
      "Epoch 2, Batch 343 - Loss: 0.355, Accuracy: 0.883\n",
      "Epoch 2, Batch 344 - Loss: 0.182, Accuracy: 0.961\n",
      "Epoch 2, Batch 345 - Loss: 0.244, Accuracy: 0.922\n",
      "Epoch 2, Batch 346 - Loss: 0.173, Accuracy: 0.938\n",
      "Epoch 2, Batch 347 - Loss: 0.217, Accuracy: 0.914\n",
      "Epoch 2, Batch 348 - Loss: 0.246, Accuracy: 0.930\n",
      "Epoch 2, Batch 349 - Loss: 0.118, Accuracy: 0.953\n",
      "Epoch 2, Batch 350 - Loss: 0.251, Accuracy: 0.906\n",
      "Epoch 2, Batch 351 - Loss: 0.331, Accuracy: 0.898\n",
      "Epoch 2, Batch 352 - Loss: 0.422, Accuracy: 0.875\n",
      "Epoch 2, Batch 353 - Loss: 0.292, Accuracy: 0.883\n",
      "Epoch 2, Batch 354 - Loss: 0.146, Accuracy: 0.930\n",
      "Epoch 2, Batch 355 - Loss: 0.197, Accuracy: 0.922\n",
      "Epoch 2, Batch 356 - Loss: 0.286, Accuracy: 0.906\n",
      "Epoch 2, Batch 357 - Loss: 0.238, Accuracy: 0.914\n",
      "Epoch 2, Batch 358 - Loss: 0.254, Accuracy: 0.914\n",
      "Epoch 2, Batch 359 - Loss: 0.349, Accuracy: 0.883\n",
      "Epoch 2, Batch 360 - Loss: 0.351, Accuracy: 0.891\n",
      "Epoch 2, Batch 361 - Loss: 0.338, Accuracy: 0.891\n",
      "Epoch 2, Batch 362 - Loss: 0.357, Accuracy: 0.852\n",
      "Epoch 2, Batch 363 - Loss: 0.302, Accuracy: 0.914\n",
      "Epoch 2, Batch 364 - Loss: 0.189, Accuracy: 0.945\n",
      "Epoch 2, Batch 365 - Loss: 0.180, Accuracy: 0.938\n",
      "Epoch 2, Batch 366 - Loss: 0.246, Accuracy: 0.922\n",
      "Epoch 2, Batch 367 - Loss: 0.225, Accuracy: 0.922\n",
      "Epoch 2, Batch 368 - Loss: 0.295, Accuracy: 0.891\n",
      "Epoch 2, Batch 369 - Loss: 0.264, Accuracy: 0.914\n",
      "Epoch 2, Batch 370 - Loss: 0.457, Accuracy: 0.820\n",
      "Epoch 2, Batch 371 - Loss: 0.285, Accuracy: 0.914\n",
      "Epoch 2, Batch 372 - Loss: 0.201, Accuracy: 0.938\n",
      "Epoch 2, Batch 373 - Loss: 0.205, Accuracy: 0.961\n",
      "Epoch 2, Batch 374 - Loss: 0.216, Accuracy: 0.930\n",
      "Epoch 2, Batch 375 - Loss: 0.384, Accuracy: 0.836\n",
      "Epoch 2, Batch 376 - Loss: 0.281, Accuracy: 0.914\n",
      "Epoch 2, Batch 377 - Loss: 0.172, Accuracy: 0.953\n",
      "Epoch 2, Batch 378 - Loss: 0.296, Accuracy: 0.891\n",
      "Epoch 2, Batch 379 - Loss: 0.199, Accuracy: 0.938\n",
      "Epoch 2, Batch 380 - Loss: 0.268, Accuracy: 0.914\n",
      "Epoch 2, Batch 381 - Loss: 0.217, Accuracy: 0.938\n",
      "Epoch 2, Batch 382 - Loss: 0.237, Accuracy: 0.914\n",
      "Epoch 2, Batch 383 - Loss: 0.368, Accuracy: 0.875\n",
      "Epoch 2, Batch 384 - Loss: 0.306, Accuracy: 0.875\n",
      "Epoch 2, Batch 385 - Loss: 0.231, Accuracy: 0.906\n",
      "Epoch 2, Batch 386 - Loss: 0.124, Accuracy: 0.969\n",
      "Epoch 2, Batch 387 - Loss: 0.387, Accuracy: 0.836\n",
      "Epoch 2, Batch 388 - Loss: 0.455, Accuracy: 0.867\n",
      "Epoch 2, Batch 389 - Loss: 0.219, Accuracy: 0.938\n",
      "Epoch 2, Batch 390 - Loss: 0.267, Accuracy: 0.930\n",
      "Epoch 2, Batch 391 - Loss: 0.211, Accuracy: 0.906\n",
      "Epoch 2, Batch 392 - Loss: 0.137, Accuracy: 0.961\n",
      "Epoch 2, Batch 393 - Loss: 0.324, Accuracy: 0.914\n",
      "Epoch 2, Batch 394 - Loss: 0.440, Accuracy: 0.859\n",
      "Epoch 2, Batch 395 - Loss: 0.303, Accuracy: 0.914\n",
      "Epoch 2, Batch 396 - Loss: 0.256, Accuracy: 0.930\n",
      "Epoch 2, Batch 397 - Loss: 0.364, Accuracy: 0.836\n",
      "Epoch 2, Batch 398 - Loss: 0.343, Accuracy: 0.883\n",
      "Epoch 2, Batch 399 - Loss: 0.180, Accuracy: 0.938\n",
      "Epoch 2, Batch 400 - Loss: 0.204, Accuracy: 0.938\n",
      "Epoch 2, Batch 401 - Loss: 0.323, Accuracy: 0.898\n",
      "Epoch 2, Batch 402 - Loss: 0.159, Accuracy: 0.961\n",
      "Epoch 2, Batch 403 - Loss: 0.221, Accuracy: 0.945\n",
      "Epoch 2, Batch 404 - Loss: 0.168, Accuracy: 0.945\n",
      "Epoch 2, Batch 405 - Loss: 0.344, Accuracy: 0.930\n",
      "Epoch 2, Batch 406 - Loss: 0.294, Accuracy: 0.930\n",
      "Epoch 2, Batch 407 - Loss: 0.266, Accuracy: 0.906\n",
      "Epoch 2, Batch 408 - Loss: 0.359, Accuracy: 0.875\n",
      "Epoch 2, Batch 409 - Loss: 0.219, Accuracy: 0.930\n",
      "Epoch 2, Batch 410 - Loss: 0.237, Accuracy: 0.906\n",
      "Epoch 2, Batch 411 - Loss: 0.080, Accuracy: 0.992\n",
      "Epoch 2, Batch 412 - Loss: 0.171, Accuracy: 0.938\n",
      "Epoch 2, Batch 413 - Loss: 0.269, Accuracy: 0.938\n",
      "Epoch 2, Batch 414 - Loss: 0.472, Accuracy: 0.859\n",
      "Epoch 2, Batch 415 - Loss: 0.269, Accuracy: 0.914\n",
      "Epoch 2, Batch 416 - Loss: 0.213, Accuracy: 0.930\n",
      "Epoch 2, Batch 417 - Loss: 0.121, Accuracy: 0.953\n",
      "Epoch 2, Batch 418 - Loss: 0.214, Accuracy: 0.945\n",
      "Epoch 2, Batch 419 - Loss: 0.359, Accuracy: 0.852\n",
      "Epoch 2, Batch 420 - Loss: 0.238, Accuracy: 0.930\n",
      "Epoch 2, Batch 421 - Loss: 0.223, Accuracy: 0.938\n",
      "Epoch 2, Batch 422 - Loss: 0.295, Accuracy: 0.914\n",
      "Epoch 2, Batch 423 - Loss: 0.177, Accuracy: 0.945\n",
      "Epoch 2, Batch 424 - Loss: 0.143, Accuracy: 0.969\n",
      "Epoch 2, Batch 425 - Loss: 0.247, Accuracy: 0.922\n",
      "Epoch 2, Batch 426 - Loss: 0.239, Accuracy: 0.914\n",
      "Epoch 2, Batch 427 - Loss: 0.229, Accuracy: 0.922\n",
      "Epoch 2, Batch 428 - Loss: 0.209, Accuracy: 0.945\n",
      "Epoch 2, Batch 429 - Loss: 0.316, Accuracy: 0.891\n",
      "Epoch 2, Batch 430 - Loss: 0.300, Accuracy: 0.922\n",
      "Epoch 2, Batch 431 - Loss: 0.148, Accuracy: 0.945\n",
      "Epoch 2, Batch 432 - Loss: 0.269, Accuracy: 0.914\n",
      "Epoch 2, Batch 433 - Loss: 0.207, Accuracy: 0.938\n",
      "Epoch 2, Batch 434 - Loss: 0.185, Accuracy: 0.938\n",
      "Epoch 2, Batch 435 - Loss: 0.116, Accuracy: 0.977\n",
      "Epoch 2, Batch 436 - Loss: 0.276, Accuracy: 0.914\n",
      "Epoch 2, Batch 437 - Loss: 0.235, Accuracy: 0.922\n",
      "Epoch 2, Batch 438 - Loss: 0.118, Accuracy: 0.977\n",
      "Epoch 2, Batch 439 - Loss: 0.180, Accuracy: 0.930\n",
      "Epoch 2, Batch 440 - Loss: 0.172, Accuracy: 0.938\n",
      "Epoch 2, Batch 441 - Loss: 0.173, Accuracy: 0.945\n",
      "Epoch 2, Batch 442 - Loss: 0.248, Accuracy: 0.930\n",
      "Epoch 2, Batch 443 - Loss: 0.285, Accuracy: 0.891\n",
      "Epoch 2, Batch 444 - Loss: 0.191, Accuracy: 0.945\n",
      "Epoch 2, Batch 445 - Loss: 0.209, Accuracy: 0.945\n",
      "Epoch 2, Batch 446 - Loss: 0.147, Accuracy: 0.953\n",
      "Epoch 2, Batch 447 - Loss: 0.087, Accuracy: 0.977\n",
      "Epoch 2, Batch 448 - Loss: 0.227, Accuracy: 0.914\n",
      "Epoch 2, Batch 449 - Loss: 0.076, Accuracy: 0.969\n",
      "Epoch 2, Batch 450 - Loss: 0.282, Accuracy: 0.914\n",
      "Epoch 2, Batch 451 - Loss: 0.187, Accuracy: 0.945\n",
      "Epoch 2, Batch 452 - Loss: 0.256, Accuracy: 0.922\n",
      "Epoch 2, Batch 453 - Loss: 0.215, Accuracy: 0.922\n",
      "Epoch 2, Batch 454 - Loss: 0.184, Accuracy: 0.953\n",
      "Epoch 2, Batch 455 - Loss: 0.071, Accuracy: 0.977\n",
      "Epoch 2, Batch 456 - Loss: 0.109, Accuracy: 0.969\n",
      "Epoch 2, Batch 457 - Loss: 0.224, Accuracy: 0.922\n",
      "Epoch 2, Batch 458 - Loss: 0.146, Accuracy: 0.961\n",
      "Epoch 2, Batch 459 - Loss: 0.081, Accuracy: 0.977\n",
      "Epoch 2, Batch 460 - Loss: 0.190, Accuracy: 0.930\n",
      "Epoch 2, Batch 461 - Loss: 0.077, Accuracy: 0.977\n",
      "Epoch 2, Batch 462 - Loss: 0.072, Accuracy: 0.969\n",
      "Epoch 2, Batch 463 - Loss: 0.122, Accuracy: 0.953\n",
      "Epoch 2, Batch 464 - Loss: 0.358, Accuracy: 0.867\n",
      "Epoch 2, Batch 465 - Loss: 0.341, Accuracy: 0.883\n",
      "Epoch 2, Batch 466 - Loss: 0.084, Accuracy: 0.969\n",
      "Epoch 2, Batch 467 - Loss: 0.632, Accuracy: 0.844\n",
      "Epoch 2, Batch 468 - Loss: 0.158, Accuracy: 0.930\n",
      "Epoch 2, Batch 469 - Loss: 0.301, Accuracy: 0.948\n",
      "Epoch 2 - Loss: 0.283, Accuracy: 0.908\n",
      "Testing...\n",
      "Epoch 2, Batch 1 - Loss: 0.121, Accuracy: 0.969\n",
      "Epoch 2, Batch 2 - Loss: 0.162, Accuracy: 0.945\n",
      "Epoch 2, Batch 3 - Loss: 0.253, Accuracy: 0.922\n",
      "Epoch 2, Batch 4 - Loss: 0.166, Accuracy: 0.938\n",
      "Epoch 2, Batch 5 - Loss: 0.176, Accuracy: 0.930\n",
      "Epoch 2, Batch 6 - Loss: 0.181, Accuracy: 0.938\n",
      "Epoch 2, Batch 7 - Loss: 0.146, Accuracy: 0.953\n",
      "Epoch 2, Batch 8 - Loss: 0.210, Accuracy: 0.930\n",
      "Epoch 2, Batch 9 - Loss: 0.154, Accuracy: 0.953\n",
      "Epoch 2, Batch 10 - Loss: 0.286, Accuracy: 0.914\n",
      "Epoch 2, Batch 11 - Loss: 0.123, Accuracy: 0.953\n",
      "Epoch 2, Batch 12 - Loss: 0.111, Accuracy: 0.961\n",
      "Epoch 2, Batch 13 - Loss: 0.151, Accuracy: 0.953\n",
      "Epoch 2, Batch 14 - Loss: 0.209, Accuracy: 0.938\n",
      "Epoch 2, Batch 15 - Loss: 0.096, Accuracy: 0.977\n",
      "Epoch 2, Batch 16 - Loss: 0.095, Accuracy: 0.977\n",
      "Epoch 2, Batch 17 - Loss: 0.207, Accuracy: 0.945\n",
      "Epoch 2, Batch 18 - Loss: 0.199, Accuracy: 0.930\n",
      "Epoch 2, Batch 19 - Loss: 0.173, Accuracy: 0.938\n",
      "Epoch 2, Batch 20 - Loss: 0.139, Accuracy: 0.953\n",
      "Epoch 2, Batch 21 - Loss: 0.135, Accuracy: 0.961\n",
      "Epoch 2, Batch 22 - Loss: 0.141, Accuracy: 0.969\n",
      "Epoch 2, Batch 23 - Loss: 0.139, Accuracy: 0.953\n",
      "Epoch 2, Batch 24 - Loss: 0.120, Accuracy: 0.969\n",
      "Epoch 2, Batch 25 - Loss: 0.177, Accuracy: 0.961\n",
      "Epoch 2, Batch 26 - Loss: 0.075, Accuracy: 0.992\n",
      "Epoch 2, Batch 27 - Loss: 0.135, Accuracy: 0.953\n",
      "Epoch 2, Batch 28 - Loss: 0.128, Accuracy: 0.953\n",
      "Epoch 2, Batch 29 - Loss: 0.108, Accuracy: 0.961\n",
      "Epoch 2, Batch 30 - Loss: 0.178, Accuracy: 0.930\n",
      "Epoch 2, Batch 31 - Loss: 0.245, Accuracy: 0.922\n",
      "Epoch 2, Batch 32 - Loss: 0.126, Accuracy: 0.961\n",
      "Epoch 2, Batch 33 - Loss: 0.129, Accuracy: 0.953\n",
      "Epoch 2, Batch 34 - Loss: 0.125, Accuracy: 0.961\n",
      "Epoch 2, Batch 35 - Loss: 0.096, Accuracy: 0.984\n",
      "Epoch 2, Batch 36 - Loss: 0.068, Accuracy: 0.992\n",
      "Epoch 2, Batch 37 - Loss: 0.111, Accuracy: 0.961\n",
      "Epoch 2, Batch 38 - Loss: 0.132, Accuracy: 0.945\n",
      "Epoch 2, Batch 39 - Loss: 0.101, Accuracy: 0.977\n",
      "Epoch 2, Batch 40 - Loss: 0.074, Accuracy: 0.977\n",
      "Epoch 2, Batch 41 - Loss: 0.131, Accuracy: 0.961\n",
      "Epoch 2, Batch 42 - Loss: 0.039, Accuracy: 0.992\n",
      "Epoch 2, Batch 43 - Loss: 0.019, Accuracy: 1.000\n",
      "Epoch 2, Batch 44 - Loss: 0.041, Accuracy: 0.984\n",
      "Epoch 2, Batch 45 - Loss: 0.098, Accuracy: 0.977\n",
      "Epoch 2, Batch 46 - Loss: 0.070, Accuracy: 0.977\n",
      "Epoch 2, Batch 47 - Loss: 0.294, Accuracy: 0.883\n",
      "Epoch 2, Batch 48 - Loss: 0.141, Accuracy: 0.953\n",
      "Epoch 2, Batch 49 - Loss: 0.066, Accuracy: 0.977\n",
      "Epoch 2, Batch 50 - Loss: 0.017, Accuracy: 1.000\n",
      "Epoch 2, Batch 51 - Loss: 0.069, Accuracy: 0.984\n",
      "Epoch 2, Batch 52 - Loss: 0.359, Accuracy: 0.891\n",
      "Epoch 2, Batch 53 - Loss: 0.081, Accuracy: 0.984\n",
      "Epoch 2, Batch 54 - Loss: 0.033, Accuracy: 0.992\n",
      "Epoch 2, Batch 55 - Loss: 0.031, Accuracy: 0.992\n",
      "Epoch 2, Batch 56 - Loss: 0.041, Accuracy: 0.992\n",
      "Epoch 2, Batch 57 - Loss: 0.050, Accuracy: 0.992\n",
      "Epoch 2, Batch 58 - Loss: 0.043, Accuracy: 0.992\n",
      "Epoch 2, Batch 59 - Loss: 0.102, Accuracy: 0.969\n",
      "Epoch 2, Batch 60 - Loss: 0.060, Accuracy: 0.977\n",
      "Epoch 2, Batch 61 - Loss: 0.033, Accuracy: 0.992\n",
      "Epoch 2, Batch 62 - Loss: 0.228, Accuracy: 0.906\n",
      "Epoch 2, Batch 63 - Loss: 0.076, Accuracy: 0.969\n",
      "Epoch 2, Batch 64 - Loss: 0.061, Accuracy: 0.977\n",
      "Epoch 2, Batch 65 - Loss: 0.079, Accuracy: 0.969\n",
      "Epoch 2, Batch 66 - Loss: 0.163, Accuracy: 0.961\n",
      "Epoch 2, Batch 67 - Loss: 0.056, Accuracy: 0.984\n",
      "Epoch 2, Batch 68 - Loss: 0.008, Accuracy: 1.000\n",
      "Epoch 2, Batch 69 - Loss: 0.004, Accuracy: 1.000\n",
      "Epoch 2, Batch 70 - Loss: 0.013, Accuracy: 1.000\n",
      "Epoch 2, Batch 71 - Loss: 0.062, Accuracy: 0.984\n",
      "Epoch 2, Batch 72 - Loss: 0.039, Accuracy: 0.984\n",
      "Epoch 2, Batch 73 - Loss: 0.056, Accuracy: 0.977\n",
      "Epoch 2, Batch 74 - Loss: 0.017, Accuracy: 1.000\n",
      "Epoch 2, Batch 75 - Loss: 0.063, Accuracy: 0.984\n",
      "Epoch 2, Batch 76 - Loss: 0.142, Accuracy: 0.930\n",
      "Epoch 2, Batch 77 - Loss: 0.248, Accuracy: 0.914\n",
      "Epoch 2, Batch 78 - Loss: 0.161, Accuracy: 0.953\n",
      "Epoch 2, Batch 79 - Loss: 0.015, Accuracy: 1.000\n",
      "Epoch 2 - Loss: 0.117, Accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    print('Training...')\n",
    "    training_loop(train_loader, epoch)\n",
    "\n",
    "    net.eval()\n",
    "    print('Testing...')\n",
    "    training_loop(test_loader, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
