{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 12 - Convolutional Neural Network MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x76039802e4d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:25<00:00, 387304.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 204857.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1571649.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 25400705.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
    "test = datasets.MNIST(root='.', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7602a84cd3c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbV0lEQVR4nO3df2xV9f3H8dct0Atqe7ta2ts7CraIssiPZShdoyKOpqVLHAh/gD8SMEYiFjfsnKZGQadLN0ycX5eKyVyoRhFlEYj8AYFqy9wKBpQQomto1w1IaVGW3gtFCqGf7x/EO68U8Fzu7bv38nwkJ6H3nk/vm+MJT097e+pzzjkBADDIMqwHAABcmQgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMdx6gO/q7+9XZ2ensrKy5PP5rMcBAHjknNPx48cVCoWUkXHh65whF6DOzk4VFRVZjwEAuEyHDh3SmDFjLvj8kPsSXFZWlvUIAIAEuNS/50kLUH19va677jqNHDlSpaWl+uSTT77XOr7sBgDp4VL/niclQO+++65qamq0cuVKffrpp5o6daoqKyt19OjRZLwcACAVuSSYPn26q66ujn589uxZFwqFXF1d3SXXhsNhJ4mNjY2NLcW3cDh80X/vE34FdPr0ae3Zs0fl5eXRxzIyMlReXq6Wlpbz9u/r61MkEonZAADpL+EB+uqrr3T27FkVFBTEPF5QUKCurq7z9q+rq1MgEIhuvAMOAK4M5u+Cq62tVTgcjm6HDh2yHgkAMAgS/nNAeXl5GjZsmLq7u2Me7+7uVjAYPG9/v98vv9+f6DEAAENcwq+AMjMzNW3aNDU2NkYf6+/vV2Njo8rKyhL9cgCAFJWUOyHU1NRo0aJFuvnmmzV9+nS9/PLL6u3t1QMPPJCMlwMApKCkBGjBggX68ssvtWLFCnV1denHP/6xtmzZct4bEwAAVy6fc85ZD/FtkUhEgUDAegwAwGUKh8PKzs6+4PPm74IDAFyZCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiYQH6Nlnn5XP54vZJk6cmOiXAQCkuOHJ+KQ33XSTtm/f/r8XGZ6UlwEApLCklGH48OEKBoPJ+NQAgDSRlO8BHThwQKFQSCUlJbrvvvt08ODBC+7b19enSCQSswEA0l/CA1RaWqqGhgZt2bJFq1evVkdHh26//XYdP358wP3r6uoUCASiW1FRUaJHAgAMQT7nnEvmC/T09GjcuHF66aWX9OCDD573fF9fn/r6+qIfRyIRIgQAaSAcDis7O/uCzyf93QE5OTm64YYb1NbWNuDzfr9ffr8/2WMAAIaYpP8c0IkTJ9Te3q7CwsJkvxQAIIUkPECPP/64mpub9e9//1v/+Mc/dPfdd2vYsGG65557Ev1SAIAUlvAvwR0+fFj33HOPjh07ptGjR+u2227Tzp07NXr06ES/FAAghSX9TQheRSIRBQIB6zEAAJfpUm9C4F5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJpP9COiCVlJaWel5z//33e15zxx13eF5z0003eV4Tr8cff9zzms7OTs9rbrvtNs9r3nrrLc9rdu3a5XkNko8rIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgbthISwsWLIhr3f/93/95XpOXl+d5jc/n87ymqanJ85rRo0d7XiNJL774YlzrvIrnOMTzd1q4cKHnNUg+roAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBSDavhw76fczTff7HnNn//8Z89rJOmqq67yvGbHjh2e1zz//POe13z88cee1/j9fs9rJOm9997zvKaioiKu1/Jq9+7dg/I6SD6ugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFIPq/vvv97zm9ddfT8IkA9u2bZvnNQsWLPC8JhKJeF4Tj3hmkwbvxqKHDx/2vOaNN95IwiSwwBUQAMAEAQIAmPAcoB07duiuu+5SKBSSz+fTxo0bY553zmnFihUqLCzUqFGjVF5ergMHDiRqXgBAmvAcoN7eXk2dOlX19fUDPr9q1Sq98soreu2117Rr1y5dffXVqqys1KlTpy57WABA+vD8JoSqqipVVVUN+JxzTi+//LKefvppzZkzR5L05ptvqqCgQBs3btTChQsvb1oAQNpI6PeAOjo61NXVpfLy8uhjgUBApaWlamlpGXBNX1+fIpFIzAYASH8JDVBXV5ckqaCgIObxgoKC6HPfVVdXp0AgEN2KiooSORIAYIgyfxdcbW2twuFwdDt06JD1SACAQZDQAAWDQUlSd3d3zOPd3d3R577L7/crOzs7ZgMApL+EBqi4uFjBYFCNjY3RxyKRiHbt2qWysrJEvhQAIMV5fhfciRMn1NbWFv24o6NDe/fuVW5ursaOHavly5frhRde0IQJE1RcXKxnnnlGoVBIc+fOTeTcAIAU5zlAu3fv1p133hn9uKamRpK0aNEiNTQ06IknnlBvb6+WLFminp4e3XbbbdqyZYtGjhyZuKkBACnP55xz1kN8WyQSUSAQsB4D38Pzzz/vec1TTz3leU08p+irr77qeY0kPf30057XDOUfHfjiiy/iWjdhwoQETzKw+fPne16zadOmJEyCZAiHwxf9vr75u+AAAFcmAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPD86xiQflasWBHXunjubH369GnPa7Zu3ep5zZNPPul5jSR9/fXXca3zKp5fT1JRUeF5zdixYz2vkSSfz+d5zQsvvOB5DXe2vrJxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpGkmJyfH85pHHnkkrtdyznleE8+NRefOnet5zWC6/vrrPa95++23Pa+ZNm2a5zXx+utf/+p5zapVq5IwCdIZV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRppmMjMzPa/Jy8tLwiQD++Uvf+l5TX5+vuc1DzzwgOc1kvSLX/zC85pJkyZ5XnPNNdd4XhPPzV/jWSNJb731luc1vb29cb0WrlxcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJnwu3rsVJkkkElEgELAeI2Xl5OR4XvPFF1/E9VqjR4/2vMbn83leM8RO0fN0dnZ6XhPPcSgsLPS85ssvv/S8Jt7XAr4rHA4rOzv7gs9zBQQAMEGAAAAmPAdox44duuuuuxQKheTz+bRx48aY5xcvXiyfzxezzZ49O1HzAgDShOcA9fb2aurUqaqvr7/gPrNnz9aRI0ei2zvvvHNZQwIA0o/n34haVVWlqqqqi+7j9/sVDAbjHgoAkP6S8j2gpqYm5efn68Ybb9TSpUt17NixC+7b19enSCQSswEA0l/CAzR79my9+eabamxs1B/+8Ac1NzerqqpKZ8+eHXD/uro6BQKB6FZUVJTokQAAQ5DnL8FdysKFC6N/njx5sqZMmaLx48erqalJs2bNOm//2tpa1dTURD+ORCJECACuAEl/G3ZJSYny8vLU1tY24PN+v1/Z2dkxGwAg/SU9QIcPH9axY8f4yWoAQAzPX4I7ceJEzNVMR0eH9u7dq9zcXOXm5uq5557T/PnzFQwG1d7erieeeELXX3+9KisrEzo4ACC1eQ7Q7t27deedd0Y//ub7N4sWLdLq1au1b98+vfHGG+rp6VEoFFJFRYWef/55+f3+xE0NAEh5ngM0c+bMi94ccuvWrZc1EC5PT0+P5zVz586N67U2b97seU1ubq7nNe3t7Z7XbNq0yfMaSWpoaPC85r///a/nNevWrfO8Jp4vY8fzOsBg4V5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMJHwX8mN1LNr16641o0ePTrBk6SmGTNmeF5zxx13eF7T39/vec2//vUvz2uAwcIVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRApdp1KhRntfEc2NR55znNevWrfO8BhgsXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSlwmbZu3Wo9ApCSuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1LgMlVWVlqPAKQkroAAACYIEADAhKcA1dXV6ZZbblFWVpby8/M1d+5ctba2xuxz6tQpVVdX69prr9U111yj+fPnq7u7O6FDAwBSn6cANTc3q7q6Wjt37tS2bdt05swZVVRUqLe3N7rPY489pg8++EDr169Xc3OzOjs7NW/evIQPDgBIbZ7ehLBly5aYjxsaGpSfn689e/ZoxowZCofD+stf/qK1a9fqZz/7mSRpzZo1+tGPfqSdO3fqpz/9aeImBwCktMv6HlA4HJYk5ebmSpL27NmjM2fOqLy8PLrPxIkTNXbsWLW0tAz4Ofr6+hSJRGI2AED6iztA/f39Wr58uW699VZNmjRJktTV1aXMzEzl5OTE7FtQUKCurq4BP09dXZ0CgUB0KyoqinckAEAKiTtA1dXV2r9/v9atW3dZA9TW1iocDke3Q4cOXdbnAwCkhrh+EHXZsmXavHmzduzYoTFjxkQfDwaDOn36tHp6emKugrq7uxUMBgf8XH6/X36/P54xAAApzNMVkHNOy5Yt04YNG/Thhx+quLg45vlp06ZpxIgRamxsjD7W2tqqgwcPqqysLDETAwDSgqcroOrqaq1du1abNm1SVlZW9Ps6gUBAo0aNUiAQ0IMPPqiamhrl5uYqOztbjz76qMrKyngHHAAghqcArV69WpI0c+bMmMfXrFmjxYsXS5L++Mc/KiMjQ/Pnz1dfX58qKyv16quvJmRYAED68BQg59wl9xk5cqTq6+tVX18f91BAKikpKbEeAUhJ3AsOAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJuL6jagA/udvf/ub5zUZGd7/36+/v9/zGmAo4woIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUiBy7R//37Paw4cOOB5TUlJiec148eP97xGkr788su41gFecAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjwOeec9RDfFolEFAgErMcAkmrx4sWe17z++uue1zQ3N3teI0mPPvqo5zWff/55XK+F9BUOh5WdnX3B57kCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSwMDFbtB4Ie+9957nNeXl5Z7XSNL777/vec0DDzzgeU1vb6/nNUgd3IwUADAkESAAgAlPAaqrq9Mtt9yirKws5efna+7cuWptbY3ZZ+bMmfL5fDHbww8/nNChAQCpz1OAmpubVV1drZ07d2rbtm06c+aMKioqzvs67kMPPaQjR45Et1WrViV0aABA6hvuZectW7bEfNzQ0KD8/Hzt2bNHM2bMiD5+1VVXKRgMJmZCAEBauqzvAYXDYUlSbm5uzONvv/228vLyNGnSJNXW1urkyZMX/Bx9fX2KRCIxGwAg/Xm6Avq2/v5+LV++XLfeeqsmTZoUffzee+/VuHHjFAqFtG/fPj355JNqbW294Ns66+rq9Nxzz8U7BgAgRcUdoOrqau3fv18ff/xxzONLliyJ/nny5MkqLCzUrFmz1N7ervHjx5/3eWpra1VTUxP9OBKJqKioKN6xAAApIq4ALVu2TJs3b9aOHTs0ZsyYi+5bWloqSWpraxswQH6/X36/P54xAAApzFOAnHN69NFHtWHDBjU1Nam4uPiSa/bu3StJKiwsjGtAAEB68hSg6upqrV27Vps2bVJWVpa6urokSYFAQKNGjVJ7e7vWrl2rn//857r22mu1b98+PfbYY5oxY4amTJmSlL8AACA1eQrQ6tWrJZ37YdNvW7NmjRYvXqzMzExt375dL7/8snp7e1VUVKT58+fr6aefTtjAAID04PlLcBdTVFSk5ubmyxoIAHBl4G7YQIqI5w7av/vd7+J6raVLl3peE8+X2T///HPPa5A6uBs2AGBIIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSAEBScDNSAMCQRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMSQC9AQuzUdACBOl/r3fMgF6Pjx49YjAAAS4FL/ng+5u2H39/ers7NTWVlZ8vl8Mc9FIhEVFRXp0KFDF73DarrjOJzDcTiH43AOx+GcoXAcnHM6fvy4QqGQMjIufJ0zfBBn+l4yMjI0ZsyYi+6TnZ19RZ9g3+A4nMNxOIfjcA7H4Rzr4/B9fq3OkPsSHADgykCAAAAmUipAfr9fK1eulN/vtx7FFMfhHI7DORyHczgO56TScRhyb0IAAFwZUuoKCACQPggQAMAEAQIAmCBAAAATKROg+vp6XXfddRo5cqRKS0v1ySefWI806J599ln5fL6YbeLEidZjJd2OHTt01113KRQKyefzaePGjTHPO+e0YsUKFRYWatSoUSovL9eBAwdshk2iSx2HxYsXn3d+zJ4922bYJKmrq9Mtt9yirKws5efna+7cuWptbY3Z59SpU6qurta1116ra665RvPnz1d3d7fRxMnxfY7DzJkzzzsfHn74YaOJB5YSAXr33XdVU1OjlStX6tNPP9XUqVNVWVmpo0ePWo826G666SYdOXIkun388cfWIyVdb2+vpk6dqvr6+gGfX7VqlV555RW99tpr2rVrl66++mpVVlbq1KlTgzxpcl3qOEjS7NmzY86Pd955ZxAnTL7m5mZVV1dr586d2rZtm86cOaOKigr19vZG93nsscf0wQcfaP369WpublZnZ6fmzZtnOHXifZ/jIEkPPfRQzPmwatUqo4kvwKWA6dOnu+rq6ujHZ8+edaFQyNXV1RlONfhWrlzppk6daj2GKUluw4YN0Y/7+/tdMBh0L774YvSxnp4e5/f73TvvvGMw4eD47nFwzrlFixa5OXPmmMxj5ejRo06Sa25uds6d+28/YsQIt379+ug+X3zxhZPkWlparMZMuu8eB+ecu+OOO9yvfvUru6G+hyF/BXT69Gnt2bNH5eXl0ccyMjJUXl6ulpYWw8lsHDhwQKFQSCUlJbrvvvt08OBB65FMdXR0qKurK+b8CAQCKi0tvSLPj6amJuXn5+vGG2/U0qVLdezYMeuRkiocDkuScnNzJUl79uzRmTNnYs6HiRMnauzYsWl9Pnz3OHzj7bffVl5eniZNmqTa2lqdPHnSYrwLGnI3I/2ur776SmfPnlVBQUHM4wUFBfrnP/9pNJWN0tJSNTQ06MYbb9SRI0f03HPP6fbbb9f+/fuVlZVlPZ6Jrq4uSRrw/PjmuSvF7NmzNW/ePBUXF6u9vV1PPfWUqqqq1NLSomHDhlmPl3D9/f1avny5br31Vk2aNEnSufMhMzNTOTk5Mfum8/kw0HGQpHvvvVfjxo1TKBTSvn379OSTT6q1tVXvv/++4bSxhnyA8D9VVVXRP0+ZMkWlpaUaN26c3nvvPT344IOGk2EoWLhwYfTPkydP1pQpUzR+/Hg1NTVp1qxZhpMlR3V1tfbv339FfB/0Yi50HJYsWRL98+TJk1VYWKhZs2apvb1d48ePH+wxBzTkvwSXl5enYcOGnfculu7ubgWDQaOphoacnBzdcMMNamtrsx7FzDfnAOfH+UpKSpSXl5eW58eyZcu0efNmffTRRzG/viUYDOr06dPq6emJ2T9dz4cLHYeBlJaWStKQOh+GfIAyMzM1bdo0NTY2Rh/r7+9XY2OjysrKDCezd+LECbW3t6uwsNB6FDPFxcUKBoMx50ckEtGuXbuu+PPj8OHDOnbsWFqdH845LVu2TBs2bNCHH36o4uLimOenTZumESNGxJwPra2tOnjwYFqdD5c6DgPZu3evJA2t88H6XRDfx7p165zf73cNDQ3u888/d0uWLHE5OTmuq6vLerRB9etf/9o1NTW5jo4O9/e//92Vl5e7vLw8d/ToUevRkur48ePus88+c5999pmT5F566SX32Wefuf/85z/OOed+//vfu5ycHLdp0ya3b98+N2fOHFdcXOy+/vpr48kT62LH4fjx4+7xxx93LS0trqOjw23fvt395Cc/cRMmTHCnTp2yHj1hli5d6gKBgGtqanJHjhyJbidPnozu8/DDD7uxY8e6Dz/80O3evduVlZW5srIyw6kT71LHoa2tzf32t791u3fvdh0dHW7Tpk2upKTEzZgxw3jyWCkRIOec+9Of/uTGjh3rMjMz3fTp093OnTutRxp0CxYscIWFhS4zM9P98Ic/dAsWLHBtbW3WYyXdRx995CSdty1atMg5d+6t2M8884wrKChwfr/fzZo1y7W2ttoOnQQXOw4nT550FRUVbvTo0W7EiBFu3Lhx7qGHHkq7/0kb6O8vya1Zsya6z9dff+0eeeQR94Mf/MBdddVV7u6773ZHjhyxGzoJLnUcDh486GbMmOFyc3Od3+93119/vfvNb37jwuGw7eDfwa9jAACYGPLfAwIApCcCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMT/AwPovkDcMDBVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = next(iter(train_loader))[0][4].view(28, 28)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([664.,   6.,   9.,   8.,   6.,   8.,   5.,   9.,   8.,  61.]),\n",
       " array([0.        , 0.1       , 0.2       , 0.30000001, 0.40000001,\n",
       "        0.5       , 0.60000002, 0.69999999, 0.80000001, 0.89999998,\n",
       "        1.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(image.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3)) # one color input, 32 output channels\n",
    "        self.conv2 = nn.Conv2d(32, 32, (3,3))\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.bnorm = nn.BatchNorm2d(num_features=32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 800 -> 128 \n",
    "        # output = (input - filter +1) / stride\n",
    "        # conv1 = (28 - 3 + 1) / 1 = 26 -> 28 is the input size, 3 is the filter size, 1 is the stride\n",
    "        # pool1 = (26 - 2 + 1) / 2 = 13 -> 26 is the input size, 2 is the filter size, 1 is the stride\n",
    "        # conv2 = (13 - 3 + 1) / 1 = 11 -> 13 is the input size, 3 is the filter size, 1 is the stride\n",
    "        # pool2 = (11 - 2 + 1) / 2 = 5 -> 11 is the input size, 2 is the filter size, 1 is the stride\n",
    "        # the image is now 5x5\n",
    "        # 5 * 5 * 32 = 800 -> 32 is the number of output channels\n",
    "\n",
    "        self.linear1 = nn.Linear(in_features=32*5*5, out_features=128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, 10) # we have 10 classes\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(self.bnorm(self.activation(self.conv1(X))))\n",
    "        X = self.pool(self.bnorm(self.activation(self.conv2(X))))\n",
    "        X = self.flatten(X)\n",
    "\n",
    "        X = self.dropout(self.activation(self.linear1(X)))\n",
    "        X = self.dropout(self.activation(self.linear2(X)))\n",
    "        X = self.output(X)\n",
    "\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = classifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (activation): ReLU()\n",
       "  (bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=800, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(loader, epoch):\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        ps = F.softmax(outputs)\n",
    "        top_p, top_class = ps.topk(k = 1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "        accuracy = torch.mean(equals.type(torch.float))\n",
    "\n",
    "\n",
    "        running_accuracy += accuracy\n",
    "\n",
    "        print(f'Epoch: {epoch}, Batch: {i}, Loss: {loss}, Accuracy: {accuracy}')\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Loss: {running_loss/len(loader)}, Accuracy: {running_accuracy/len(loader)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 0, Batch: 0, Loss: 0.024465838447213173, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 1, Loss: 0.09872777760028839, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 2, Loss: 0.05060483515262604, Accuracy: 0.9921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7167/3157752744.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ps = F.softmax(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 3, Loss: 0.09324637055397034, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 4, Loss: 0.031524501740932465, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 5, Loss: 0.04231029376387596, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 6, Loss: 0.04860639572143555, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 7, Loss: 0.05050100013613701, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 8, Loss: 0.0414893664419651, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 9, Loss: 0.02588081732392311, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 10, Loss: 0.0416053831577301, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 11, Loss: 0.014964098110795021, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 12, Loss: 0.023985901847481728, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 13, Loss: 0.007028053980320692, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 14, Loss: 0.04720953106880188, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 15, Loss: 0.07336022704839706, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 16, Loss: 0.005908803083002567, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 17, Loss: 0.01243351586163044, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 18, Loss: 0.11719002574682236, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 19, Loss: 0.005801476072520018, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 20, Loss: 0.04068135470151901, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 21, Loss: 0.11563453078269958, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 22, Loss: 0.027260323986411095, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 23, Loss: 0.005590047221630812, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 24, Loss: 0.01877496764063835, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 25, Loss: 0.02046061120927334, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 26, Loss: 0.037614855915308, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 27, Loss: 0.03449952229857445, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 28, Loss: 0.06244358792901039, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 29, Loss: 0.07367630302906036, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 30, Loss: 0.020214978605508804, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 31, Loss: 0.05249393358826637, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 32, Loss: 0.019092073664069176, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 33, Loss: 0.05306310951709747, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 34, Loss: 0.06820884346961975, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 35, Loss: 0.010522103868424892, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 36, Loss: 0.039416126906871796, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 37, Loss: 0.012488419190049171, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 38, Loss: 0.026516800746321678, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 39, Loss: 0.018940052017569542, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 40, Loss: 0.014663984067738056, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 41, Loss: 0.08654820173978806, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 42, Loss: 0.012327282689511776, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 43, Loss: 0.012946040369570255, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 44, Loss: 0.05471156910061836, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 45, Loss: 0.0300529096275568, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 46, Loss: 0.03302530199289322, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 47, Loss: 0.07012147456407547, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 48, Loss: 0.058742981404066086, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 49, Loss: 0.028120078146457672, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 50, Loss: 0.08540821075439453, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 51, Loss: 0.016222821548581123, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 52, Loss: 0.04029862955212593, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 53, Loss: 0.03867276757955551, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 54, Loss: 0.07326960563659668, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 55, Loss: 0.07939262688159943, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 56, Loss: 0.08054723590612411, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 57, Loss: 0.048069655895233154, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 58, Loss: 0.07088282704353333, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 59, Loss: 0.034672465175390244, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 60, Loss: 0.04803965613245964, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 61, Loss: 0.057153236120939255, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 62, Loss: 0.02392342872917652, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 63, Loss: 0.03150726109743118, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 64, Loss: 0.07686315476894379, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 65, Loss: 0.017479682341217995, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 66, Loss: 0.04262692853808403, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 67, Loss: 0.02191426232457161, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 68, Loss: 0.089278444647789, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 69, Loss: 0.025669770315289497, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 70, Loss: 0.04979832470417023, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 71, Loss: 0.012025010772049427, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 72, Loss: 0.02263648435473442, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 73, Loss: 0.07525348663330078, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 74, Loss: 0.05496586114168167, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 75, Loss: 0.03249958157539368, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 76, Loss: 0.01577039808034897, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 77, Loss: 0.021628661081194878, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 78, Loss: 0.02466576173901558, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 79, Loss: 0.03674763813614845, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 80, Loss: 0.07672610878944397, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 81, Loss: 0.009391319938004017, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 82, Loss: 0.0055840471759438515, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 83, Loss: 0.010345769114792347, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 84, Loss: 0.025093473494052887, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 85, Loss: 0.1646760255098343, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 86, Loss: 0.014909771271049976, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 87, Loss: 0.04161568358540535, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 88, Loss: 0.026163926348090172, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 89, Loss: 0.011947162449359894, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 90, Loss: 0.035720862448215485, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 91, Loss: 0.05408037453889847, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 92, Loss: 0.07043622434139252, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 93, Loss: 0.04727434739470482, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 94, Loss: 0.01762457564473152, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 95, Loss: 0.056874021887779236, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 96, Loss: 0.025134257972240448, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 97, Loss: 0.015033174306154251, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 98, Loss: 0.05427117273211479, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 99, Loss: 0.05642901360988617, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 100, Loss: 0.05936192348599434, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 101, Loss: 0.015398201532661915, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 102, Loss: 0.06449013203382492, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 103, Loss: 0.009148144163191319, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 104, Loss: 0.012809614650905132, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 105, Loss: 0.05795513466000557, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 106, Loss: 0.02890346199274063, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 107, Loss: 0.013743788935244083, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 108, Loss: 0.03497454896569252, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 109, Loss: 0.04208684712648392, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 110, Loss: 0.01763864792883396, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 111, Loss: 0.05031255632638931, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 112, Loss: 0.013590006157755852, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 113, Loss: 0.04062291607260704, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 114, Loss: 0.048903461545705795, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 115, Loss: 0.04833747446537018, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 116, Loss: 0.014724801294505596, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 117, Loss: 0.04313527047634125, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 118, Loss: 0.028144221752882004, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 119, Loss: 0.024738162755966187, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 120, Loss: 0.1346566528081894, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 121, Loss: 0.008893761783838272, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 122, Loss: 0.004938484635204077, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 123, Loss: 0.029263770207762718, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 124, Loss: 0.02865334041416645, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 125, Loss: 0.008663995191454887, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 126, Loss: 0.04445018991827965, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 127, Loss: 0.040224067866802216, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 128, Loss: 0.002954173367470503, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 129, Loss: 0.019481483846902847, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 130, Loss: 0.07179530709981918, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 131, Loss: 0.004064909648150206, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 132, Loss: 0.007548301015049219, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 133, Loss: 0.019232943654060364, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 134, Loss: 0.022480618208646774, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 135, Loss: 0.004297035746276379, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 136, Loss: 0.0098299914970994, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 137, Loss: 0.12385229766368866, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 138, Loss: 0.04964465647935867, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 139, Loss: 0.029964236542582512, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 140, Loss: 0.08941547572612762, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 141, Loss: 0.014589684084057808, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 142, Loss: 0.021833715960383415, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 143, Loss: 0.09341371059417725, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 144, Loss: 0.03061094507575035, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 145, Loss: 0.005169279407709837, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 146, Loss: 0.004614119417965412, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 147, Loss: 0.004044686444103718, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 148, Loss: 0.005970865022391081, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 149, Loss: 0.02962016500532627, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 150, Loss: 0.023088593035936356, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 151, Loss: 0.02480693906545639, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 152, Loss: 0.016259338706731796, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 153, Loss: 0.008217943832278252, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 154, Loss: 0.003805929096415639, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 155, Loss: 0.014427758753299713, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 156, Loss: 0.017614319920539856, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 157, Loss: 0.07237126678228378, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 158, Loss: 0.027135318145155907, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 159, Loss: 0.008365355432033539, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 160, Loss: 0.0023788604885339737, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 161, Loss: 0.07929772883653641, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 162, Loss: 0.02252190373837948, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 163, Loss: 0.04865565896034241, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 164, Loss: 0.0029281754978001118, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 165, Loss: 0.013876333832740784, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 166, Loss: 0.01662743277847767, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 167, Loss: 0.029985476285219193, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 168, Loss: 0.02486528269946575, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 169, Loss: 0.015383759513497353, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 170, Loss: 0.014174116775393486, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 171, Loss: 0.05637791380286217, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 172, Loss: 0.0031428991351276636, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 173, Loss: 0.05108068510890007, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 174, Loss: 0.014179914258420467, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 175, Loss: 0.01916179433465004, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 176, Loss: 0.04441631957888603, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 177, Loss: 0.07292427867650986, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 178, Loss: 0.0025836252607405186, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 179, Loss: 0.03096938692033291, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 180, Loss: 0.061817411333322525, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 181, Loss: 0.003131716512143612, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 182, Loss: 0.006959708407521248, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 183, Loss: 0.004296035505831242, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 184, Loss: 0.03968082740902901, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 185, Loss: 0.05482463166117668, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 186, Loss: 0.08062576502561569, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 187, Loss: 0.04969659820199013, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 188, Loss: 0.01481986790895462, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 189, Loss: 0.004332083743065596, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 190, Loss: 0.006461941171437502, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 191, Loss: 0.013755835592746735, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 192, Loss: 0.05285334959626198, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 193, Loss: 0.08631417900323868, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 194, Loss: 0.030231602489948273, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 195, Loss: 0.0007402472547255456, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 196, Loss: 0.05916692316532135, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 197, Loss: 0.058248259127140045, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 198, Loss: 0.0014667755458503962, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 199, Loss: 0.06016705930233002, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 200, Loss: 0.05958498641848564, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 201, Loss: 0.09146777540445328, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 202, Loss: 0.05379750579595566, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 203, Loss: 0.023963935673236847, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 204, Loss: 0.015431367792189121, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 205, Loss: 0.006007214542478323, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 206, Loss: 0.07790275663137436, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 207, Loss: 0.1772010773420334, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 208, Loss: 0.08840247988700867, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 209, Loss: 0.029945239424705505, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 210, Loss: 0.009316853247582912, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 211, Loss: 0.05248430371284485, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 212, Loss: 0.04728446155786514, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 213, Loss: 0.01061087753623724, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 214, Loss: 0.03586484491825104, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 215, Loss: 0.038758784532547, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 216, Loss: 0.010456615127623081, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 217, Loss: 0.019664766266942024, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 218, Loss: 0.017645597457885742, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 219, Loss: 0.006408714223653078, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 220, Loss: 0.06436280161142349, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 221, Loss: 0.032926883548498154, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 222, Loss: 0.010985119268298149, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 223, Loss: 0.036408502608537674, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 224, Loss: 0.04282127693295479, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 225, Loss: 0.00510926079005003, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 226, Loss: 0.015778211876749992, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 227, Loss: 0.013457958586513996, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 228, Loss: 0.040329303592443466, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 229, Loss: 0.03274506703019142, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 230, Loss: 0.015415922738611698, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 231, Loss: 0.02455536648631096, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 232, Loss: 0.01631045527756214, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 233, Loss: 0.012056850828230381, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 234, Loss: 0.08621776849031448, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 235, Loss: 0.016373207792639732, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 236, Loss: 0.009582992643117905, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 237, Loss: 0.017936784774065018, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 238, Loss: 0.01067944336682558, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 239, Loss: 0.03951233997941017, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 240, Loss: 0.02291066013276577, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 241, Loss: 0.01624244451522827, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 242, Loss: 0.05024706944823265, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 243, Loss: 0.005581690464168787, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 244, Loss: 0.026845281943678856, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 245, Loss: 0.015515225939452648, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 246, Loss: 0.011888841167092323, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 247, Loss: 0.030658138915896416, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 248, Loss: 0.03259596601128578, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 249, Loss: 0.007545320317149162, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 250, Loss: 0.02674778923392296, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 251, Loss: 0.009064317680895329, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 252, Loss: 0.08503598719835281, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 253, Loss: 0.1084037721157074, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 254, Loss: 0.05596967414021492, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 255, Loss: 0.064540334045887, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 256, Loss: 0.044574785977602005, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 257, Loss: 0.008195357397198677, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 258, Loss: 0.00517918448895216, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 259, Loss: 0.035631220787763596, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 260, Loss: 0.02220200002193451, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 261, Loss: 0.05659738555550575, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 262, Loss: 0.0347980260848999, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 263, Loss: 0.03970520198345184, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 264, Loss: 0.01189897395670414, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 265, Loss: 0.007355735171586275, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 266, Loss: 0.026988081634044647, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 267, Loss: 0.0009480078588239849, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 268, Loss: 0.051110800355672836, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 269, Loss: 0.01612481102347374, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 270, Loss: 0.052786026149988174, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 271, Loss: 0.08805468678474426, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 272, Loss: 0.07006500661373138, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 273, Loss: 0.010506803169846535, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 274, Loss: 0.001845936058089137, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 275, Loss: 0.05664951354265213, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 276, Loss: 0.0173944178968668, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 277, Loss: 0.06682755798101425, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 278, Loss: 0.1291167438030243, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 279, Loss: 0.014775225892663002, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 280, Loss: 0.061214346438646317, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 281, Loss: 0.03262338414788246, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 282, Loss: 0.02647254802286625, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 283, Loss: 0.01719406247138977, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 284, Loss: 0.0777144730091095, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 285, Loss: 0.027458904311060905, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 286, Loss: 0.07356271147727966, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 287, Loss: 0.04408498853445053, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 288, Loss: 0.012151104398071766, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 289, Loss: 0.07231635600328445, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 290, Loss: 0.010430270805954933, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 291, Loss: 0.025324776768684387, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 292, Loss: 0.10702381283044815, Accuracy: 0.9453125\n",
      "Epoch: 0, Batch: 293, Loss: 0.04652918875217438, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 294, Loss: 0.0844779759645462, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 295, Loss: 0.04127777740359306, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 296, Loss: 0.014588546007871628, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 297, Loss: 0.019859327003359795, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 298, Loss: 0.006762473378330469, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 299, Loss: 0.0857146680355072, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 300, Loss: 0.04909967631101608, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 301, Loss: 0.01603679172694683, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 302, Loss: 0.03245742991566658, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 303, Loss: 0.02097843773663044, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 304, Loss: 0.028916802257299423, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 305, Loss: 0.002791887614876032, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 306, Loss: 0.06322164088487625, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 307, Loss: 0.1494467854499817, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 308, Loss: 0.008274178020656109, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 309, Loss: 0.03170786425471306, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 310, Loss: 0.03213630989193916, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 311, Loss: 0.01250308845192194, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 312, Loss: 0.011646085418760777, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 313, Loss: 0.0314055010676384, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 314, Loss: 0.010966829024255276, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 315, Loss: 0.10976957529783249, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 316, Loss: 0.019807886332273483, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 317, Loss: 0.02223656140267849, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 318, Loss: 0.005269852001219988, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 319, Loss: 0.06155284121632576, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 320, Loss: 0.049112819135189056, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 321, Loss: 0.031235039234161377, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 322, Loss: 0.10134527832269669, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 323, Loss: 0.1440572738647461, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 324, Loss: 0.038350660353899, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 325, Loss: 0.015514982864260674, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 326, Loss: 0.006799350492656231, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 327, Loss: 0.0059955185279250145, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 328, Loss: 0.011762130074203014, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 329, Loss: 0.031833864748477936, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 330, Loss: 0.012764237821102142, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 331, Loss: 0.02081197313964367, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 332, Loss: 0.01869557611644268, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 333, Loss: 0.03825456649065018, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 334, Loss: 0.0956057533621788, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 335, Loss: 0.03160887584090233, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 336, Loss: 0.0629710778594017, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 337, Loss: 0.011994309723377228, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 338, Loss: 0.004101952537894249, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 339, Loss: 0.13352960348129272, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 340, Loss: 0.03777914494276047, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 341, Loss: 0.02198525331914425, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 342, Loss: 0.010492885485291481, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 343, Loss: 0.012909536249935627, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 344, Loss: 0.017567655071616173, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 345, Loss: 0.03310592472553253, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 346, Loss: 0.00402506859973073, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 347, Loss: 0.07932282984256744, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 348, Loss: 0.0054540992714464664, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 349, Loss: 0.0061213294975459576, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 350, Loss: 0.02406311221420765, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 351, Loss: 0.029697544872760773, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 352, Loss: 0.03249991685152054, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 353, Loss: 0.05786275491118431, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 354, Loss: 0.061026398092508316, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 355, Loss: 0.03134731203317642, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 356, Loss: 0.02013121172785759, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 357, Loss: 0.0225690770894289, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 358, Loss: 0.053482986986637115, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 359, Loss: 0.0667574554681778, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 360, Loss: 0.04842909425497055, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 361, Loss: 0.030128099024295807, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 362, Loss: 0.07251444458961487, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 363, Loss: 0.009941770695149899, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 364, Loss: 0.021303212270140648, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 365, Loss: 0.039798103272914886, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 366, Loss: 0.03600938618183136, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 367, Loss: 0.04384754225611687, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 368, Loss: 0.0331859327852726, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 369, Loss: 0.09491026401519775, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 370, Loss: 0.035296712070703506, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 371, Loss: 0.048236921429634094, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 372, Loss: 0.06352562457323074, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 373, Loss: 0.012391863390803337, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 374, Loss: 0.013868491165339947, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 375, Loss: 0.024259502068161964, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 376, Loss: 0.0029398049227893353, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 377, Loss: 0.021361665800213814, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 378, Loss: 0.013258724473416805, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 379, Loss: 0.004220770671963692, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 380, Loss: 0.012910888530313969, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 381, Loss: 0.01969679445028305, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 382, Loss: 0.05860283225774765, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 383, Loss: 0.05417027696967125, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 384, Loss: 0.0562632791697979, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 385, Loss: 0.03934711217880249, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 386, Loss: 0.008702359162271023, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 387, Loss: 0.054198186844587326, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 388, Loss: 0.00727037200704217, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 389, Loss: 0.033618178218603134, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 390, Loss: 0.011654318310320377, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 391, Loss: 0.02827604115009308, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 392, Loss: 0.030301308259367943, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 393, Loss: 0.10755907744169235, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 394, Loss: 0.018958639353513718, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 395, Loss: 0.004069590475410223, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 396, Loss: 0.020765533670783043, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 397, Loss: 0.03628180921077728, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 398, Loss: 0.01584526151418686, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 399, Loss: 0.00131220871116966, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 400, Loss: 0.09677750617265701, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 401, Loss: 0.07794799655675888, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 402, Loss: 0.00680901063606143, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 403, Loss: 0.00342551083303988, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 404, Loss: 0.010031582787632942, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 405, Loss: 0.06988787651062012, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 406, Loss: 0.030692046508193016, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 407, Loss: 0.04540100693702698, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 408, Loss: 0.04118772968649864, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 409, Loss: 0.01215205155313015, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 410, Loss: 0.017900407314300537, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 411, Loss: 0.013797758147120476, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 412, Loss: 0.03298386558890343, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 413, Loss: 0.11386625468730927, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 414, Loss: 0.04202950745820999, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 415, Loss: 0.02631099708378315, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 416, Loss: 0.0009407703182660043, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 417, Loss: 0.07783284783363342, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 418, Loss: 0.005542197730392218, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 419, Loss: 0.054915621876716614, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 420, Loss: 0.03828705474734306, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 421, Loss: 0.0702362135052681, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 422, Loss: 0.05401505529880524, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 423, Loss: 0.03465140238404274, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 424, Loss: 0.020068230107426643, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 425, Loss: 0.02838326245546341, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 426, Loss: 0.01228566374629736, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 427, Loss: 0.006110682617872953, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 428, Loss: 0.03335832431912422, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 429, Loss: 0.014141906052827835, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 430, Loss: 0.003022311720997095, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 431, Loss: 0.027790792286396027, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 432, Loss: 0.02519512176513672, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 433, Loss: 0.015452450141310692, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 434, Loss: 0.02795831672847271, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 435, Loss: 0.017655011266469955, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 436, Loss: 0.012539935298264027, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 437, Loss: 0.046538591384887695, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 438, Loss: 0.015325735323131084, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 439, Loss: 0.008798431605100632, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 440, Loss: 0.011891908943653107, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 441, Loss: 0.027060499414801598, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 442, Loss: 0.09096509218215942, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 443, Loss: 0.026293648406863213, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 444, Loss: 0.02104836143553257, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 445, Loss: 0.0452815443277359, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 446, Loss: 0.0013033138820901513, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 447, Loss: 0.06756678968667984, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 448, Loss: 0.00707087479531765, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 449, Loss: 0.00569831533357501, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 450, Loss: 0.02730328030884266, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 451, Loss: 0.07594918459653854, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 452, Loss: 0.012922719120979309, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 453, Loss: 0.02285991981625557, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 454, Loss: 0.021605242043733597, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 455, Loss: 0.0029470587614923716, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 456, Loss: 0.007786674425005913, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 457, Loss: 0.0034327851608395576, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 458, Loss: 0.003736816579475999, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 459, Loss: 0.008778260089457035, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 460, Loss: 0.0013371935347095132, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 461, Loss: 0.00021456569083966315, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 462, Loss: 0.00041789107490330935, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 463, Loss: 0.013487973250448704, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 464, Loss: 0.013775581493973732, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 465, Loss: 0.004308817908167839, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 466, Loss: 0.2988119423389435, Accuracy: 0.9453125\n",
      "Epoch: 0, Batch: 467, Loss: 0.00604211026802659, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 468, Loss: 0.12552668154239655, Accuracy: 0.9895833730697632\n",
      "Epoch: 0, Loss: 0.03577967357382661, Accuracy: 0.9895500540733337\n",
      "Testing\n",
      "Epoch: 0, Batch: 0, Loss: 1.1710176467895508, Accuracy: 0.5703125\n",
      "Epoch: 0, Batch: 1, Loss: 0.5654526352882385, Accuracy: 0.9140625\n",
      "Epoch: 0, Batch: 2, Loss: 0.6467418670654297, Accuracy: 0.8046875\n",
      "Epoch: 0, Batch: 3, Loss: 0.49324700236320496, Accuracy: 0.8359375\n",
      "Epoch: 0, Batch: 4, Loss: 0.23287297785282135, Accuracy: 0.9453125\n",
      "Epoch: 0, Batch: 5, Loss: 0.21984528005123138, Accuracy: 0.9453125\n",
      "Epoch: 0, Batch: 6, Loss: 0.1539161652326584, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 7, Loss: 0.19141776859760284, Accuracy: 0.953125\n",
      "Epoch: 0, Batch: 8, Loss: 0.15784570574760437, Accuracy: 0.953125\n",
      "Epoch: 0, Batch: 9, Loss: 0.16377785801887512, Accuracy: 0.9375\n",
      "Epoch: 0, Batch: 10, Loss: 0.15294873714447021, Accuracy: 0.953125\n",
      "Epoch: 0, Batch: 11, Loss: 0.08864334225654602, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 12, Loss: 0.11836309731006622, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 13, Loss: 0.14711491763591766, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 14, Loss: 0.12162069231271744, Accuracy: 0.953125\n",
      "Epoch: 0, Batch: 15, Loss: 0.15794505178928375, Accuracy: 0.9453125\n",
      "Epoch: 0, Batch: 16, Loss: 0.14808769524097443, Accuracy: 0.9375\n",
      "Epoch: 0, Batch: 17, Loss: 0.10429804772138596, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 18, Loss: 0.09870018064975739, Accuracy: 0.9453125\n",
      "Epoch: 0, Batch: 19, Loss: 0.041446488350629807, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 20, Loss: 0.09693662077188492, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 21, Loss: 0.04610355570912361, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 22, Loss: 0.09762793779373169, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 23, Loss: 0.13649162650108337, Accuracy: 0.9609375\n",
      "Epoch: 0, Batch: 24, Loss: 0.05999777838587761, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 25, Loss: 0.030074141919612885, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 26, Loss: 0.06529197096824646, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 27, Loss: 0.14184387028217316, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 28, Loss: 0.04222814738750458, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 29, Loss: 0.17219334840774536, Accuracy: 0.9375\n",
      "Epoch: 0, Batch: 30, Loss: 0.056846506893634796, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 31, Loss: 0.07322204113006592, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 32, Loss: 0.03747733682394028, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 33, Loss: 0.09885908663272858, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 34, Loss: 0.06051669269800186, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 35, Loss: 0.06828170269727707, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 36, Loss: 0.044960543513298035, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 37, Loss: 0.08232173323631287, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 38, Loss: 0.0301551204174757, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 39, Loss: 0.008862391114234924, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 40, Loss: 0.021432267501950264, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 41, Loss: 0.021116482093930244, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 42, Loss: 0.003084033727645874, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 43, Loss: 0.01886082999408245, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 44, Loss: 0.03189101070165634, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 45, Loss: 0.028183886781334877, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 46, Loss: 0.11687842011451721, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 47, Loss: 0.04193582385778427, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 48, Loss: 0.008294671773910522, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 49, Loss: 0.001774619217030704, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 50, Loss: 0.03175130859017372, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 51, Loss: 0.18871979415416718, Accuracy: 0.9375\n",
      "Epoch: 0, Batch: 52, Loss: 0.030691565945744514, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 53, Loss: 0.002735493239015341, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 54, Loss: 0.0023412189912050962, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 55, Loss: 0.04415716975927353, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 56, Loss: 0.009522013366222382, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 57, Loss: 0.02596989832818508, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 58, Loss: 0.0462610088288784, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 59, Loss: 0.01597512885928154, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 60, Loss: 0.008747641928493977, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 61, Loss: 0.03572780638933182, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 62, Loss: 0.039724674075841904, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 63, Loss: 0.05367523431777954, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 64, Loss: 0.012725683860480785, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 65, Loss: 0.061941906809806824, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 66, Loss: 0.006467888597398996, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 67, Loss: 0.0024519090075045824, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 68, Loss: 0.001571154105477035, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 69, Loss: 0.0030077730771154165, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 70, Loss: 0.0876939594745636, Accuracy: 0.9765625\n",
      "Epoch: 0, Batch: 71, Loss: 0.01142112072557211, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 72, Loss: 0.057571347802877426, Accuracy: 0.984375\n",
      "Epoch: 0, Batch: 73, Loss: 0.006937506143003702, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 74, Loss: 0.015402663499116898, Accuracy: 1.0\n",
      "Epoch: 0, Batch: 75, Loss: 0.11388497054576874, Accuracy: 0.96875\n",
      "Epoch: 0, Batch: 76, Loss: 0.1728409379720688, Accuracy: 0.953125\n",
      "Epoch: 0, Batch: 77, Loss: 0.06251123547554016, Accuracy: 0.9921875\n",
      "Epoch: 0, Batch: 78, Loss: 0.0002010861353483051, Accuracy: 1.0\n",
      "Epoch: 0, Loss: 0.10217314501863291, Accuracy: 0.9694422483444214\n",
      "Epoch: 1\n",
      "Epoch: 1, Batch: 0, Loss: 0.09097665548324585, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 1, Loss: 0.08387582004070282, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 2, Loss: 0.027455700561404228, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 3, Loss: 0.15129400789737701, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 4, Loss: 0.07492465525865555, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 5, Loss: 0.005392575170844793, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 6, Loss: 0.13676634430885315, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 7, Loss: 0.20466341078281403, Accuracy: 0.953125\n",
      "Epoch: 1, Batch: 8, Loss: 0.12944450974464417, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 9, Loss: 0.10636603832244873, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 10, Loss: 0.0856991559267044, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 11, Loss: 0.049203164875507355, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 12, Loss: 0.05391388386487961, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 13, Loss: 0.010466345585882664, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 14, Loss: 0.07719569653272629, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 15, Loss: 0.14184878766536713, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 16, Loss: 0.0021658397745341063, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 17, Loss: 0.013293429277837276, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 18, Loss: 0.09257770329713821, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 19, Loss: 0.028569035232067108, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 20, Loss: 0.15605777502059937, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 21, Loss: 0.03334414213895798, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 22, Loss: 0.03897928074002266, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 23, Loss: 0.012774488888680935, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 24, Loss: 0.0020674460101872683, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 25, Loss: 0.010318497195839882, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 26, Loss: 0.028327947482466698, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 27, Loss: 0.08177851140499115, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 28, Loss: 0.06521749496459961, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 29, Loss: 0.05448633432388306, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 30, Loss: 0.009194007143378258, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 31, Loss: 0.05387711152434349, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 32, Loss: 0.028169095516204834, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 33, Loss: 0.028131656348705292, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 34, Loss: 0.10447189211845398, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 35, Loss: 0.03641244396567345, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 36, Loss: 0.022512013092637062, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 37, Loss: 0.020009398460388184, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 38, Loss: 0.06794615089893341, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 39, Loss: 0.09346333146095276, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 40, Loss: 0.024371622130274773, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 41, Loss: 0.03441152349114418, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 42, Loss: 0.01306081097573042, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 43, Loss: 0.10647270083427429, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 44, Loss: 0.11173789948225021, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 45, Loss: 0.06948622316122055, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 46, Loss: 0.020214535295963287, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 47, Loss: 0.1143377423286438, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 48, Loss: 0.03533988445997238, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 49, Loss: 0.03416768088936806, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 50, Loss: 0.01856129802763462, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 51, Loss: 0.0178067646920681, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 52, Loss: 0.05503489077091217, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 53, Loss: 0.04975025728344917, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 54, Loss: 0.13938789069652557, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 55, Loss: 0.07209723442792892, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 56, Loss: 0.11754083633422852, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 57, Loss: 0.011459681205451488, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 58, Loss: 0.06433258205652237, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 59, Loss: 0.020349282771348953, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 60, Loss: 0.022512169554829597, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 61, Loss: 0.02845354937016964, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 62, Loss: 0.03046237677335739, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 63, Loss: 0.13006755709648132, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 64, Loss: 0.06397181749343872, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 65, Loss: 0.029087292030453682, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 66, Loss: 0.032874006778001785, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 67, Loss: 0.0533459447324276, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 68, Loss: 0.10282628238201141, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 69, Loss: 0.048288505524396896, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 70, Loss: 0.00847560353577137, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 71, Loss: 0.017266802489757538, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 72, Loss: 0.021045193076133728, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 73, Loss: 0.03667449206113815, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 74, Loss: 0.016301119700074196, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 75, Loss: 0.025852445513010025, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 76, Loss: 0.022167706862092018, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 77, Loss: 0.005693164654076099, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 78, Loss: 0.051228977739810944, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 79, Loss: 0.055850155651569366, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 80, Loss: 0.08941579610109329, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 81, Loss: 0.05102548748254776, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 82, Loss: 0.0030863999854773283, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 83, Loss: 0.011789949610829353, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 84, Loss: 0.03875216841697693, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 85, Loss: 0.13662368059158325, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 86, Loss: 0.00787346065044403, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 87, Loss: 0.031737733632326126, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 88, Loss: 0.016806436702609062, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 89, Loss: 0.02624281868338585, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 90, Loss: 0.04736902564764023, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 91, Loss: 0.03669944778084755, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 92, Loss: 0.0482114776968956, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 93, Loss: 0.03481369838118553, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 94, Loss: 0.015093217603862286, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 95, Loss: 0.012909715063869953, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 96, Loss: 0.012957212515175343, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 97, Loss: 0.07560492306947708, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 98, Loss: 0.042310744524002075, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 99, Loss: 0.0022203277330845594, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 100, Loss: 0.04116020351648331, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 101, Loss: 0.0341339036822319, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 102, Loss: 0.05143943056464195, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 103, Loss: 0.008076871745288372, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 104, Loss: 0.007054002955555916, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 105, Loss: 0.024538051337003708, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 106, Loss: 0.004563856404274702, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 107, Loss: 0.012738595716655254, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 108, Loss: 0.010212091729044914, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 109, Loss: 0.052078939974308014, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 110, Loss: 0.015150493942201138, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 111, Loss: 0.022523539140820503, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 112, Loss: 0.06301073729991913, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 113, Loss: 0.04997975006699562, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 114, Loss: 0.04335903003811836, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 115, Loss: 0.053202562034130096, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 116, Loss: 0.010198465548455715, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 117, Loss: 0.017116928473114967, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 118, Loss: 0.04301175847649574, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 119, Loss: 0.006361729931086302, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 120, Loss: 0.048445191234350204, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 121, Loss: 0.05588586628437042, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 122, Loss: 0.005902701523154974, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 123, Loss: 0.10253295302391052, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 124, Loss: 0.04230282083153725, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 125, Loss: 0.02062753029167652, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 126, Loss: 0.04721900820732117, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 127, Loss: 0.016837114468216896, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 128, Loss: 0.013904763385653496, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 129, Loss: 0.017662793397903442, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 130, Loss: 0.06821072101593018, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 131, Loss: 0.005695134401321411, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 132, Loss: 0.036840420216321945, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 133, Loss: 0.07530725002288818, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 134, Loss: 0.0179423987865448, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 135, Loss: 0.011433826759457588, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 136, Loss: 0.010635600425302982, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 137, Loss: 0.04051582142710686, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 138, Loss: 0.030373631045222282, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 139, Loss: 0.050686128437519073, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 140, Loss: 0.034455347806215286, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 141, Loss: 0.03466487303376198, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 142, Loss: 0.005934967193752527, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 143, Loss: 0.08469513058662415, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 144, Loss: 0.006323542445898056, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 145, Loss: 0.012490062974393368, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 146, Loss: 0.003924841992557049, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 147, Loss: 0.006492013111710548, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 148, Loss: 0.0010600457899272442, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 149, Loss: 0.0641031414270401, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 150, Loss: 0.06398311257362366, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 151, Loss: 0.05075855180621147, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 152, Loss: 0.03199917450547218, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 153, Loss: 0.005256845150142908, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 154, Loss: 0.017563553526997566, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 155, Loss: 0.008092035539448261, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 156, Loss: 0.0036185127682983875, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 157, Loss: 0.03828762471675873, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 158, Loss: 0.04468850791454315, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 159, Loss: 0.0021568709053099155, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 160, Loss: 0.004056819714605808, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 161, Loss: 0.03917721286416054, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 162, Loss: 0.050187304615974426, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 163, Loss: 0.02545466087758541, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 164, Loss: 0.0065717934630811214, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 165, Loss: 0.028189390897750854, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 166, Loss: 0.015026150271296501, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 167, Loss: 0.04155290126800537, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 168, Loss: 0.06340347975492477, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 169, Loss: 0.017830466851592064, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 170, Loss: 0.03488445281982422, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 171, Loss: 0.02733384072780609, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 172, Loss: 0.03179748356342316, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 173, Loss: 0.05611662194132805, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 174, Loss: 0.013539238832890987, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 175, Loss: 0.06552520394325256, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 176, Loss: 0.032083120197057724, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 177, Loss: 0.05412941798567772, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 178, Loss: 0.0013025173684582114, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 179, Loss: 0.00691294576972723, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 180, Loss: 0.05137963593006134, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 181, Loss: 0.004140610806643963, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 182, Loss: 0.012267600744962692, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 183, Loss: 0.004715730901807547, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 184, Loss: 0.07668723165988922, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 185, Loss: 0.055024076253175735, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 186, Loss: 0.04943320155143738, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 187, Loss: 0.021696049720048904, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 188, Loss: 0.02086600475013256, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 189, Loss: 0.007025334984064102, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 190, Loss: 0.0040831598453223705, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 191, Loss: 0.016262458637356758, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 192, Loss: 0.058188002556562424, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 193, Loss: 0.023145243525505066, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 194, Loss: 0.003321633907034993, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 195, Loss: 0.001158926635980606, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 196, Loss: 0.009055995382368565, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 197, Loss: 0.025012006983160973, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 198, Loss: 0.0004542047390714288, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 199, Loss: 0.023299116641283035, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 200, Loss: 0.06424230337142944, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 201, Loss: 0.08000410348176956, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 202, Loss: 0.006410656962543726, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 203, Loss: 0.015611591748893261, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 204, Loss: 0.0074600777588784695, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 205, Loss: 0.04236282780766487, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 206, Loss: 0.06528983265161514, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 207, Loss: 0.14735054969787598, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 208, Loss: 0.0974944680929184, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 209, Loss: 0.005164068192243576, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 210, Loss: 0.024081459268927574, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 211, Loss: 0.005364551674574614, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 212, Loss: 0.034380946308374405, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 213, Loss: 0.007050766609609127, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 214, Loss: 0.017880087718367577, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 215, Loss: 0.06505376845598221, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 216, Loss: 0.02002858556807041, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 217, Loss: 0.015306011773645878, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 218, Loss: 0.02163459174335003, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 219, Loss: 0.014809895306825638, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 220, Loss: 0.01224561221897602, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 221, Loss: 0.04271503537893295, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 222, Loss: 0.010585417039692402, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 223, Loss: 0.03988783434033394, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 224, Loss: 0.08070021867752075, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 225, Loss: 0.02264089696109295, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 226, Loss: 0.025630421936511993, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 227, Loss: 0.0346498116850853, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 228, Loss: 0.012923899106681347, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 229, Loss: 0.0346965417265892, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 230, Loss: 0.002461417345330119, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 231, Loss: 0.005415632855147123, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 232, Loss: 0.06373301148414612, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 233, Loss: 0.011836482211947441, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 234, Loss: 0.036390867084264755, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 235, Loss: 0.010648103430867195, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 236, Loss: 0.010322797112166882, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 237, Loss: 0.005430710501968861, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 238, Loss: 0.018951496109366417, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 239, Loss: 0.015673888847231865, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 240, Loss: 0.026771429926156998, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 241, Loss: 0.06148587539792061, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 242, Loss: 0.006204670295119286, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 243, Loss: 0.012013333849608898, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 244, Loss: 0.03943808376789093, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 245, Loss: 0.052196573466062546, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 246, Loss: 0.08223822712898254, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 247, Loss: 0.0812755599617958, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 248, Loss: 0.05933375656604767, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 249, Loss: 0.006308846641331911, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 250, Loss: 0.01861315220594406, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 251, Loss: 0.0066925897262990475, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 252, Loss: 0.1327138990163803, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 253, Loss: 0.052274759858846664, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 254, Loss: 0.011160627007484436, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 255, Loss: 0.02395395003259182, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 256, Loss: 0.015852026641368866, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 257, Loss: 0.0027027775067836046, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 258, Loss: 0.00867884699255228, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 259, Loss: 0.02402978204190731, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 260, Loss: 0.06397813558578491, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 261, Loss: 0.04753733053803444, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 262, Loss: 0.0018351813778281212, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 263, Loss: 0.04788525402545929, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 264, Loss: 0.01890140026807785, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 265, Loss: 0.004485372453927994, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 266, Loss: 0.05550353601574898, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 267, Loss: 0.0015422353753820062, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 268, Loss: 0.021490950137376785, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 269, Loss: 0.04503711685538292, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 270, Loss: 0.053368594497442245, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 271, Loss: 0.06013033911585808, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 272, Loss: 0.07783418148756027, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 273, Loss: 0.005931817460805178, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 274, Loss: 0.015137525275349617, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 275, Loss: 0.08191230148077011, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 276, Loss: 0.0011814008466899395, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 277, Loss: 0.08006377518177032, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 278, Loss: 0.047151342034339905, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 279, Loss: 0.001464502653107047, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 280, Loss: 0.0077577377669513226, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 281, Loss: 0.026878252625465393, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 282, Loss: 0.054431743919849396, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 283, Loss: 0.012111223302781582, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 284, Loss: 0.11506865173578262, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 285, Loss: 0.005227582063525915, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 286, Loss: 0.11471772938966751, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 287, Loss: 0.05055929720401764, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 288, Loss: 0.0389007069170475, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 289, Loss: 0.05947881191968918, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 290, Loss: 0.008368559181690216, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 291, Loss: 0.007105979602783918, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 292, Loss: 0.022090885788202286, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 293, Loss: 0.03231581673026085, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 294, Loss: 0.058905426412820816, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 295, Loss: 0.030205249786376953, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 296, Loss: 0.007215237244963646, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 297, Loss: 0.01534302718937397, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 298, Loss: 0.019359568133950233, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 299, Loss: 0.08157604187726974, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 300, Loss: 0.03726156800985336, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 301, Loss: 0.04787685349583626, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 302, Loss: 0.02817610092461109, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 303, Loss: 0.005966644734144211, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 304, Loss: 0.015252737328410149, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 305, Loss: 0.004321771208196878, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 306, Loss: 0.06572631001472473, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 307, Loss: 0.16260358691215515, Accuracy: 0.9296875\n",
      "Epoch: 1, Batch: 308, Loss: 0.018628723919391632, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 309, Loss: 0.012759089469909668, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 310, Loss: 0.017765307798981667, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 311, Loss: 0.045437395572662354, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 312, Loss: 0.022002756595611572, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 313, Loss: 0.08736853301525116, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 314, Loss: 0.014001650735735893, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 315, Loss: 0.0106140011921525, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 316, Loss: 0.027033420279622078, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 317, Loss: 0.016838200390338898, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 318, Loss: 0.06802788376808167, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 319, Loss: 0.02188383787870407, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 320, Loss: 0.034516341984272, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 321, Loss: 0.06999312341213226, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 322, Loss: 0.06898581981658936, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 323, Loss: 0.048905886709690094, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 324, Loss: 0.07815694063901901, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 325, Loss: 0.012651619501411915, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 326, Loss: 0.0052788578905165195, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 327, Loss: 0.006846042349934578, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 328, Loss: 0.004852816928178072, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 329, Loss: 0.007241922430694103, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 330, Loss: 0.03465363383293152, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 331, Loss: 0.02643515355885029, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 332, Loss: 0.03148745000362396, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 333, Loss: 0.05051570013165474, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 334, Loss: 0.029847649857401848, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 335, Loss: 0.06016020476818085, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 336, Loss: 0.07612814009189606, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 337, Loss: 0.0187640730291605, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 338, Loss: 0.0025832047685980797, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 339, Loss: 0.15235723555088043, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 340, Loss: 0.006430806126445532, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 341, Loss: 0.018679222092032433, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 342, Loss: 0.006432076450437307, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 343, Loss: 0.01532921101897955, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 344, Loss: 0.00438771303743124, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 345, Loss: 0.019403476268053055, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 346, Loss: 0.02198430895805359, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 347, Loss: 0.025384658947587013, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 348, Loss: 0.0018871957436203957, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 349, Loss: 0.0013121033553034067, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 350, Loss: 0.011798650957643986, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 351, Loss: 0.018325990065932274, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 352, Loss: 0.057089850306510925, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 353, Loss: 0.011001159437000751, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 354, Loss: 0.023856371641159058, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 355, Loss: 0.004182180855423212, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 356, Loss: 0.01577765867114067, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 357, Loss: 0.02005729079246521, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 358, Loss: 0.08514142781496048, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 359, Loss: 0.0693569928407669, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 360, Loss: 0.01319808978587389, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 361, Loss: 0.021153563633561134, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 362, Loss: 0.041700467467308044, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 363, Loss: 0.015484300442039967, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 364, Loss: 0.015465730801224709, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 365, Loss: 0.027714915573596954, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 366, Loss: 0.01551273837685585, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 367, Loss: 0.06088995188474655, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 368, Loss: 0.02491978369653225, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 369, Loss: 0.08179236203432083, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 370, Loss: 0.06448023021221161, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 371, Loss: 0.009977682493627071, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 372, Loss: 0.014440280385315418, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 373, Loss: 0.013754724524915218, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 374, Loss: 0.003184169763699174, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 375, Loss: 0.0139227993786335, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 376, Loss: 0.014028266072273254, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 377, Loss: 0.024417400360107422, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 378, Loss: 0.009210146963596344, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 379, Loss: 0.01752723753452301, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 380, Loss: 0.003569461638107896, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 381, Loss: 0.012436061166226864, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 382, Loss: 0.03834511339664459, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 383, Loss: 0.05462230369448662, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 384, Loss: 0.09647469222545624, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 385, Loss: 0.005324455909430981, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 386, Loss: 0.0332162044942379, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 387, Loss: 0.06091251224279404, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 388, Loss: 0.015896346420049667, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 389, Loss: 0.04842134192585945, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 390, Loss: 0.0453859381377697, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 391, Loss: 0.008242256008088589, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 392, Loss: 0.012123417109251022, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 393, Loss: 0.034839414060115814, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 394, Loss: 0.008155117742717266, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 395, Loss: 0.022601943463087082, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 396, Loss: 0.004582568071782589, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 397, Loss: 0.01847710646688938, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 398, Loss: 0.014231575652956963, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 399, Loss: 0.0008860466768965125, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 400, Loss: 0.06966094672679901, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 401, Loss: 0.026074910536408424, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 402, Loss: 0.012056184932589531, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 403, Loss: 0.02230939269065857, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 404, Loss: 0.06269112229347229, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 405, Loss: 0.06092599406838417, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 406, Loss: 0.02531924471259117, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 407, Loss: 0.010699947364628315, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 408, Loss: 0.03152615949511528, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 409, Loss: 0.009906630031764507, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 410, Loss: 0.058952365070581436, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 411, Loss: 0.014063914306461811, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 412, Loss: 0.04704894497990608, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 413, Loss: 0.024566112086176872, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 414, Loss: 0.01527335960417986, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 415, Loss: 0.0426451750099659, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 416, Loss: 0.0012577208690345287, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 417, Loss: 0.09832341969013214, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 418, Loss: 0.0076095303520560265, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 419, Loss: 0.05082212761044502, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 420, Loss: 0.01825902797281742, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 421, Loss: 0.00911794789135456, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 422, Loss: 0.01694086194038391, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 423, Loss: 0.03155221790075302, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 424, Loss: 0.009690990671515465, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 425, Loss: 0.00967152789235115, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 426, Loss: 0.028699008747935295, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 427, Loss: 0.01747913658618927, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 428, Loss: 0.026594243943691254, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 429, Loss: 0.047564148902893066, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 430, Loss: 0.004105378873646259, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 431, Loss: 0.015032622963190079, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 432, Loss: 0.02131779119372368, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 433, Loss: 0.012657771818339825, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 434, Loss: 0.02278911881148815, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 435, Loss: 0.007866350002586842, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 436, Loss: 0.02265205979347229, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 437, Loss: 0.028637755662202835, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 438, Loss: 0.008424710482358932, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 439, Loss: 0.02294270694255829, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 440, Loss: 0.03794366866350174, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 441, Loss: 0.0071460530161857605, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 442, Loss: 0.07763003557920456, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 443, Loss: 0.014138823375105858, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 444, Loss: 0.009963138960301876, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 445, Loss: 0.005222246050834656, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 446, Loss: 0.0005263991770334542, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 447, Loss: 0.034184057265520096, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 448, Loss: 0.0034676853101700544, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 449, Loss: 0.028814150020480156, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 450, Loss: 0.021442662924528122, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 451, Loss: 0.011988948099315166, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 452, Loss: 0.0013288576155900955, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 453, Loss: 0.03348271921277046, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 454, Loss: 0.003359468188136816, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 455, Loss: 0.00592306163161993, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 456, Loss: 0.009292647242546082, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 457, Loss: 0.008256570436060429, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 458, Loss: 0.0010863880161195993, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 459, Loss: 0.011667458340525627, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 460, Loss: 0.0002463382843416184, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 461, Loss: 0.00015435843670275062, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 462, Loss: 0.00010082217340823263, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 463, Loss: 0.016762172803282738, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 464, Loss: 0.026138518005609512, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 465, Loss: 0.00028600526275113225, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 466, Loss: 0.15099328756332397, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 467, Loss: 0.0010063783265650272, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 468, Loss: 0.08967789262533188, Accuracy: 0.9895833730697632\n",
      "Epoch: 1, Loss: 0.03469703434000928, Accuracy: 0.9895667433738708\n",
      "Testing\n",
      "Epoch: 1, Batch: 0, Loss: 0.1317184418439865, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 1, Loss: 0.1436595767736435, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 2, Loss: 0.14330847561359406, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 3, Loss: 0.14985142648220062, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 4, Loss: 0.10080347210168839, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 5, Loss: 0.0733383521437645, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 6, Loss: 0.04616151005029678, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 7, Loss: 0.07945309579372406, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 8, Loss: 0.07568368315696716, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 9, Loss: 0.12377960979938507, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 10, Loss: 0.075979083776474, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 11, Loss: 0.06855752319097519, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 12, Loss: 0.07762611657381058, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 13, Loss: 0.0787307396531105, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 14, Loss: 0.04847390204668045, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 15, Loss: 0.036005113273859024, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 16, Loss: 0.118367999792099, Accuracy: 0.9453125\n",
      "Epoch: 1, Batch: 17, Loss: 0.06610677391290665, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 18, Loss: 0.02603202313184738, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 19, Loss: 0.05764341726899147, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 20, Loss: 0.10332624614238739, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 21, Loss: 0.03313053026795387, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 22, Loss: 0.031633876264095306, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 23, Loss: 0.06063802167773247, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 24, Loss: 0.016764529049396515, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 25, Loss: 0.025379018858075142, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 26, Loss: 0.03709792718291283, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 27, Loss: 0.06100181117653847, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 28, Loss: 0.008103189058601856, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 29, Loss: 0.07571956515312195, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 30, Loss: 0.023778950795531273, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 31, Loss: 0.023404914885759354, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 32, Loss: 0.03118058480322361, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 33, Loss: 0.05815059319138527, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 34, Loss: 0.02953265979886055, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 35, Loss: 0.041115887463092804, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 36, Loss: 0.015172692015767097, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 37, Loss: 0.045860350131988525, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 38, Loss: 0.023755541071295738, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 39, Loss: 0.009780686348676682, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 40, Loss: 0.014167788438498974, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 41, Loss: 0.006834312807768583, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 42, Loss: 0.0014984625158831477, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 43, Loss: 0.006248355843126774, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 44, Loss: 0.013863559812307358, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 45, Loss: 0.018475402146577835, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 46, Loss: 0.12083438038825989, Accuracy: 0.953125\n",
      "Epoch: 1, Batch: 47, Loss: 0.007229929324239492, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 48, Loss: 0.007143549621105194, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 49, Loss: 0.0004852191195823252, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 50, Loss: 0.021683011204004288, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 51, Loss: 0.29048189520835876, Accuracy: 0.9140625\n",
      "Epoch: 1, Batch: 52, Loss: 0.038485754281282425, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 53, Loss: 0.0021031261421740055, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 54, Loss: 0.0015958782751113176, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 55, Loss: 0.013053163886070251, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 56, Loss: 0.012903102673590183, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 57, Loss: 0.015667160972952843, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 58, Loss: 0.06352963298559189, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 59, Loss: 0.012535895220935345, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 60, Loss: 0.027813343331217766, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 61, Loss: 0.046722911298274994, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 62, Loss: 0.021987805142998695, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 63, Loss: 0.02209966443479061, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 64, Loss: 0.014611508697271347, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 65, Loss: 0.022042950615286827, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 66, Loss: 0.010477976873517036, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 67, Loss: 0.0035963966511189938, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 68, Loss: 0.0017852355958893895, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 69, Loss: 0.001693487516604364, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 70, Loss: 0.07889661937952042, Accuracy: 0.9765625\n",
      "Epoch: 1, Batch: 71, Loss: 0.022257346659898758, Accuracy: 0.9921875\n",
      "Epoch: 1, Batch: 72, Loss: 0.03481125831604004, Accuracy: 0.984375\n",
      "Epoch: 1, Batch: 73, Loss: 0.007038361858576536, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 74, Loss: 0.014658707194030285, Accuracy: 1.0\n",
      "Epoch: 1, Batch: 75, Loss: 0.13351550698280334, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 76, Loss: 0.10053786635398865, Accuracy: 0.96875\n",
      "Epoch: 1, Batch: 77, Loss: 0.07676997780799866, Accuracy: 0.9609375\n",
      "Epoch: 1, Batch: 78, Loss: 0.0010783621110022068, Accuracy: 1.0\n",
      "Epoch: 1, Loss: 0.04793699720765381, Accuracy: 0.9859573245048523\n",
      "Epoch: 2\n",
      "Epoch: 2, Batch: 0, Loss: 0.014962570741772652, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 1, Loss: 0.017431264743208885, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 2, Loss: 0.02807244099676609, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 3, Loss: 0.06660262495279312, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 4, Loss: 0.009555353783071041, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 5, Loss: 0.0031363421585410833, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 6, Loss: 0.010937576182186604, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 7, Loss: 0.06799507141113281, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 8, Loss: 0.005018352530896664, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 9, Loss: 0.004470942076295614, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 10, Loss: 0.13377737998962402, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 11, Loss: 0.012185946106910706, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 12, Loss: 0.06954653561115265, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 13, Loss: 0.0070013920776546, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 14, Loss: 0.0017619014251977205, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 15, Loss: 0.035603031516075134, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 16, Loss: 0.018205514177680016, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 17, Loss: 0.013278180733323097, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 18, Loss: 0.00802687183022499, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 19, Loss: 0.0012310632737353444, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 20, Loss: 0.005690844263881445, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 21, Loss: 0.05434662476181984, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 22, Loss: 0.006849447265267372, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 23, Loss: 0.0030216576997190714, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 24, Loss: 0.000660087913274765, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 25, Loss: 0.010647207498550415, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 26, Loss: 0.011389891617000103, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 27, Loss: 0.05009648948907852, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 28, Loss: 0.08431588858366013, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 29, Loss: 0.03062582015991211, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 30, Loss: 0.00051646598149091, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 31, Loss: 0.05933206528425217, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 32, Loss: 0.0545961856842041, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 33, Loss: 0.01427295058965683, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 34, Loss: 0.04662013798952103, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 35, Loss: 0.04925091937184334, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 36, Loss: 0.0010434692958369851, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 37, Loss: 0.003908241633325815, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 38, Loss: 0.03208707645535469, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 39, Loss: 0.05709352344274521, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 40, Loss: 0.05921584367752075, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 41, Loss: 0.030939795076847076, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 42, Loss: 0.019793907180428505, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 43, Loss: 0.04652489721775055, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 44, Loss: 0.10047152638435364, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 45, Loss: 0.10375194251537323, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 46, Loss: 0.008160289376974106, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 47, Loss: 0.009321705438196659, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 48, Loss: 0.06250195950269699, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 49, Loss: 0.01521445345133543, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 50, Loss: 0.05179733410477638, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 51, Loss: 0.01979605294764042, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 52, Loss: 0.009082498028874397, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 53, Loss: 0.045908670872449875, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 54, Loss: 0.0034531541168689728, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 55, Loss: 0.09958742558956146, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 56, Loss: 0.08454778045415878, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 57, Loss: 0.0076621831394732, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 58, Loss: 0.006613599136471748, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 59, Loss: 0.03997943922877312, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 60, Loss: 0.005134505219757557, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 61, Loss: 0.03535176441073418, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 62, Loss: 0.006587660405784845, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 63, Loss: 0.018778106197714806, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 64, Loss: 0.060659751296043396, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 65, Loss: 0.014637874439358711, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 66, Loss: 0.0608542263507843, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 67, Loss: 0.02294308878481388, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 68, Loss: 0.11805503815412521, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 69, Loss: 0.06367598474025726, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 70, Loss: 0.07763700932264328, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 71, Loss: 0.011092077009379864, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 72, Loss: 0.009473859332501888, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 73, Loss: 0.027510466054081917, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 74, Loss: 0.09072267264127731, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 75, Loss: 0.05152071639895439, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 76, Loss: 0.004586388356983662, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 77, Loss: 0.002661769511178136, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 78, Loss: 0.022763263434171677, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 79, Loss: 0.05225953087210655, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 80, Loss: 0.12019448727369308, Accuracy: 0.9609375\n",
      "Epoch: 2, Batch: 81, Loss: 0.012734416872262955, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 82, Loss: 0.0003110630495939404, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 83, Loss: 0.015616422519087791, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 84, Loss: 0.026547590270638466, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 85, Loss: 0.12354343384504318, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 86, Loss: 0.0018547498621046543, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 87, Loss: 0.042002350091934204, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 88, Loss: 0.004419348202645779, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 89, Loss: 0.006337708793580532, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 90, Loss: 0.01759457215666771, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 91, Loss: 0.023233745247125626, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 92, Loss: 0.08843875676393509, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 93, Loss: 0.026446785777807236, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 94, Loss: 0.0445438027381897, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 95, Loss: 0.02963395044207573, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 96, Loss: 0.020919399335980415, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 97, Loss: 0.042421795427799225, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 98, Loss: 0.01074110995978117, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 99, Loss: 0.06218136101961136, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 100, Loss: 0.03214707225561142, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 101, Loss: 0.011698463931679726, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 102, Loss: 0.017515087500214577, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 103, Loss: 0.01415315642952919, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 104, Loss: 0.010143328458070755, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 105, Loss: 0.011759401299059391, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 106, Loss: 0.00283723883330822, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 107, Loss: 0.048371121287345886, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 108, Loss: 0.0651814416050911, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 109, Loss: 0.03100619651377201, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 110, Loss: 0.00912878755480051, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 111, Loss: 0.001774617936462164, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 112, Loss: 0.0312009509652853, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 113, Loss: 0.03678077086806297, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 114, Loss: 0.004384832456707954, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 115, Loss: 0.02104731649160385, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 116, Loss: 0.01347586140036583, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 117, Loss: 0.000820083252619952, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 118, Loss: 0.02449578419327736, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 119, Loss: 0.0012748074950650334, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 120, Loss: 0.04998214915394783, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 121, Loss: 0.0038590221665799618, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 122, Loss: 0.0011397522175684571, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 123, Loss: 0.05041259527206421, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 124, Loss: 0.010494950227439404, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 125, Loss: 0.005960710346698761, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 126, Loss: 0.024282531812787056, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 127, Loss: 0.01003539189696312, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 128, Loss: 0.0007563724066130817, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 129, Loss: 0.010930567979812622, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 130, Loss: 0.037076305598020554, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 131, Loss: 0.01800888404250145, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 132, Loss: 0.012173846364021301, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 133, Loss: 0.053947143256664276, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 134, Loss: 0.0049639493227005005, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 135, Loss: 0.0016438778256997466, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 136, Loss: 0.04306888207793236, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 137, Loss: 0.02537395805120468, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 138, Loss: 0.01759563758969307, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 139, Loss: 0.046135906130075455, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 140, Loss: 0.034616436809301376, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 141, Loss: 0.040375638753175735, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 142, Loss: 0.004094345029443502, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 143, Loss: 0.03009721450507641, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 144, Loss: 0.0074219610542058945, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 145, Loss: 0.013078900054097176, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 146, Loss: 0.0025015678256750107, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 147, Loss: 0.001185228000395, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 148, Loss: 0.009908960200846195, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 149, Loss: 0.0324154831469059, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 150, Loss: 0.0075820996426045895, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 151, Loss: 0.011608419939875603, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 152, Loss: 0.010714354924857616, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 153, Loss: 0.004922602325677872, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 154, Loss: 0.0009465000475756824, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 155, Loss: 0.029823152348399162, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 156, Loss: 0.00874781608581543, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 157, Loss: 0.016108309850096703, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 158, Loss: 0.01695660687983036, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 159, Loss: 0.00022176376660354435, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 160, Loss: 0.002194671891629696, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 161, Loss: 0.022138945758342743, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 162, Loss: 0.029671909287571907, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 163, Loss: 0.02988966554403305, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 164, Loss: 0.0097750723361969, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 165, Loss: 0.005591195076704025, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 166, Loss: 0.022246437147259712, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 167, Loss: 0.033358633518218994, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 168, Loss: 0.04711876064538956, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 169, Loss: 0.0018995397258549929, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 170, Loss: 0.01584516651928425, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 171, Loss: 0.06184489652514458, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 172, Loss: 0.005458387546241283, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 173, Loss: 0.001083686831407249, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 174, Loss: 0.01578957587480545, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 175, Loss: 0.017359739169478416, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 176, Loss: 0.009910719469189644, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 177, Loss: 0.08891229331493378, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 178, Loss: 0.00107279559597373, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 179, Loss: 0.014581705443561077, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 180, Loss: 0.014424855820834637, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 181, Loss: 0.0030472411308437586, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 182, Loss: 0.013580016791820526, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 183, Loss: 0.005534487776458263, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 184, Loss: 0.024320749565958977, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 185, Loss: 0.03890746086835861, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 186, Loss: 0.02528487890958786, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 187, Loss: 0.004483039025217295, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 188, Loss: 0.01050146296620369, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 189, Loss: 0.009450726211071014, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 190, Loss: 0.004244656302034855, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 191, Loss: 0.005070158746093512, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 192, Loss: 0.045604001730680466, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 193, Loss: 0.065367192029953, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 194, Loss: 0.0082072913646698, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 195, Loss: 0.001961906673386693, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 196, Loss: 0.0203250739723444, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 197, Loss: 0.0032501828391104937, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 198, Loss: 0.000772937957663089, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 199, Loss: 0.016419973224401474, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 200, Loss: 0.04869465157389641, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 201, Loss: 0.014996739104390144, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 202, Loss: 0.017150837928056717, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 203, Loss: 0.011165544390678406, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 204, Loss: 0.04050597548484802, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 205, Loss: 0.015401639975607395, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 206, Loss: 0.06195570528507233, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 207, Loss: 0.18317538499832153, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 208, Loss: 0.07273342460393906, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 209, Loss: 0.033699773252010345, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 210, Loss: 0.052700694650411606, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 211, Loss: 0.0007839046884328127, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 212, Loss: 0.00350116821937263, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 213, Loss: 0.006793107837438583, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 214, Loss: 0.07162642478942871, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 215, Loss: 0.03221490979194641, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 216, Loss: 0.026761917397379875, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 217, Loss: 0.006177334114909172, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 218, Loss: 0.007868007756769657, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 219, Loss: 0.02867799438536167, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 220, Loss: 0.017446991056203842, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 221, Loss: 0.019013384357094765, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 222, Loss: 0.014483952894806862, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 223, Loss: 0.030387938022613525, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 224, Loss: 0.11984480172395706, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 225, Loss: 0.026662496849894524, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 226, Loss: 0.02789042703807354, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 227, Loss: 0.0030759007204324007, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 228, Loss: 0.014716913923621178, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 229, Loss: 0.04808695614337921, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 230, Loss: 0.034228675067424774, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 231, Loss: 0.02742891199886799, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 232, Loss: 0.04790781810879707, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 233, Loss: 0.033140286803245544, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 234, Loss: 0.020334560424089432, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 235, Loss: 0.012622346170246601, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 236, Loss: 0.011945733800530434, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 237, Loss: 0.0023301912005990744, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 238, Loss: 0.012514217756688595, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 239, Loss: 0.001912750187329948, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 240, Loss: 0.018369290977716446, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 241, Loss: 0.03542615845799446, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 242, Loss: 0.004339923150837421, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 243, Loss: 0.004903856664896011, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 244, Loss: 0.023892410099506378, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 245, Loss: 0.0020331349223852158, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 246, Loss: 0.13396099209785461, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 247, Loss: 0.01492252852767706, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 248, Loss: 0.038401126861572266, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 249, Loss: 0.019980359822511673, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 250, Loss: 0.05844753980636597, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 251, Loss: 0.00515604205429554, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 252, Loss: 0.201595276594162, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 253, Loss: 0.040580302476882935, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 254, Loss: 0.0228246059268713, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 255, Loss: 0.009153562597930431, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 256, Loss: 0.040461353957653046, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 257, Loss: 0.00404225941747427, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 258, Loss: 0.010673223994672298, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 259, Loss: 0.01382120605558157, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 260, Loss: 0.012580640614032745, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 261, Loss: 0.017772993072867393, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 262, Loss: 0.005876481533050537, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 263, Loss: 0.01866820640861988, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 264, Loss: 0.015189919620752335, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 265, Loss: 0.009974286891520023, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 266, Loss: 0.010066863149404526, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 267, Loss: 0.037652380764484406, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 268, Loss: 0.026859208941459656, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 269, Loss: 0.02562548778951168, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 270, Loss: 0.01563374139368534, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 271, Loss: 0.07553127408027649, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 272, Loss: 0.017768850550055504, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 273, Loss: 0.0029022085946053267, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 274, Loss: 0.0008476424845866859, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 275, Loss: 0.052814990282058716, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 276, Loss: 0.007486979477107525, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 277, Loss: 0.04778408259153366, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 278, Loss: 0.057718675583601, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 279, Loss: 0.006374867167323828, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 280, Loss: 0.013524498790502548, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 281, Loss: 0.05783380568027496, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 282, Loss: 0.023938952013850212, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 283, Loss: 0.05225790664553642, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 284, Loss: 0.04277953878045082, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 285, Loss: 0.009691284969449043, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 286, Loss: 0.020863644778728485, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 287, Loss: 0.060434985905885696, Accuracy: 0.9609375\n",
      "Epoch: 2, Batch: 288, Loss: 0.005128104239702225, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 289, Loss: 0.04264175519347191, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 290, Loss: 0.04157639667391777, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 291, Loss: 0.010771123692393303, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 292, Loss: 0.03533872216939926, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 293, Loss: 0.00958293117582798, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 294, Loss: 0.03858787938952446, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 295, Loss: 0.15280631184577942, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 296, Loss: 0.002017229562625289, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 297, Loss: 0.014094275422394276, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 298, Loss: 0.0015245637623593211, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 299, Loss: 0.05390319228172302, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 300, Loss: 0.027189915999770164, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 301, Loss: 0.003261091187596321, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 302, Loss: 0.06201215460896492, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 303, Loss: 0.006940559484064579, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 304, Loss: 0.029140528291463852, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 305, Loss: 0.009569129906594753, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 306, Loss: 0.04558525234460831, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 307, Loss: 0.054473791271448135, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 308, Loss: 0.015499673783779144, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 309, Loss: 0.004114816430956125, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 310, Loss: 0.011871381662786007, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 311, Loss: 0.006270119920372963, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 312, Loss: 0.015438586473464966, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 313, Loss: 0.09325027465820312, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 314, Loss: 0.03084699995815754, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 315, Loss: 0.16025035083293915, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 316, Loss: 0.007770630531013012, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 317, Loss: 0.013592526316642761, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 318, Loss: 0.003535996424034238, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 319, Loss: 0.04607461765408516, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 320, Loss: 0.04707636684179306, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 321, Loss: 0.036331657320261, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 322, Loss: 0.09014297276735306, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 323, Loss: 0.14091014862060547, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 324, Loss: 0.09595851600170135, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 325, Loss: 0.008379282429814339, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 326, Loss: 0.009045068174600601, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 327, Loss: 0.023959193378686905, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 328, Loss: 0.0034500458277761936, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 329, Loss: 0.03750896826386452, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 330, Loss: 0.020466888323426247, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 331, Loss: 0.0424564853310585, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 332, Loss: 0.0529642179608345, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 333, Loss: 0.019769081845879555, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 334, Loss: 0.021977197378873825, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 335, Loss: 0.027135606855154037, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 336, Loss: 0.01968984492123127, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 337, Loss: 0.004782631993293762, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 338, Loss: 0.00827469490468502, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 339, Loss: 0.11275195330381393, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 340, Loss: 0.009980208240449429, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 341, Loss: 0.053192395716905594, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 342, Loss: 0.008614200167357922, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 343, Loss: 0.004919624421745539, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 344, Loss: 0.00823627132922411, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 345, Loss: 0.039028797298669815, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 346, Loss: 0.014188947156071663, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 347, Loss: 0.03312872350215912, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 348, Loss: 0.0011835632612928748, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 349, Loss: 0.0013781733578070998, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 350, Loss: 0.011326995678246021, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 351, Loss: 0.0055153039284050465, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 352, Loss: 0.016557253897190094, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 353, Loss: 0.014594233594834805, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 354, Loss: 0.015655359253287315, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 355, Loss: 0.019748615100979805, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 356, Loss: 0.01715364307165146, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 357, Loss: 0.019822660833597183, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 358, Loss: 0.03377341851592064, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 359, Loss: 0.07587467133998871, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 360, Loss: 0.009928356856107712, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 361, Loss: 0.03798539936542511, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 362, Loss: 0.021519720554351807, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 363, Loss: 0.005780864506959915, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 364, Loss: 0.0028386744670569897, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 365, Loss: 0.022424204275012016, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 366, Loss: 0.003293075365945697, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 367, Loss: 0.045167069882154465, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 368, Loss: 0.00493151368573308, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 369, Loss: 0.034803468734025955, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 370, Loss: 0.04759883135557175, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 371, Loss: 0.003540918231010437, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 372, Loss: 0.04020078107714653, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 373, Loss: 0.012327935546636581, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 374, Loss: 0.02334030717611313, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 375, Loss: 0.03035437874495983, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 376, Loss: 0.0030534528195858, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 377, Loss: 0.009208457544445992, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 378, Loss: 0.0349983386695385, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 379, Loss: 0.013639467768371105, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 380, Loss: 0.008147889748215675, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 381, Loss: 0.022888243198394775, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 382, Loss: 0.10914605110883713, Accuracy: 0.9609375\n",
      "Epoch: 2, Batch: 383, Loss: 0.06322167813777924, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 384, Loss: 0.11235995590686798, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 385, Loss: 0.006359110586345196, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 386, Loss: 0.007467267569154501, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 387, Loss: 0.04641669988632202, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 388, Loss: 0.0310113076120615, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 389, Loss: 0.028694484382867813, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 390, Loss: 0.005173976998776197, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 391, Loss: 0.0005009757587686181, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 392, Loss: 0.08464610576629639, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 393, Loss: 0.15626829862594604, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 394, Loss: 0.003931394312530756, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 395, Loss: 0.006546356715261936, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 396, Loss: 0.005250377114862204, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 397, Loss: 0.0785355269908905, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 398, Loss: 0.00454314611852169, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 399, Loss: 0.002193015068769455, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 400, Loss: 0.05138558894395828, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 401, Loss: 0.046447526663541794, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 402, Loss: 0.03270939365029335, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 403, Loss: 0.017330359667539597, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 404, Loss: 0.01223701611161232, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 405, Loss: 0.06525611877441406, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 406, Loss: 0.027500944212079048, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 407, Loss: 0.025720590725541115, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 408, Loss: 0.1139502078294754, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 409, Loss: 0.011012058705091476, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 410, Loss: 0.008398455567657948, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 411, Loss: 0.03091997466981411, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 412, Loss: 0.054822929203510284, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 413, Loss: 0.06597364693880081, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 414, Loss: 0.021084919571876526, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 415, Loss: 0.013674476183950901, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 416, Loss: 0.0031374094542115927, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 417, Loss: 0.05328785255551338, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 418, Loss: 0.012075030244886875, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 419, Loss: 0.06306714564561844, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 420, Loss: 0.011356803588569164, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 421, Loss: 0.06244392693042755, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 422, Loss: 0.04474933445453644, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 423, Loss: 0.007909134030342102, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 424, Loss: 0.0008954584482125938, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 425, Loss: 0.04338109493255615, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 426, Loss: 0.02678157575428486, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 427, Loss: 0.019243601709604263, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 428, Loss: 0.04215885326266289, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 429, Loss: 0.01924259215593338, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 430, Loss: 0.002173243323341012, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 431, Loss: 0.010527625679969788, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 432, Loss: 0.06500205397605896, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 433, Loss: 0.00740169920027256, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 434, Loss: 0.009790580719709396, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 435, Loss: 0.004771074280142784, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 436, Loss: 0.018427981063723564, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 437, Loss: 0.016046540811657906, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 438, Loss: 0.031269997358322144, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 439, Loss: 0.05124850571155548, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 440, Loss: 0.014901572838425636, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 441, Loss: 0.006327637005597353, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 442, Loss: 0.03125641122460365, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 443, Loss: 0.022457247599959373, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 444, Loss: 0.01826424151659012, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 445, Loss: 0.010130324400961399, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 446, Loss: 0.00034255534410476685, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 447, Loss: 0.015621388331055641, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 448, Loss: 0.0026408026460558176, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 449, Loss: 0.011275635100901127, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 450, Loss: 0.0033231370616704226, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 451, Loss: 0.015022781677544117, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 452, Loss: 0.0012485833140090108, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 453, Loss: 0.0445481576025486, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 454, Loss: 0.00012475984112825245, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 455, Loss: 0.024728694930672646, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 456, Loss: 0.0005130161880515516, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 457, Loss: 0.00017408723942935467, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 458, Loss: 0.0006500737508758903, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 459, Loss: 0.03407322242856026, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 460, Loss: 0.0003071179671678692, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 461, Loss: 8.543623698642477e-05, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 462, Loss: 0.0002882049302570522, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 463, Loss: 0.022647826001048088, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 464, Loss: 0.0026665683835744858, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 465, Loss: 0.0001968911528820172, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 466, Loss: 0.09110621362924576, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 467, Loss: 0.01928732916712761, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 468, Loss: 0.11015526205301285, Accuracy: 0.9895833730697632\n",
      "Epoch: 2, Loss: 0.028093733286508285, Accuracy: 0.9912658333778381\n",
      "Testing\n",
      "Epoch: 2, Batch: 0, Loss: 0.12397816777229309, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 1, Loss: 0.06521903723478317, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 2, Loss: 0.0667320042848587, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 3, Loss: 0.07081519067287445, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 4, Loss: 0.046873725950717926, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 5, Loss: 0.049912672489881516, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 6, Loss: 0.03215879574418068, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 7, Loss: 0.08639232814311981, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 8, Loss: 0.05581093952059746, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 9, Loss: 0.09220569580793381, Accuracy: 0.9609375\n",
      "Epoch: 2, Batch: 10, Loss: 0.05645190551877022, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 11, Loss: 0.04045660048723221, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 12, Loss: 0.05665130168199539, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 13, Loss: 0.05834091454744339, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 14, Loss: 0.01706690713763237, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 15, Loss: 0.049136411398649216, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 16, Loss: 0.06427158415317535, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 17, Loss: 0.07659830152988434, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 18, Loss: 0.03672387823462486, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 19, Loss: 0.03884756565093994, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 20, Loss: 0.07217928767204285, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 21, Loss: 0.02527957782149315, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 22, Loss: 0.047717198729515076, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 23, Loss: 0.05041078105568886, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 24, Loss: 0.015017478726804256, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 25, Loss: 0.02307184599339962, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 26, Loss: 0.022127918899059296, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 27, Loss: 0.07210224121809006, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 28, Loss: 0.009990822523832321, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 29, Loss: 0.07193534821271896, Accuracy: 0.96875\n",
      "Epoch: 2, Batch: 30, Loss: 0.010319002903997898, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 31, Loss: 0.022550756111741066, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 32, Loss: 0.017507631331682205, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 33, Loss: 0.03462715819478035, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 34, Loss: 0.027552152052521706, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 35, Loss: 0.03227650374174118, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 36, Loss: 0.008286919444799423, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 37, Loss: 0.040044017136096954, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 38, Loss: 0.007543051149696112, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 39, Loss: 0.0037801105063408613, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 40, Loss: 0.005852043628692627, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 41, Loss: 0.003981408197432756, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 42, Loss: 0.0012571895495057106, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 43, Loss: 0.008236411958932877, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 44, Loss: 0.029635148122906685, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 45, Loss: 0.005062254145741463, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 46, Loss: 0.1117757111787796, Accuracy: 0.953125\n",
      "Epoch: 2, Batch: 47, Loss: 0.004716408904641867, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 48, Loss: 0.0015014739474281669, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 49, Loss: 0.0003911264648195356, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 50, Loss: 0.015045469626784325, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 51, Loss: 0.15184767544269562, Accuracy: 0.9453125\n",
      "Epoch: 2, Batch: 52, Loss: 0.02652808465063572, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 53, Loss: 0.006222373340278864, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 54, Loss: 0.007025999017059803, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 55, Loss: 0.022554265335202217, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 56, Loss: 0.010925836861133575, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 57, Loss: 0.0007601742399856448, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 58, Loss: 0.01158544234931469, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 59, Loss: 0.004941852297633886, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 60, Loss: 0.0014820434153079987, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 61, Loss: 0.011101020500063896, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 62, Loss: 0.006034509278833866, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 63, Loss: 0.017512362450361252, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 64, Loss: 0.013218428939580917, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 65, Loss: 0.012671294622123241, Accuracy: 0.9921875\n",
      "Epoch: 2, Batch: 66, Loss: 0.003880241885781288, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 67, Loss: 0.0003092920233029872, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 68, Loss: 0.00018359780369792134, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 69, Loss: 0.0002027116424869746, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 70, Loss: 0.047180384397506714, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 71, Loss: 0.0003606685786508024, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 72, Loss: 0.0007065198151394725, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 73, Loss: 0.0006472694803960621, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 74, Loss: 0.00331723690032959, Accuracy: 1.0\n",
      "Epoch: 2, Batch: 75, Loss: 0.034624263644218445, Accuracy: 0.984375\n",
      "Epoch: 2, Batch: 76, Loss: 0.08956753462553024, Accuracy: 0.9609375\n",
      "Epoch: 2, Batch: 77, Loss: 0.04233706369996071, Accuracy: 0.9765625\n",
      "Epoch: 2, Batch: 78, Loss: 0.0005921697011217475, Accuracy: 1.0\n",
      "Epoch: 2, Loss: 0.03183213536774215, Accuracy: 0.990209698677063\n",
      "Epoch: 3\n",
      "Epoch: 3, Batch: 0, Loss: 0.00896285567432642, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 1, Loss: 0.07927920669317245, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 2, Loss: 0.00258183223195374, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 3, Loss: 0.06964448094367981, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 4, Loss: 0.001986302435398102, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 5, Loss: 0.003641772083938122, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 6, Loss: 0.00552313681691885, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 7, Loss: 0.08961130678653717, Accuracy: 0.9609375\n",
      "Epoch: 3, Batch: 8, Loss: 0.00929031241685152, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 9, Loss: 0.00597261730581522, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 10, Loss: 0.07390033453702927, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 11, Loss: 0.0063472636975348, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 12, Loss: 0.010400746017694473, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 13, Loss: 0.011708912439644337, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 14, Loss: 0.00041553596383892, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 15, Loss: 0.036072950810194016, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 16, Loss: 0.006733205635100603, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 17, Loss: 0.00322133069857955, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 18, Loss: 0.036814264953136444, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 19, Loss: 0.0013855930883437395, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 20, Loss: 0.030498063191771507, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 21, Loss: 0.03587719798088074, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 22, Loss: 0.0026430534198880196, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 23, Loss: 0.0016164170810952783, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 24, Loss: 0.02805517055094242, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 25, Loss: 0.005139842163771391, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 26, Loss: 0.003743204288184643, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 27, Loss: 0.0177916269749403, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 28, Loss: 0.032230522483587265, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 29, Loss: 0.021039118990302086, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 30, Loss: 0.004581949207931757, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 31, Loss: 0.030125180259346962, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 32, Loss: 0.011301083490252495, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 33, Loss: 0.003293068381026387, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 34, Loss: 0.07750458270311356, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 35, Loss: 0.00019790024089161307, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 36, Loss: 0.06457880884408951, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 37, Loss: 0.01226094365119934, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 38, Loss: 0.010077848099172115, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 39, Loss: 0.10696237534284592, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 40, Loss: 0.0026138366665691137, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 41, Loss: 0.008483733981847763, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 42, Loss: 0.016881000250577927, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 43, Loss: 0.01224458683282137, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 44, Loss: 0.02592015638947487, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 45, Loss: 0.05461117997765541, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 46, Loss: 0.001333765801973641, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 47, Loss: 0.0022328742779791355, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 48, Loss: 0.024684973061084747, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 49, Loss: 0.00285821920260787, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 50, Loss: 0.04205374792218208, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 51, Loss: 0.001991688273847103, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 52, Loss: 0.023782940581440926, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 53, Loss: 0.02141328901052475, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 54, Loss: 0.0015773713821545243, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 55, Loss: 0.12619970738887787, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 56, Loss: 0.06936546415090561, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 57, Loss: 0.012846039608120918, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 58, Loss: 0.008585012517869473, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 59, Loss: 0.003369592595845461, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 60, Loss: 0.02215799316763878, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 61, Loss: 0.018169403076171875, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 62, Loss: 0.003465390531346202, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 63, Loss: 0.004745190963149071, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 64, Loss: 0.0329347625374794, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 65, Loss: 0.007598317228257656, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 66, Loss: 0.04203013703227043, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 67, Loss: 0.02883296087384224, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 68, Loss: 0.08696024864912033, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 69, Loss: 0.05631440132856369, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 70, Loss: 0.033539365977048874, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 71, Loss: 0.027073241770267487, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 72, Loss: 0.020641084760427475, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 73, Loss: 0.01588721014559269, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 74, Loss: 0.007341379765421152, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 75, Loss: 0.0067607443779706955, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 76, Loss: 0.03504745662212372, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 77, Loss: 0.012074713595211506, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 78, Loss: 0.013604175299406052, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 79, Loss: 0.027582678943872452, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 80, Loss: 0.09503379464149475, Accuracy: 0.9609375\n",
      "Epoch: 3, Batch: 81, Loss: 0.0008822469972074032, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 82, Loss: 4.263338269083761e-05, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 83, Loss: 0.006419649347662926, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 84, Loss: 0.013109573163092136, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 85, Loss: 0.17646369338035583, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 86, Loss: 0.0010060740169137716, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 87, Loss: 0.02405036985874176, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 88, Loss: 0.001577280811034143, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 89, Loss: 0.008413529023528099, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 90, Loss: 0.03146953880786896, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 91, Loss: 0.021873876452445984, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 92, Loss: 0.024876220151782036, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 93, Loss: 0.003117104759439826, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 94, Loss: 0.005741833709180355, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 95, Loss: 0.028094585984945297, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 96, Loss: 0.006346584297716618, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 97, Loss: 0.001492178882472217, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 98, Loss: 0.007521498017013073, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 99, Loss: 0.0011127091711387038, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 100, Loss: 0.03969446197152138, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 101, Loss: 0.011614156886935234, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 102, Loss: 0.017236007377505302, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 103, Loss: 0.0009177506435662508, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 104, Loss: 0.011045331135392189, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 105, Loss: 0.01663975417613983, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 106, Loss: 0.00039810524322092533, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 107, Loss: 0.01860576681792736, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 108, Loss: 0.024527497589588165, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 109, Loss: 0.07666283845901489, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 110, Loss: 0.015994759276509285, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 111, Loss: 0.0031600031070411205, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 112, Loss: 0.005901677533984184, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 113, Loss: 0.027126016095280647, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 114, Loss: 0.01045901421457529, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 115, Loss: 0.014463174156844616, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 116, Loss: 0.016628576442599297, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 117, Loss: 0.002803799929097295, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 118, Loss: 0.04187018796801567, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 119, Loss: 0.022621572017669678, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 120, Loss: 0.019248364493250847, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 121, Loss: 0.02757938764989376, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 122, Loss: 0.010565564967691898, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 123, Loss: 0.025821633636951447, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 124, Loss: 0.05853869020938873, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 125, Loss: 0.029943088069558144, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 126, Loss: 0.013734830543398857, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 127, Loss: 0.0018605414079502225, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 128, Loss: 0.00023832000442780554, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 129, Loss: 0.006826700177043676, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 130, Loss: 0.04022190719842911, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 131, Loss: 0.013884736225008965, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 132, Loss: 0.011382491327822208, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 133, Loss: 0.022786976769566536, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 134, Loss: 0.004195282701402903, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 135, Loss: 0.0014967690221965313, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 136, Loss: 0.0020833283197134733, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 137, Loss: 0.02096315659582615, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 138, Loss: 0.036927320063114166, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 139, Loss: 0.015695540234446526, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 140, Loss: 0.006824242416769266, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 141, Loss: 0.010240832343697548, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 142, Loss: 0.020443670451641083, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 143, Loss: 0.07174506783485413, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 144, Loss: 0.025481753051280975, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 145, Loss: 0.008685114793479443, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 146, Loss: 0.025921180844306946, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 147, Loss: 0.00485424418002367, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 148, Loss: 0.0023758241441100836, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 149, Loss: 0.059698574244976044, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 150, Loss: 0.06608463823795319, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 151, Loss: 0.010581822134554386, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 152, Loss: 0.027140023186802864, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 153, Loss: 0.007127780932933092, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 154, Loss: 0.0031818789429962635, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 155, Loss: 0.009319640696048737, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 156, Loss: 0.001316850888542831, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 157, Loss: 0.020171064883470535, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 158, Loss: 0.032362692058086395, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 159, Loss: 0.0006873292149975896, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 160, Loss: 0.0007214354700408876, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 161, Loss: 0.005015129689127207, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 162, Loss: 0.046400655061006546, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 163, Loss: 0.01849997043609619, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 164, Loss: 0.0017822305671870708, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 165, Loss: 0.007773019839078188, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 166, Loss: 0.007307284977287054, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 167, Loss: 0.013587528839707375, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 168, Loss: 0.014278631657361984, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 169, Loss: 0.005065963137894869, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 170, Loss: 0.028793152421712875, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 171, Loss: 0.009026015177369118, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 172, Loss: 0.003264258848503232, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 173, Loss: 0.003130292519927025, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 174, Loss: 0.00028893485432490706, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 175, Loss: 0.0007496924372389913, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 176, Loss: 0.11906895041465759, Accuracy: 0.9609375\n",
      "Epoch: 3, Batch: 177, Loss: 0.045913755893707275, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 178, Loss: 0.009496201761066914, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 179, Loss: 0.023510465398430824, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 180, Loss: 0.0014848136343061924, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 181, Loss: 0.006475384347140789, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 182, Loss: 0.004981174133718014, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 183, Loss: 0.008046614937484264, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 184, Loss: 0.043558575212955475, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 185, Loss: 0.012075714766979218, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 186, Loss: 0.015891781076788902, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 187, Loss: 0.0023492793552577496, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 188, Loss: 0.0621970109641552, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 189, Loss: 0.008312497287988663, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 190, Loss: 0.003905178513377905, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 191, Loss: 0.009034376591444016, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 192, Loss: 0.09023408591747284, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 193, Loss: 0.055641841143369675, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 194, Loss: 0.03681232035160065, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 195, Loss: 0.0006653025047853589, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 196, Loss: 0.017626555636525154, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 197, Loss: 0.05364705249667168, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 198, Loss: 0.0017524231225252151, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 199, Loss: 0.012063462287187576, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 200, Loss: 0.058024175465106964, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 201, Loss: 0.01985987462103367, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 202, Loss: 0.009301848709583282, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 203, Loss: 0.020783141255378723, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 204, Loss: 0.003986137453466654, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 205, Loss: 0.006406730972230434, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 206, Loss: 0.08793829381465912, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 207, Loss: 0.06886830180883408, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 208, Loss: 0.05822787433862686, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 209, Loss: 0.006644363049417734, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 210, Loss: 0.017928440123796463, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 211, Loss: 0.0010346544440835714, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 212, Loss: 0.024810172617435455, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 213, Loss: 0.04830170050263405, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 214, Loss: 0.014809625223279, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 215, Loss: 0.06630723178386688, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 216, Loss: 0.006929018534719944, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 217, Loss: 0.0013929569395259023, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 218, Loss: 0.0032892394810914993, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 219, Loss: 0.002039896557107568, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 220, Loss: 0.025023996829986572, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 221, Loss: 0.022306250408291817, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 222, Loss: 0.001515248673968017, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 223, Loss: 0.001324943033978343, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 224, Loss: 0.05224819853901863, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 225, Loss: 0.04097801446914673, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 226, Loss: 0.03584655746817589, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 227, Loss: 0.03283991292119026, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 228, Loss: 0.054074976593256, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 229, Loss: 0.00638949079439044, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 230, Loss: 0.009763319976627827, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 231, Loss: 0.006155882030725479, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 232, Loss: 0.010757065378129482, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 233, Loss: 0.007746135350316763, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 234, Loss: 0.007056472357362509, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 235, Loss: 0.010306810960173607, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 236, Loss: 0.0022561801597476006, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 237, Loss: 0.004152481909841299, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 238, Loss: 0.010454264469444752, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 239, Loss: 0.02675030380487442, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 240, Loss: 0.08304161578416824, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 241, Loss: 0.0038182614371180534, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 242, Loss: 0.023003125563263893, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 243, Loss: 0.003074423875659704, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 244, Loss: 0.04500798508524895, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 245, Loss: 0.002901364117860794, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 246, Loss: 0.0633443146944046, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 247, Loss: 0.04076189547777176, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 248, Loss: 0.00375910522416234, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 249, Loss: 0.002574134850874543, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 250, Loss: 0.01730351336300373, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 251, Loss: 0.00661245733499527, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 252, Loss: 0.03191728889942169, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 253, Loss: 0.016126006841659546, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 254, Loss: 0.002465628320351243, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 255, Loss: 0.035041216760873795, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 256, Loss: 0.03244689106941223, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 257, Loss: 0.00048398133367300034, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 258, Loss: 0.0036102149169892073, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 259, Loss: 0.010724938474595547, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 260, Loss: 0.04686961695551872, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 261, Loss: 0.038247000426054, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 262, Loss: 0.0008678544545546174, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 263, Loss: 0.021220263093709946, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 264, Loss: 0.002641981700435281, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 265, Loss: 0.012816700153052807, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 266, Loss: 0.014541790820658207, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 267, Loss: 0.0006286036805249751, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 268, Loss: 0.034114617854356766, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 269, Loss: 0.0018286065896973014, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 270, Loss: 0.008343396708369255, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 271, Loss: 0.03578241914510727, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 272, Loss: 0.012403243221342564, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 273, Loss: 0.0057865921407938, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 274, Loss: 0.005030980799347162, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 275, Loss: 0.0116291344165802, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 276, Loss: 0.005351828411221504, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 277, Loss: 0.040848493576049805, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 278, Loss: 0.03822336345911026, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 279, Loss: 0.0015806168084964156, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 280, Loss: 0.010781851597130299, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 281, Loss: 0.010526588186621666, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 282, Loss: 0.014154157601296902, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 283, Loss: 0.002429833635687828, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 284, Loss: 0.06310567259788513, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 285, Loss: 0.003949849866330624, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 286, Loss: 0.07876431941986084, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 287, Loss: 0.004887136165052652, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 288, Loss: 0.004751481581479311, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 289, Loss: 0.04554242268204689, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 290, Loss: 0.015758389607071877, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 291, Loss: 0.04802640154957771, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 292, Loss: 0.024029666557908058, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 293, Loss: 0.0611923485994339, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 294, Loss: 0.014369465410709381, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 295, Loss: 0.024318940937519073, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 296, Loss: 0.0025733832735568285, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 297, Loss: 0.020857052877545357, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 298, Loss: 0.001107713207602501, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 299, Loss: 0.012715446762740612, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 300, Loss: 0.0267266184091568, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 301, Loss: 0.01390467956662178, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 302, Loss: 0.01746060512959957, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 303, Loss: 0.014055589213967323, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 304, Loss: 0.0022360391449183226, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 305, Loss: 0.0011586056789383292, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 306, Loss: 0.002583993598818779, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 307, Loss: 0.05138896033167839, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 308, Loss: 0.004649037029594183, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 309, Loss: 0.006710398010909557, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 310, Loss: 0.038730766624212265, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 311, Loss: 0.005797010846436024, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 312, Loss: 0.01434948481619358, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 313, Loss: 0.05658123642206192, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 314, Loss: 0.010822259820997715, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 315, Loss: 0.03670952841639519, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 316, Loss: 0.004978604149073362, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 317, Loss: 0.026868728920817375, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 318, Loss: 0.018538471311330795, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 319, Loss: 0.017228931188583374, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 320, Loss: 0.02220435068011284, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 321, Loss: 0.007673564366996288, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 322, Loss: 0.06050495058298111, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 323, Loss: 0.03459944203495979, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 324, Loss: 0.04007136449217796, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 325, Loss: 0.002333372598513961, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 326, Loss: 0.0004479881899897009, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 327, Loss: 0.0006611953140236437, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 328, Loss: 0.0028756754472851753, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 329, Loss: 0.04748326167464256, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 330, Loss: 0.01142361480742693, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 331, Loss: 0.001079318462871015, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 332, Loss: 0.021610405296087265, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 333, Loss: 0.02942027896642685, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 334, Loss: 0.028783930465579033, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 335, Loss: 0.00403627660125494, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 336, Loss: 0.04245259612798691, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 337, Loss: 0.007984299212694168, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 338, Loss: 0.0003520845784805715, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 339, Loss: 0.20495350658893585, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 340, Loss: 0.003335476154461503, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 341, Loss: 0.030912254005670547, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 342, Loss: 0.01313625369220972, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 343, Loss: 0.03314019739627838, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 344, Loss: 0.017540907487273216, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 345, Loss: 0.0026890537701547146, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 346, Loss: 0.06731781363487244, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 347, Loss: 0.016177551820874214, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 348, Loss: 0.0011824974790215492, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 349, Loss: 0.0010943388333544135, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 350, Loss: 0.009756692685186863, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 351, Loss: 0.01455344632267952, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 352, Loss: 0.006435800343751907, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 353, Loss: 0.005249821115285158, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 354, Loss: 0.05420100688934326, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 355, Loss: 0.007200240157544613, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 356, Loss: 0.028945723548531532, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 357, Loss: 0.010238364338874817, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 358, Loss: 0.02258623205125332, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 359, Loss: 0.060151126235723495, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 360, Loss: 0.004405259620398283, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 361, Loss: 0.013487191870808601, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 362, Loss: 0.028560930863022804, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 363, Loss: 0.0023718704469501972, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 364, Loss: 0.0018054437823593616, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 365, Loss: 0.020718559622764587, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 366, Loss: 0.01650608889758587, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 367, Loss: 0.08514195680618286, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 368, Loss: 0.03038022480905056, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 369, Loss: 0.02946087159216404, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 370, Loss: 0.06680312007665634, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 371, Loss: 0.007454740349203348, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 372, Loss: 0.021041685715317726, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 373, Loss: 0.024219868704676628, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 374, Loss: 0.028531523421406746, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 375, Loss: 0.002708297921344638, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 376, Loss: 0.009468541480600834, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 377, Loss: 0.018505960702896118, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 378, Loss: 0.01281057856976986, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 379, Loss: 0.003913177642971277, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 380, Loss: 0.004507510922849178, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 381, Loss: 0.006106641609221697, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 382, Loss: 0.023745134472846985, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 383, Loss: 0.06413090229034424, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 384, Loss: 0.065903440117836, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 385, Loss: 0.014076708815991879, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 386, Loss: 0.01922765001654625, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 387, Loss: 0.010249858722090721, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 388, Loss: 0.033209290355443954, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 389, Loss: 0.026694953441619873, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 390, Loss: 0.0018189351540058851, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 391, Loss: 0.02132999710738659, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 392, Loss: 0.01872396655380726, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 393, Loss: 0.06396419554948807, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 394, Loss: 0.0027291683945804834, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 395, Loss: 0.024078693240880966, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 396, Loss: 0.017621150240302086, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 397, Loss: 0.002899176673963666, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 398, Loss: 0.00048662448534742, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 399, Loss: 0.0003990364202763885, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 400, Loss: 0.08957846462726593, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 401, Loss: 0.02695092186331749, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 402, Loss: 0.001408116426318884, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 403, Loss: 0.003276366740465164, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 404, Loss: 0.03956254944205284, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 405, Loss: 0.05046373978257179, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 406, Loss: 0.001657329499721527, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 407, Loss: 0.0029842155054211617, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 408, Loss: 0.024873122572898865, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 409, Loss: 0.0037272979971021414, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 410, Loss: 0.030703891068696976, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 411, Loss: 0.007372276857495308, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 412, Loss: 0.0032073413021862507, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 413, Loss: 0.09054720401763916, Accuracy: 0.9609375\n",
      "Epoch: 3, Batch: 414, Loss: 0.02525230124592781, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 415, Loss: 0.029842859134078026, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 416, Loss: 0.007845969870686531, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 417, Loss: 0.0584103986620903, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 418, Loss: 0.002364147687330842, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 419, Loss: 0.023852771148085594, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 420, Loss: 0.043894603848457336, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 421, Loss: 0.013444753363728523, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 422, Loss: 0.014938823878765106, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 423, Loss: 0.008602652698755264, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 424, Loss: 0.003399407956749201, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 425, Loss: 0.008392811752855778, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 426, Loss: 0.0027141112368553877, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 427, Loss: 0.007147989701479673, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 428, Loss: 0.03161703795194626, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 429, Loss: 0.002547364216297865, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 430, Loss: 0.02391640841960907, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 431, Loss: 0.006695558782666922, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 432, Loss: 0.021693730726838112, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 433, Loss: 0.008955416269600391, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 434, Loss: 0.006316393613815308, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 435, Loss: 0.03395353630185127, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 436, Loss: 0.0013346039922907948, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 437, Loss: 0.001381546608172357, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 438, Loss: 0.00760739715769887, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 439, Loss: 0.0031160179059952497, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 440, Loss: 0.027715200558304787, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 441, Loss: 0.0031479124445468187, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 442, Loss: 0.04897483438253403, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 443, Loss: 0.0047664460726082325, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 444, Loss: 0.05253395065665245, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 445, Loss: 0.006614891812205315, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 446, Loss: 9.293686161981896e-05, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 447, Loss: 0.026606617495417595, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 448, Loss: 0.0004070534778293222, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 449, Loss: 0.009960136376321316, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 450, Loss: 0.016567520797252655, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 451, Loss: 0.03671113774180412, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 452, Loss: 0.0009496069978922606, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 453, Loss: 0.01928793638944626, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 454, Loss: 3.519390520523302e-05, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 455, Loss: 0.0005689953686669469, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 456, Loss: 0.01689867302775383, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 457, Loss: 0.0003775037475861609, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 458, Loss: 0.0029731900431215763, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 459, Loss: 0.0011870936723425984, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 460, Loss: 0.00010089107672683895, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 461, Loss: 6.124066567281261e-05, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 462, Loss: 0.0005501719424501061, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 463, Loss: 0.015030888840556145, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 464, Loss: 0.004804861731827259, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 465, Loss: 5.5423421144951135e-05, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 466, Loss: 0.10701639950275421, Accuracy: 0.9453125\n",
      "Epoch: 3, Batch: 467, Loss: 0.001049770275130868, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 468, Loss: 0.11533128470182419, Accuracy: 0.9791666865348816\n",
      "Epoch: 3, Loss: 0.021267285692843862, Accuracy: 0.9933091402053833\n",
      "Testing\n",
      "Epoch: 3, Batch: 0, Loss: 0.019317366182804108, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 1, Loss: 0.027737222611904144, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 2, Loss: 0.07918565720319748, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 3, Loss: 0.03023833967745304, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 4, Loss: 0.034903883934020996, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 5, Loss: 0.05385831370949745, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 6, Loss: 0.018603632226586342, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 7, Loss: 0.0324920117855072, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 8, Loss: 0.06494035571813583, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 9, Loss: 0.07132115215063095, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 10, Loss: 0.0402972511947155, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 11, Loss: 0.03444294258952141, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 12, Loss: 0.032845500856637955, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 13, Loss: 0.045019954442977905, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 14, Loss: 0.016591748222708702, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 15, Loss: 0.022559918463230133, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 16, Loss: 0.06669162958860397, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 17, Loss: 0.04730105772614479, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 18, Loss: 0.035909999161958694, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 19, Loss: 0.027061827480793, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 20, Loss: 0.08018144965171814, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 21, Loss: 0.02636958658695221, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 22, Loss: 0.0417683944106102, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 23, Loss: 0.027166295796632767, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 24, Loss: 0.01967678777873516, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 25, Loss: 0.02017861232161522, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 26, Loss: 0.02542376145720482, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 27, Loss: 0.031421829015016556, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 28, Loss: 0.01239520963281393, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 29, Loss: 0.033395204693078995, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 30, Loss: 0.024988364428281784, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 31, Loss: 0.015184077434241772, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 32, Loss: 0.028489310294389725, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 33, Loss: 0.03891919553279877, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 34, Loss: 0.01361439935863018, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 35, Loss: 0.02745664305984974, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 36, Loss: 0.017195088788866997, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 37, Loss: 0.04162680730223656, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 38, Loss: 0.009638865478336811, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 39, Loss: 0.005549084860831499, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 40, Loss: 0.012865498661994934, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 41, Loss: 0.00989946536719799, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 42, Loss: 0.000981394317932427, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 43, Loss: 0.002183970995247364, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 44, Loss: 0.013222910463809967, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 45, Loss: 0.005551266949623823, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 46, Loss: 0.047437336295843124, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 47, Loss: 0.0020512896589934826, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 48, Loss: 0.0012293403269723058, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 49, Loss: 0.0004112143360543996, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 50, Loss: 0.0035831774584949017, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 51, Loss: 0.08599589765071869, Accuracy: 0.9765625\n",
      "Epoch: 3, Batch: 52, Loss: 0.009766173548996449, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 53, Loss: 0.0015916225966066122, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 54, Loss: 0.0015145867364481091, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 55, Loss: 0.008408560417592525, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 56, Loss: 0.006797545589506626, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 57, Loss: 0.00042930967174470425, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 58, Loss: 0.004160727374255657, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 59, Loss: 0.0014402902452275157, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 60, Loss: 0.000718596507795155, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 61, Loss: 0.007070782594382763, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 62, Loss: 0.009252957068383694, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 63, Loss: 0.022926416248083115, Accuracy: 0.984375\n",
      "Epoch: 3, Batch: 64, Loss: 0.015128451399505138, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 65, Loss: 0.01041749119758606, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 66, Loss: 0.0015890662325546145, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 67, Loss: 0.00022573636670131236, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 68, Loss: 8.413642353843898e-05, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 69, Loss: 0.00012402902939356863, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 70, Loss: 0.018020300194621086, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 71, Loss: 0.0003756181977223605, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 72, Loss: 0.0006204616511240602, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 73, Loss: 0.0026005511172115803, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 74, Loss: 0.0030463740695267916, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 75, Loss: 0.018926970660686493, Accuracy: 1.0\n",
      "Epoch: 3, Batch: 76, Loss: 0.07407023012638092, Accuracy: 0.96875\n",
      "Epoch: 3, Batch: 77, Loss: 0.02593385800719261, Accuracy: 0.9921875\n",
      "Epoch: 3, Batch: 78, Loss: 0.0004391378606669605, Accuracy: 1.0\n",
      "Epoch: 3, Loss: 0.02244368957501506, Accuracy: 0.9932753443717957\n",
      "Epoch: 4\n",
      "Epoch: 4, Batch: 0, Loss: 0.001723071443848312, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 1, Loss: 0.00886575784534216, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 2, Loss: 0.006776765454560518, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 3, Loss: 0.024013960734009743, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 4, Loss: 0.027953503653407097, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 5, Loss: 0.0012579212198033929, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 6, Loss: 0.01140716951340437, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 7, Loss: 0.006424805149435997, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 8, Loss: 0.015126179903745651, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 9, Loss: 0.0051813386380672455, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 10, Loss: 0.07667244225740433, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 11, Loss: 0.015139782801270485, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 12, Loss: 0.005835314281284809, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 13, Loss: 0.0015737287467345595, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 14, Loss: 0.0025406749919056892, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 15, Loss: 0.008706599473953247, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 16, Loss: 0.003293318673968315, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 17, Loss: 0.015532068908214569, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 18, Loss: 0.021497156471014023, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 19, Loss: 0.031238339841365814, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 20, Loss: 0.01654127985239029, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 21, Loss: 0.012865529395639896, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 22, Loss: 0.031719088554382324, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 23, Loss: 0.0008658543811179698, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 24, Loss: 0.0009175162413157523, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 25, Loss: 0.0007540859514847398, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 26, Loss: 0.013202456757426262, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 27, Loss: 0.006613694131374359, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 28, Loss: 0.06761947274208069, Accuracy: 0.96875\n",
      "Epoch: 4, Batch: 29, Loss: 0.004079311154782772, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 30, Loss: 7.684565935051069e-05, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 31, Loss: 0.027665842324495316, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 32, Loss: 0.0005244549829512835, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 33, Loss: 0.0022265836596488953, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 34, Loss: 0.07098884135484695, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 35, Loss: 0.0005205682828091085, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 36, Loss: 0.002606913447380066, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 37, Loss: 0.0018426134483888745, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 38, Loss: 0.0006369103211909533, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 39, Loss: 0.002463934477418661, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 40, Loss: 0.008480637334287167, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 41, Loss: 0.018765229731798172, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 42, Loss: 0.00022804259788244963, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 43, Loss: 0.00757220946252346, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 44, Loss: 0.04333223029971123, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 45, Loss: 0.03699939325451851, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 46, Loss: 0.024416906759142876, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 47, Loss: 0.05047450214624405, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 48, Loss: 0.013342130929231644, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 49, Loss: 0.01188536174595356, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 50, Loss: 0.041671428829431534, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 51, Loss: 0.009876582771539688, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 52, Loss: 0.01338101364672184, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 53, Loss: 0.012006574310362339, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 54, Loss: 0.06059195473790169, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 55, Loss: 0.05033572018146515, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 56, Loss: 0.015853269025683403, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 57, Loss: 0.03441404178738594, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 58, Loss: 0.017368314787745476, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 59, Loss: 0.002751268446445465, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 60, Loss: 0.010533508844673634, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 61, Loss: 0.011124186217784882, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 62, Loss: 0.016170302405953407, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 63, Loss: 0.06638235598802567, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 64, Loss: 0.005830585956573486, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 65, Loss: 0.012193150818347931, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 66, Loss: 0.004812193568795919, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 67, Loss: 0.003014753805473447, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 68, Loss: 0.04010132700204849, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 69, Loss: 0.013238021172583103, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 70, Loss: 0.00036052518407814205, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 71, Loss: 0.006780923344194889, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 72, Loss: 0.0079673295840621, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 73, Loss: 0.002892160089686513, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 74, Loss: 0.0016794770490378141, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 75, Loss: 0.005765662062913179, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 76, Loss: 0.007155905477702618, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 77, Loss: 0.0006680927472189069, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 78, Loss: 0.06139512360095978, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 79, Loss: 0.0016777714481577277, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 80, Loss: 0.017833225429058075, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 81, Loss: 0.002124540042132139, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 82, Loss: 4.156319482717663e-05, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 83, Loss: 0.003703421913087368, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 84, Loss: 0.019065793603658676, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 85, Loss: 0.14472968876361847, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 86, Loss: 0.029039887711405754, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 87, Loss: 0.0033880500122904778, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 88, Loss: 0.012231703847646713, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 89, Loss: 0.00017149605264421552, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 90, Loss: 0.012101960368454456, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 91, Loss: 0.00602288544178009, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 92, Loss: 0.08917126804590225, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 93, Loss: 0.02648402564227581, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 94, Loss: 0.004929439164698124, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 95, Loss: 0.004775936249643564, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 96, Loss: 0.004273605067282915, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 97, Loss: 0.0006013582460582256, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 98, Loss: 0.0029635101091116667, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 99, Loss: 0.0011120731942355633, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 100, Loss: 0.003932108636945486, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 101, Loss: 0.05547736585140228, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 102, Loss: 0.014506449922919273, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 103, Loss: 0.024177102372050285, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 104, Loss: 0.00931718572974205, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 105, Loss: 0.06130726635456085, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 106, Loss: 0.018016496673226357, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 107, Loss: 0.0035050741862505674, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 108, Loss: 0.0018589362734928727, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 109, Loss: 0.03519274666905403, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 110, Loss: 0.0006373206852003932, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 111, Loss: 0.00909294281154871, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 112, Loss: 0.03810310363769531, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 113, Loss: 0.03468520566821098, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 114, Loss: 0.020641162991523743, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 115, Loss: 0.003564083017408848, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 116, Loss: 0.0012022280134260654, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 117, Loss: 0.0017439249204471707, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 118, Loss: 0.001469830283895135, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 119, Loss: 0.00762849161401391, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 120, Loss: 0.07068057358264923, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 121, Loss: 0.010503692552447319, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 122, Loss: 0.0002888343296945095, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 123, Loss: 0.06000959500670433, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 124, Loss: 0.033123139292001724, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 125, Loss: 0.0011695839930325747, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 126, Loss: 0.0067527624778449535, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 127, Loss: 0.007122692186385393, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 128, Loss: 0.0002228351659141481, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 129, Loss: 0.005418207496404648, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 130, Loss: 0.012503542006015778, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 131, Loss: 0.0007603807607665658, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 132, Loss: 0.003167622722685337, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 133, Loss: 0.0439634695649147, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 134, Loss: 0.005616004578769207, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 135, Loss: 0.0215897299349308, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 136, Loss: 0.016131456941366196, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 137, Loss: 0.012697956524789333, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 138, Loss: 0.009878569282591343, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 139, Loss: 0.02267647348344326, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 140, Loss: 0.03653571009635925, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 141, Loss: 0.0061935861594974995, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 142, Loss: 0.014498086646199226, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 143, Loss: 0.06249863654375076, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 144, Loss: 0.04334290698170662, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 145, Loss: 0.000768100842833519, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 146, Loss: 0.000956278236117214, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 147, Loss: 0.0004684398591052741, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 148, Loss: 0.004884114023298025, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 149, Loss: 0.041180502623319626, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 150, Loss: 0.02651391550898552, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 151, Loss: 0.08660860359668732, Accuracy: 0.96875\n",
      "Epoch: 4, Batch: 152, Loss: 0.0003945580974686891, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 153, Loss: 0.003034674795344472, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 154, Loss: 0.0009705342235974967, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 155, Loss: 0.00965624488890171, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 156, Loss: 0.07297132164239883, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 157, Loss: 0.02884654887020588, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 158, Loss: 0.02658424898982048, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 159, Loss: 0.0005073180655017495, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 160, Loss: 0.0010699433041736484, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 161, Loss: 0.014057268388569355, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 162, Loss: 0.01953606866300106, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 163, Loss: 0.023673996329307556, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 164, Loss: 0.054610658437013626, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 165, Loss: 0.004017728380858898, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 166, Loss: 0.013980759307742119, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 167, Loss: 0.0007703572046011686, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 168, Loss: 0.001992200966924429, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 169, Loss: 0.0003196236793883145, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 170, Loss: 0.0031451100949198008, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 171, Loss: 0.038144975900650024, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 172, Loss: 0.022099876776337624, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 173, Loss: 0.02626660093665123, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 174, Loss: 0.00862057413905859, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 175, Loss: 0.01941296085715294, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 176, Loss: 0.0657007023692131, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 177, Loss: 0.026367558166384697, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 178, Loss: 0.0008398158242926002, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 179, Loss: 0.0011114096269011497, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 180, Loss: 0.003248627297580242, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 181, Loss: 0.011261848732829094, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 182, Loss: 0.013212192803621292, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 183, Loss: 0.0014653377002105117, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 184, Loss: 0.03733225539326668, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 185, Loss: 0.02212347276508808, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 186, Loss: 0.050122227519750595, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 187, Loss: 0.012223239988088608, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 188, Loss: 0.004474491346627474, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 189, Loss: 0.029238486662507057, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 190, Loss: 0.034290701150894165, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 191, Loss: 0.010703583247959614, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 192, Loss: 0.019317111000418663, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 193, Loss: 0.035449039191007614, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 194, Loss: 0.03710690513253212, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 195, Loss: 0.0040733651258051395, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 196, Loss: 0.011995458044111729, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 197, Loss: 0.02478983625769615, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 198, Loss: 0.00042547943303361535, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 199, Loss: 0.0028054320719093084, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 200, Loss: 0.10089288651943207, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 201, Loss: 0.04210370033979416, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 202, Loss: 0.033002711832523346, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 203, Loss: 0.0009489069925621152, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 204, Loss: 0.05150149390101433, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 205, Loss: 0.024045875295996666, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 206, Loss: 0.016354601830244064, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 207, Loss: 0.09267422556877136, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 208, Loss: 0.03499063476920128, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 209, Loss: 0.008582410402595997, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 210, Loss: 0.004815044812858105, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 211, Loss: 0.010377250611782074, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 212, Loss: 0.002371853217482567, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 213, Loss: 0.00422552227973938, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 214, Loss: 0.033996760845184326, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 215, Loss: 0.03884510323405266, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 216, Loss: 0.02945041097700596, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 217, Loss: 0.0036045049782842398, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 218, Loss: 0.001968666212633252, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 219, Loss: 0.01431415043771267, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 220, Loss: 0.05745791271328926, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 221, Loss: 0.06158587336540222, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 222, Loss: 0.0005960465641692281, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 223, Loss: 0.0074294134974479675, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 224, Loss: 0.026255212724208832, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 225, Loss: 0.002675391733646393, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 226, Loss: 0.020095471292734146, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 227, Loss: 0.005286119412630796, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 228, Loss: 0.011789007112383842, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 229, Loss: 0.021809091791510582, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 230, Loss: 0.005024708341807127, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 231, Loss: 0.04069960489869118, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 232, Loss: 0.03138298541307449, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 233, Loss: 0.007964867167174816, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 234, Loss: 0.013798441737890244, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 235, Loss: 0.032792072743177414, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 236, Loss: 0.03270269185304642, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 237, Loss: 0.0032810617703944445, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 238, Loss: 0.00624609412625432, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 239, Loss: 0.013301952742040157, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 240, Loss: 0.0646313801407814, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 241, Loss: 0.005053198896348476, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 242, Loss: 0.003753505414351821, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 243, Loss: 0.0016887788660824299, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 244, Loss: 0.023094959557056427, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 245, Loss: 0.09511956572532654, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 246, Loss: 0.015345508232712746, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 247, Loss: 0.016832105815410614, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 248, Loss: 0.003383426461368799, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 249, Loss: 0.0018298268551006913, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 250, Loss: 0.006999011151492596, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 251, Loss: 0.0038839562330394983, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 252, Loss: 0.049522869288921356, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 253, Loss: 0.015829235315322876, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 254, Loss: 0.012347820214927197, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 255, Loss: 0.0033659988548606634, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 256, Loss: 0.04077728092670441, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 257, Loss: 0.002524446463212371, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 258, Loss: 0.0038930941373109818, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 259, Loss: 0.0030975970439612865, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 260, Loss: 0.016125312075018883, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 261, Loss: 0.016865063458681107, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 262, Loss: 0.019251933321356773, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 263, Loss: 0.022649114951491356, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 264, Loss: 0.004001301247626543, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 265, Loss: 0.0004968609428033233, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 266, Loss: 0.0073435427621006966, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 267, Loss: 0.0036017082165926695, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 268, Loss: 0.03979124501347542, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 269, Loss: 0.000514925573952496, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 270, Loss: 0.029884513467550278, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 271, Loss: 0.020863978192210197, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 272, Loss: 0.02919531986117363, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 273, Loss: 0.004695172421634197, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 274, Loss: 0.00015030060603749007, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 275, Loss: 0.032126568257808685, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 276, Loss: 0.00017830125580076128, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 277, Loss: 0.13962215185165405, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 278, Loss: 0.0024044893216341734, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 279, Loss: 0.0073297638446092606, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 280, Loss: 0.005028914660215378, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 281, Loss: 0.00246548093855381, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 282, Loss: 0.025792429223656654, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 283, Loss: 0.012787741608917713, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 284, Loss: 0.023689711466431618, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 285, Loss: 0.027471372857689857, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 286, Loss: 0.05297459661960602, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 287, Loss: 0.0072969128377735615, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 288, Loss: 0.003978629596531391, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 289, Loss: 0.04445178061723709, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 290, Loss: 0.004332962445914745, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 291, Loss: 0.007873882539570332, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 292, Loss: 0.004744932986795902, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 293, Loss: 0.02331785298883915, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 294, Loss: 0.0034561282955110073, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 295, Loss: 0.0467975027859211, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 296, Loss: 0.0005802949890494347, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 297, Loss: 0.0011940965196117759, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 298, Loss: 0.0014648803044110537, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 299, Loss: 0.050727132707834244, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 300, Loss: 0.03995220735669136, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 301, Loss: 0.000370145688066259, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 302, Loss: 0.04493330046534538, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 303, Loss: 0.006056356243789196, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 304, Loss: 0.02688492462038994, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 305, Loss: 0.0059758457355201244, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 306, Loss: 0.05753039941191673, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 307, Loss: 0.06249994784593582, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 308, Loss: 0.0015428566839545965, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 309, Loss: 0.03148069232702255, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 310, Loss: 0.028765080496668816, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 311, Loss: 0.0012203672667965293, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 312, Loss: 0.0014973245561122894, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 313, Loss: 0.04422864690423012, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 314, Loss: 0.002698774915188551, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 315, Loss: 0.05761340260505676, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 316, Loss: 0.017966557294130325, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 317, Loss: 0.009724932722747326, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 318, Loss: 0.07208507508039474, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 319, Loss: 0.0033564737532287836, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 320, Loss: 0.019365180283784866, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 321, Loss: 0.0238624420017004, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 322, Loss: 0.03259545937180519, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 323, Loss: 0.03499243035912514, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 324, Loss: 0.03191237151622772, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 325, Loss: 0.010765179060399532, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 326, Loss: 0.011077271774411201, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 327, Loss: 0.05431308597326279, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 328, Loss: 0.051946189254522324, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 329, Loss: 0.0011774409795179963, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 330, Loss: 0.020648088306188583, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 331, Loss: 0.01568617857992649, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 332, Loss: 0.022101694718003273, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 333, Loss: 0.023478012531995773, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 334, Loss: 0.00263658887706697, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 335, Loss: 0.001379102817736566, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 336, Loss: 0.0552707239985466, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 337, Loss: 0.011841154657304287, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 338, Loss: 0.008922652341425419, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 339, Loss: 0.05545389652252197, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 340, Loss: 0.017955901101231575, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 341, Loss: 0.006886705756187439, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 342, Loss: 0.07553255558013916, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 343, Loss: 0.018784280866384506, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 344, Loss: 0.008992179296910763, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 345, Loss: 0.005791082512587309, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 346, Loss: 0.016197556629776955, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 347, Loss: 0.0043023633770644665, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 348, Loss: 0.0010857146698981524, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 349, Loss: 0.0019152972381561995, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 350, Loss: 0.011220328509807587, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 351, Loss: 0.012477810494601727, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 352, Loss: 0.0013605697313323617, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 353, Loss: 0.0013340177247300744, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 354, Loss: 0.043144337832927704, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 355, Loss: 0.0018148950766772032, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 356, Loss: 0.023713653907179832, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 357, Loss: 0.010186238214373589, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 358, Loss: 0.030752360820770264, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 359, Loss: 0.021389111876487732, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 360, Loss: 0.004446367733180523, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 361, Loss: 0.019031835719943047, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 362, Loss: 0.027954207733273506, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 363, Loss: 0.0006723743863403797, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 364, Loss: 0.007894481532275677, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 365, Loss: 0.013734284788370132, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 366, Loss: 0.03576137498021126, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 367, Loss: 0.024733277037739754, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 368, Loss: 0.0014321268536150455, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 369, Loss: 0.06941429525613785, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 370, Loss: 0.0016595338238403201, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 371, Loss: 0.03534356504678726, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 372, Loss: 0.0009507316281087697, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 373, Loss: 0.035219304263591766, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 374, Loss: 0.0011850856244564056, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 375, Loss: 0.03287917375564575, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 376, Loss: 0.016175491735339165, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 377, Loss: 0.00514065520837903, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 378, Loss: 0.013051653280854225, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 379, Loss: 0.0029917370993644, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 380, Loss: 0.003906331956386566, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 381, Loss: 0.0023059328086674213, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 382, Loss: 0.013356849551200867, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 383, Loss: 0.03050941415131092, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 384, Loss: 0.08318831771612167, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 385, Loss: 0.0002603928733151406, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 386, Loss: 0.05461886525154114, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 387, Loss: 0.07946386933326721, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 388, Loss: 0.01763005554676056, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 389, Loss: 0.01231393963098526, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 390, Loss: 0.002553547965362668, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 391, Loss: 0.005606243386864662, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 392, Loss: 0.003979381639510393, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 393, Loss: 0.014152291230857372, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 394, Loss: 0.011403756216168404, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 395, Loss: 0.0008970839553512633, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 396, Loss: 0.0031337516847997904, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 397, Loss: 0.004967750050127506, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 398, Loss: 0.0005592091474682093, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 399, Loss: 0.0002564205205999315, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 400, Loss: 0.09640689194202423, Accuracy: 0.96875\n",
      "Epoch: 4, Batch: 401, Loss: 0.010598934255540371, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 402, Loss: 0.024294419214129448, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 403, Loss: 0.011977363377809525, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 404, Loss: 0.0022208699956536293, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 405, Loss: 0.03940965607762337, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 406, Loss: 0.013149523176252842, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 407, Loss: 0.02695334702730179, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 408, Loss: 0.002133023925125599, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 409, Loss: 0.013262497261166573, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 410, Loss: 0.006805626675486565, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 411, Loss: 0.00274125998839736, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 412, Loss: 0.00029373462894000113, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 413, Loss: 0.053947076201438904, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 414, Loss: 0.00479374174028635, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 415, Loss: 0.05501353740692139, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 416, Loss: 0.0016765805194154382, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 417, Loss: 0.06810086965560913, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 418, Loss: 0.0006151651032269001, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 419, Loss: 0.01485460065305233, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 420, Loss: 0.019669288769364357, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 421, Loss: 0.006768960040062666, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 422, Loss: 0.004935943987220526, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 423, Loss: 0.022600267082452774, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 424, Loss: 0.007127129938453436, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 425, Loss: 0.057317595928907394, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 426, Loss: 0.002839483553543687, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 427, Loss: 0.006629756651818752, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 428, Loss: 0.020281368866562843, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 429, Loss: 0.0031143829692155123, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 430, Loss: 0.004978369455784559, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 431, Loss: 0.0030091628432273865, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 432, Loss: 0.03345370665192604, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 433, Loss: 0.0036485481541603804, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 434, Loss: 0.0058462475426495075, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 435, Loss: 0.005677404347807169, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 436, Loss: 0.002189580351114273, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 437, Loss: 0.001892590313218534, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 438, Loss: 0.003114137100055814, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 439, Loss: 0.042443811893463135, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 440, Loss: 0.005372727755457163, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 441, Loss: 0.013843252323567867, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 442, Loss: 0.034602563828229904, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 443, Loss: 0.015390926972031593, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 444, Loss: 0.019859347492456436, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 445, Loss: 0.042340558022260666, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 446, Loss: 0.0005533387884497643, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 447, Loss: 0.002511841244995594, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 448, Loss: 0.007315678987652063, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 449, Loss: 0.06297285854816437, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 450, Loss: 0.050830334424972534, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 451, Loss: 0.05504777655005455, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 452, Loss: 0.0033765272237360477, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 453, Loss: 0.02484918385744095, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 454, Loss: 0.00028104084776714444, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 455, Loss: 0.008618855848908424, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 456, Loss: 0.0010297743137925863, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 457, Loss: 0.00021283788373693824, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 458, Loss: 0.0023161694407463074, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 459, Loss: 0.02294069528579712, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 460, Loss: 0.0001679555862210691, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 461, Loss: 2.9463657483574934e-05, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 462, Loss: 2.3004959075478837e-05, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 463, Loss: 0.009673860855400562, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 464, Loss: 0.0024905004538595676, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 465, Loss: 0.00015304810949601233, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 466, Loss: 0.02196934074163437, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 467, Loss: 0.002235255902633071, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 468, Loss: 0.10579059273004532, Accuracy: 0.9895833730697632\n",
      "Epoch: 4, Loss: 0.01892024373111455, Accuracy: 0.9943141937255859\n",
      "Testing\n",
      "Epoch: 4, Batch: 0, Loss: 0.11264187842607498, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 1, Loss: 0.03440357372164726, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 2, Loss: 0.08442022651433945, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 3, Loss: 0.075437992811203, Accuracy: 0.96875\n",
      "Epoch: 4, Batch: 4, Loss: 0.030151328071951866, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 5, Loss: 0.1117873266339302, Accuracy: 0.9609375\n",
      "Epoch: 4, Batch: 6, Loss: 0.047708336263895035, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 7, Loss: 0.06387312710285187, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 8, Loss: 0.06473980098962784, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 9, Loss: 0.061599280685186386, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 10, Loss: 0.03405965864658356, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 11, Loss: 0.038785211741924286, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 12, Loss: 0.05186251178383827, Accuracy: 0.96875\n",
      "Epoch: 4, Batch: 13, Loss: 0.03607013076543808, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 14, Loss: 0.0180082768201828, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 15, Loss: 0.04380408674478531, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 16, Loss: 0.05195404589176178, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 17, Loss: 0.038869813084602356, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 18, Loss: 0.01833881065249443, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 19, Loss: 0.021542534232139587, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 20, Loss: 0.04780811071395874, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 21, Loss: 0.0199284628033638, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 22, Loss: 0.03204061836004257, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 23, Loss: 0.023094721138477325, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 24, Loss: 0.014895256608724594, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 25, Loss: 0.02313835918903351, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 26, Loss: 0.06195969134569168, Accuracy: 0.9765625\n",
      "Epoch: 4, Batch: 27, Loss: 0.07360034435987473, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 28, Loss: 0.0066085332073271275, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 29, Loss: 0.054503798484802246, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 30, Loss: 0.007902896031737328, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 31, Loss: 0.03725679591298103, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 32, Loss: 0.01329518761485815, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 33, Loss: 0.01491799671202898, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 34, Loss: 0.014820948243141174, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 35, Loss: 0.012402350082993507, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 36, Loss: 0.009416049346327782, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 37, Loss: 0.02615528553724289, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 38, Loss: 0.004783679731190205, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 39, Loss: 0.001547308755107224, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 40, Loss: 0.0050107683055102825, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 41, Loss: 0.0011404231190681458, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 42, Loss: 0.0015208465047180653, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 43, Loss: 0.0007157821673899889, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 44, Loss: 0.012836175970733166, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 45, Loss: 0.013624709099531174, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 46, Loss: 0.0391433909535408, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 47, Loss: 0.006255479529500008, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 48, Loss: 0.004664757754653692, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 49, Loss: 0.0001901459036162123, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 50, Loss: 0.0010549796279519796, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 51, Loss: 0.07572231441736221, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 52, Loss: 0.018421292304992676, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 53, Loss: 0.0007356680580414832, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 54, Loss: 0.00016505470557603985, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 55, Loss: 0.0017805139068514109, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 56, Loss: 0.002059859922155738, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 57, Loss: 0.0005969184567220509, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 58, Loss: 0.003296085400506854, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 59, Loss: 0.001277285860851407, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 60, Loss: 0.00040152479778043926, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 61, Loss: 0.004284472670406103, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 62, Loss: 0.0016263892175629735, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 63, Loss: 0.010841413401067257, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 64, Loss: 0.01082353014498949, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 65, Loss: 0.013144295662641525, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 66, Loss: 0.002333718352019787, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 67, Loss: 0.0007741962326690555, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 68, Loss: 0.00020877049246337265, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 69, Loss: 0.00033220680779777467, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 70, Loss: 0.004013724625110626, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 71, Loss: 0.00010419386671856046, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 72, Loss: 0.00016156211495399475, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 73, Loss: 0.005571804475039244, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 74, Loss: 0.0013363276375457644, Accuracy: 1.0\n",
      "Epoch: 4, Batch: 75, Loss: 0.013227605260908604, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 76, Loss: 0.025875605642795563, Accuracy: 0.9921875\n",
      "Epoch: 4, Batch: 77, Loss: 0.03115568496286869, Accuracy: 0.984375\n",
      "Epoch: 4, Batch: 78, Loss: 0.0001074077736120671, Accuracy: 1.0\n",
      "Epoch: 4, Loss: 0.02350216749204541, Accuracy: 0.992780864238739\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_loop(train_loader, epoch)\n",
    "    net.eval()\n",
    "\n",
    "    print('Testing')\n",
    "    train_loop(test_loader, epoch)\n",
    "    net.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x76028054e680>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = next(iter(test_loader))[0][0].view(28, 28)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1, 1, 28, 28) - (batch, color, height, width)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.view(1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (activation): ReLU()\n",
       "  (bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=800, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.1606,  -2.7881,  -1.2881,  -0.5853,  -3.1578,  -5.2321, -12.0607,\n",
       "          10.9540,  -3.7738,  -0.1944]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = image.to(device)\n",
    "\n",
    "forecast = net.forward(image)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7167/900664498.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  forecast = F.softmax(forecast)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.7278e-07, 1.0762e-06, 4.8232e-06, 9.7396e-06, 7.4355e-07, 9.3429e-08,\n",
       "         1.0112e-10, 9.9997e-01, 4.0160e-07, 1.4398e-05]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = F.softmax(forecast)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = forecast.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
